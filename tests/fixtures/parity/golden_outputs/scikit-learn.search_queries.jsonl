{"repo": "scikit-learn", "query": "RidgeClassifierCV store_cv_values parameter", "top_10": [{"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.425630569458008, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.08987283706665, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV.fit", "type": "codeblock", "score": 4.0474324226379395, "line": 2957, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        \"\"\"Fit Ridge classifier with cv.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features. When using GCV,\n            will be cast to float64 if necessary.\n\n        y : ndarray of shape (n_samples,)\n            Target values. Will be cast to X's dtype if necessary.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying scorer.\n\n            .. versionadded:: 1.5\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # `RidgeClassifier` does not accept \"sag\" or \"saga\" solver and thus support\n        # csr, csc, and coo sparse matrices. By using solver=\"eigen\" we force to accept\n        # all sparse format.\n        X, y, sample_weight, Y = self._prepare_data(X, y, sample_weight, solver=\"eigen\")\n\n        # If cv is None, gcv mode will be used and we used the binarized Y\n        # since y will not be binarized in _RidgeGCV estimator.\n        # If cv is not None, a GridSearchCV with some RidgeClassifier\n        # estimators are used where y will be binarized. Thus, we pass y\n        # instead of the binarized Y.\n        target = Y if self.cv is None else y\n        super().fit(X, target, sample_weight=sample_weight, **params)\n        return self"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 3.668154001235962, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeCV", "type": "codeblock", "score": 3.2313930988311768, "line": 2612, "text": "class RidgeCV(MultiOutputMixin, RegressorMixin, _BaseRidgeCV):\n    \"\"\"Ridge regression with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs efficient Leave-One-Out Cross-Validation.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`coefficient of determination <r2_score>` (:math:`R^2`) otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used, else,\n        :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    gcv_mode : {'auto', 'svd', 'eigen'}, default='auto'\n        Flag indicating which strategy to use when performing\n        Leave-One-Out Cross-Validation. Options are::\n\n            'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'\n            'svd' : force use of singular value decomposition of X when X is\n                dense, eigenvalue decomposition of X^T.X when X is sparse.\n            'eigen' : force computation via eigendecomposition of X.X^T\n\n        The 'auto' mode is the default and is intended to pick the cheaper\n        option of the two depending on the shape of the training data.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation values corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    alpha_per_target : bool, default=False\n        Flag indicating whether to optimize the alpha value (picked from the\n        `alphas` parameter list) for each target separately (for multi-output\n        settings: multiple prediction targets). When set to `True`, after\n        fitting, the `alpha_` attribute will contain a value for each target.\n        When set to `False`, a single alpha is used for all targets.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_alphas) or \\\n            shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation values for each alpha (only available if\n        ``store_cv_results=True`` and ``cv=None``). After ``fit()`` has been\n        called, this attribute will contain the mean squared errors if\n        `scoring is None` otherwise it will contain standardized per point\n        prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (n_features) or (n_targets, n_features)\n        Weight vector(s).\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float or ndarray of shape (n_targets,)\n        Estimated regularization parameter, or, if ``alpha_per_target=True``,\n        the estimated regularization parameter for each target.\n\n    best_score_ : float or ndarray of shape (n_targets,)\n        Score of base estimator with best alpha, or, if\n        ``alpha_per_target=True``, a score for each target.\n\n        .. versionadded:: 0.23\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Classifier based on ridge regression on {-1, 1} labels.\n    RidgeClassifierCV : Ridge classifier with built-in cross validation.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_diabetes\n    >>> from sklearn.linear_model import RidgeCV\n    >>> X, y = load_diabetes(return_X_y=True)\n    >>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.5166...\n    \"\"\""}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 2.799100875854492, "line": 1, "text": "\"\"\"A variety of linear models.\"\"\"\n\nfrom sklearn.linear_model._base import LinearRegression\nfrom sklearn.linear_model._bayes import ARDRegression, BayesianRidge\nfrom sklearn.linear_model._coordinate_descent import (\n    ElasticNet,\n    ElasticNetCV,\n    Lasso,\n    LassoCV,\n    MultiTaskElasticNet,\n    MultiTaskElasticNetCV,\n    MultiTaskLasso,\n    MultiTaskLassoCV,\n    enet_path,\n    lasso_path,\n)\nfrom sklearn.linear_model._glm import GammaRegressor, PoissonRegressor, TweedieRegressor\nfrom sklearn.linear_model._huber import HuberRegressor\nfrom sklearn.linear_model._least_angle import (\n    Lars,\n    LarsCV,\n    LassoLars,\n    LassoLarsCV,\n    LassoLarsIC,\n    lars_path,\n    lars_path_gram,\n)\nfrom sklearn.linear_model._logistic import LogisticRegression, LogisticRegressionCV\nfrom sklearn.linear_model._omp import (\n    OrthogonalMatchingPursuit,\n    OrthogonalMatchingPursuitCV,\n    orthogonal_mp,\n    orthogonal_mp_gram,\n)\nfrom sklearn.linear_model._passive_aggressive import (\n    PassiveAggressiveClassifier,\n    PassiveAggressiveRegressor,\n)\nfrom sklearn.linear_model._perceptron import Perceptron\nfrom sklearn.linear_model._quantile import QuantileRegressor\nfrom sklearn.linear_model._ransac import RANSACRegressor\nfrom sklearn.linear_model._ridge import (\n    Ridge,\n    RidgeClassifier,\n    RidgeClassifierCV,\n    RidgeCV,\n    ridge_regression,\n)\nfrom sklearn.linear_model._stochastic_gradient import (\n    SGDClassifier,\n    SGDOneClassSVM,\n    SGDRegressor,\n)\nfrom sklearn.linear_model._theil_sen import TheilSenRegressor"}, {"file": "sklearn/metrics/_ranking.py", "name": "roc_auc_score", "type": "codeblock", "score": 1.843227744102478, "line": 491, "text": "@validate_params(\n    {\n        \"y_true\": [\"array-like\"],\n        \"y_score\": [\"array-like\"],\n        \"average\": [StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\"}), None],\n        \"sample_weight\": [\"array-like\", None],\n        \"max_fpr\": [Interval(Real, 0.0, 1, closed=\"right\"), None],\n        \"multi_class\": [StrOptions({\"raise\", \"ovr\", \"ovo\"})],\n        \"labels\": [\"array-like\", None],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef roc_auc_score(\n    y_true,\n    y_score,\n    *,\n    average=\"macro\",\n    sample_weight=None,\n    max_fpr=None,\n    multi_class=\"raise\",\n    labels=None,\n):\n    \"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\n    from prediction scores.\n\n    Note: this implementation can be used with binary, multiclass and\n    multilabel classification, but some restrictions apply (see Parameters).\n\n    Read more in the :ref:`User Guide <roc_metrics>`.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n        True labels or binary label indicators. The binary and multiclass cases\n        expect labels with shape (n_samples,) while the multilabel case expects\n        binary label indicators with shape (n_samples, n_classes).\n\n    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n        Target scores.\n\n        * In the binary case, it corresponds to an array of shape\n          `(n_samples,)`. Both probability estimates and non-thresholded\n          decision values can be provided. The probability estimates correspond\n          to the **probability of the class with the greater label**,\n          i.e. `estimator.classes_[1]` and thus\n          `estimator.predict_proba(X, y)[:, 1]`. The decision values\n          corresponds to the output of `estimator.decision_function(X, y)`.\n          See more information in the :ref:`User guide <roc_auc_binary>`;\n        * In the multiclass case, it corresponds to an array of shape\n          `(n_samples, n_classes)` of probability estimates provided by the\n          `predict_proba` method. The probability estimates **must**\n          sum to 1 across the possible classes. In addition, the order of the\n          class scores must correspond to the order of ``labels``,\n          if provided, or else to the numerical or lexicographical order of\n          the labels in ``y_true``. See more information in the\n          :ref:`User guide <roc_auc_multiclass>`;\n        * In the multilabel case, it corresponds to an array of shape\n          `(n_samples, n_classes)`. Probability estimates are provided by the\n          `predict_proba` method and the non-thresholded decision values by\n          the `decision_function` method. The probability estimates correspond\n          to the **probability of the class with the greater label for each\n          output** of the classifier. See more information in the\n          :ref:`User guide <roc_auc_multilabel>`.\n\n    average : {'micro', 'macro', 'samples', 'weighted'} or None, \\\n            default='macro'\n        If ``None``, the scores for each class are returned.\n        Otherwise, this determines the type of averaging performed on the data.\n        Note: multiclass ROC AUC currently only handles the 'macro' and\n        'weighted' averages. For multiclass targets, `average=None` is only\n        implemented for `multi_class='ovr'` and `average='micro'` is only\n        implemented for `multi_class='ovr'`.\n\n        ``'micro'``:\n            Calculate metrics globally by considering each element of the label\n            indicator matrix as a label.\n        ``'macro'``:\n            Calculate metrics for each label, and find their unweighted\n            mean.  This does not take label imbalance into account.\n        ``'weighted'``:\n            Calculate metrics for each label, and find their average, weighted\n            by support (the number of true instances for each label).\n        ``'samples'``:\n            Calculate metrics for each instance, and find their average.\n\n        Will be ignored when ``y_true`` is binary.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    max_fpr : float > 0 and <= 1, default=None\n        If not ``None``, the standardized partial AUC [2]_ over the range\n        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n        computation currently is not supported for multiclass.\n\n    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n        Only used for multiclass targets. Determines the type of configuration\n        to use. The default value raises an error, so either\n        ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n\n        ``'ovr'``:\n            Stands for One-vs-rest. Computes the AUC of each class\n            against the rest [3]_ [4]_. This\n            treats the multiclass case in the same way as the multilabel case.\n            Sensitive to class imbalance even when ``average == 'macro'``,\n            because class imbalance affects the composition of each of the\n            'rest' groupings.\n        ``'ovo'``:\n            Stands for One-vs-one. Computes the average AUC of all\n            possible pairwise combinations of classes [5]_.\n            Insensitive to class imbalance when\n            ``average == 'macro'``.\n\n    labels : array-like of shape (n_classes,), default=None\n        Only used for multiclass targets. List of labels that index the\n        classes in ``y_score``. If ``None``, the numerical or lexicographical\n        order of the labels in ``y_true`` is used.\n\n    Returns\n    -------\n    auc : float\n        Area Under the Curve score.\n\n    See Also\n    --------\n    average_precision_score : Area under the precision-recall curve.\n    roc_curve : Compute Receiver operating characteristic (ROC) curve.\n    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n        (ROC) curve given an estimator and some data.\n    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n        (ROC) curve given the true and predicted values.\n\n    Notes\n    -----\n    The Gini Coefficient is a summary measure of the ranking ability of binary\n    classifiers. It is expressed using the area under of the ROC as follows:\n\n    G = 2 * AUC - 1\n\n    Where G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation\n    will ensure that random guessing will yield a score of 0 in expectation, and it is\n    upper bounded by 1.\n\n    References\n    ----------\n    .. [1] `Wikipedia entry for the Receiver operating characteristic\n            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n\n    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n\n    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n           probability estimation trees (Section 6.2), CeDER Working Paper\n           #IS-00-04, Stern School of Business, New York University.\n\n    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n            Recognition Letters, 27(8), 861-874.\n            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n\n    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n            Under the ROC Curve for Multiple Class Classification Problems.\n            Machine Learning, 45(2), 171-186.\n            <http://link.springer.com/article/10.1023/A:1010920819831>`_\n    .. [6] `Wikipedia entry for the Gini coefficient\n            <https://en.wikipedia.org/wiki/Gini_coefficient>`_\n\n    Examples\n    --------\n    Binary case:\n\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.metrics import roc_auc_score\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\", random_state=0).fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n    0.99\n    >>> roc_auc_score(y, clf.decision_function(X))\n    0.99\n\n    Multiclass case:\n\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\").fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n    0.99\n\n    Multilabel case:\n\n    >>> import numpy as np\n    >>> from sklearn.datasets import make_multilabel_classification\n    >>> from sklearn.multioutput import MultiOutputClassifier\n    >>> X, y = make_multilabel_classification(random_state=0)\n    >>> clf = MultiOutputClassifier(clf).fit(X, y)\n    >>> # get a list of n_output containing probability arrays of shape\n    >>> # (n_samples, n_classes)\n    >>> y_score = clf.predict_proba(X)\n    >>> # extract the positive columns for each output\n    >>> y_score = np.transpose([score[:, 1] for score in y_score])\n    >>> roc_auc_score(y, y_score, average=None)\n    array([0.828, 0.852, 0.94, 0.869, 0.95])\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> clf = RidgeClassifierCV().fit(X, y)\n    >>> roc_auc_score(y, clf.decision_function(X), average=None)\n    array([0.82, 0.847, 0.93, 0.872, 0.944])\n    \"\"\"\n    # ... other code"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifier", "type": "codeblock", "score": 1.3511686325073242, "line": 1388, "text": "class RidgeClassifier(_RidgeClassifierMixin, _BaseRidge):\n    \"\"\"Classifier using Ridge regression.\n\n    This classifier first converts the target values into ``{-1, 1}`` and\n    then treats the problem as a regression task (multi-output regression in\n    the multiclass case).\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alpha : float, default=1.0\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set to false, no\n        intercept will be used in calculations (e.g. data is expected to be\n        already centered).\n\n    copy_X : bool, default=True\n        If True, X will be copied; else, it may be overwritten.\n\n    max_iter : int, default=None\n        Maximum number of iterations for conjugate gradient solver.\n        The default value is determined by scipy.sparse.linalg.\n\n    tol : float, default=1e-4\n        The precision of the solution (`coef_`) is determined by `tol` which\n        specifies a different convergence criterion for each solver:\n\n        - 'svd': `tol` has no impact.\n\n        - 'cholesky': `tol` has no impact.\n\n        - 'sparse_cg': norm of residuals smaller than `tol`.\n\n        - 'lsqr': `tol` is set as atol and btol of scipy.sparse.linalg.lsqr,\n          which control the norm of the residual vector in terms of the norms of\n          matrix and coefficients.\n\n        - 'sag' and 'saga': relative change of coef smaller than `tol`.\n\n        - 'lbfgs': maximum of the absolute (projected) gradient=max|residuals|\n          smaller than `tol`.\n\n        .. versionchanged:: 1.2\n           Default value changed from 1e-3 to 1e-4 for consistency with other linear\n           models.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', \\\n            'sag', 'saga', 'lbfgs'}, default='auto'\n        Solver to use in the computational routines:\n\n        - 'auto' chooses the solver automatically based on the type of data.\n\n        - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n          coefficients. It is the most stable solver, in particular more stable\n          for singular matrices than 'cholesky' at the cost of being slower.\n\n        - 'cholesky' uses the standard scipy.linalg.solve function to\n          obtain a closed-form solution.\n\n        - 'sparse_cg' uses the conjugate gradient solver as found in\n          scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n          more appropriate than 'cholesky' for large-scale data\n          (possibility to set `tol` and `max_iter`).\n\n        - 'lsqr' uses the dedicated regularized least-squares routine\n          scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n          procedure.\n\n        - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n          its unbiased and more flexible version named SAGA. Both methods\n          use an iterative procedure, and are often faster than other solvers\n          when both n_samples and n_features are large. Note that 'sag' and\n          'saga' fast convergence is only guaranteed on features with\n          approximately the same scale. You can preprocess the data with a\n          scaler from sklearn.preprocessing.\n\n          .. versionadded:: 0.17\n             Stochastic Average Gradient descent solver.\n          .. versionadded:: 0.19\n             SAGA solver.\n\n        - 'lbfgs' uses L-BFGS-B algorithm implemented in\n          `scipy.optimize.minimize`. It can be used only when `positive`\n          is True.\n\n    positive : bool, default=False\n        When set to ``True``, forces the coefficients to be positive.\n        Only 'lbfgs' solver is supported in this case.\n\n    random_state : int, RandomState instance, default=None\n        Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n        See :term:`Glossary <random_state>` for details.\n\n    Attributes\n    ----------\n    coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    n_iter_ : None or ndarray of shape (n_targets,)\n        Actual number of iterations for each target. Available only for\n        sag and lsqr solvers. Other solvers will return None.\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    solver_ : str\n        The solver that was used at fit time by the computational\n        routines.\n\n        .. versionadded:: 1.5\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifierCV :  Ridge classifier with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifier\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifier().fit(X, y)\n    >>> clf.score(X, y)\n    0.9595...\n    \"\"\""}, {"file": "sklearn/gaussian_process/kernels.py", "name": "Kernel.get_params", "type": "codeblock", "score": 0.8048868775367737, "line": 178, "text": "class Kernel(metaclass=ABCMeta):\n\n    def get_params(self, deep=True):\n        \"\"\"Get parameters of this kernel.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : dict\n            Parameter names mapped to their values.\n        \"\"\"\n        params = dict()\n\n        # introspect the constructor arguments to find the model parameters\n        # to represent\n        cls = self.__class__\n        init = getattr(cls.__init__, \"deprecated_original\", cls.__init__)\n        init_sign = signature(init)\n        args, varargs = [], []\n        for parameter in init_sign.parameters.values():\n            if parameter.kind != parameter.VAR_KEYWORD and parameter.name != \"self\":\n                args.append(parameter.name)\n            if parameter.kind == parameter.VAR_POSITIONAL:\n                varargs.append(parameter.name)\n\n        if len(varargs) != 0:\n            raise RuntimeError(\n                \"scikit-learn kernels should always \"\n                \"specify their parameters in the signature\"\n                \" of their __init__ (no varargs).\"\n                \" %s doesn't follow this convention.\" % (cls,)\n            )\n        for arg in args:\n            params[arg] = getattr(self, arg)\n\n        return params"}, {"file": "sklearn/pipeline.py", "name": "Pipeline.set_params", "type": "codeblock", "score": 0.7859475612640381, "line": 268, "text": "class Pipeline(_BaseComposition):\n\n    def set_params(self, **kwargs):\n        \"\"\"Set the parameters of this estimator.\n\n        Valid parameter keys can be listed with ``get_params()``. Note that\n        you can directly set the parameters of the estimators contained in\n        `steps`.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Parameters of this estimator or parameters of estimators contained\n            in `steps`. Parameters of the steps may be set using its name and\n            the parameter name separated by a '__'.\n\n        Returns\n        -------\n        self : object\n            Pipeline class instance.\n        \"\"\"\n        self._set_params(\"steps\", **kwargs)\n        return self"}], "total_results": 10}
{"repo": "scikit-learn", "query": "linear_model._ridge RidgeClassifierCV docstring", "top_10": [{"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 8.75922966003418, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 7.517611503601074, "line": 1, "text": "\"\"\"A variety of linear models.\"\"\"\n\nfrom sklearn.linear_model._base import LinearRegression\nfrom sklearn.linear_model._bayes import ARDRegression, BayesianRidge\nfrom sklearn.linear_model._coordinate_descent import (\n    ElasticNet,\n    ElasticNetCV,\n    Lasso,\n    LassoCV,\n    MultiTaskElasticNet,\n    MultiTaskElasticNetCV,\n    MultiTaskLasso,\n    MultiTaskLassoCV,\n    enet_path,\n    lasso_path,\n)\nfrom sklearn.linear_model._glm import GammaRegressor, PoissonRegressor, TweedieRegressor\nfrom sklearn.linear_model._huber import HuberRegressor\nfrom sklearn.linear_model._least_angle import (\n    Lars,\n    LarsCV,\n    LassoLars,\n    LassoLarsCV,\n    LassoLarsIC,\n    lars_path,\n    lars_path_gram,\n)\nfrom sklearn.linear_model._logistic import LogisticRegression, LogisticRegressionCV\nfrom sklearn.linear_model._omp import (\n    OrthogonalMatchingPursuit,\n    OrthogonalMatchingPursuitCV,\n    orthogonal_mp,\n    orthogonal_mp_gram,\n)\nfrom sklearn.linear_model._passive_aggressive import (\n    PassiveAggressiveClassifier,\n    PassiveAggressiveRegressor,\n)\nfrom sklearn.linear_model._perceptron import Perceptron\nfrom sklearn.linear_model._quantile import QuantileRegressor\nfrom sklearn.linear_model._ransac import RANSACRegressor\nfrom sklearn.linear_model._ridge import (\n    Ridge,\n    RidgeClassifier,\n    RidgeClassifierCV,\n    RidgeCV,\n    ridge_regression,\n)\nfrom sklearn.linear_model._stochastic_gradient import (\n    SGDClassifier,\n    SGDOneClassSVM,\n    SGDRegressor,\n)\nfrom sklearn.linear_model._theil_sen import TheilSenRegressor"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV.fit", "type": "codeblock", "score": 6.092648506164551, "line": 2957, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        \"\"\"Fit Ridge classifier with cv.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features. When using GCV,\n            will be cast to float64 if necessary.\n\n        y : ndarray of shape (n_samples,)\n            Target values. Will be cast to X's dtype if necessary.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying scorer.\n\n            .. versionadded:: 1.5\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # `RidgeClassifier` does not accept \"sag\" or \"saga\" solver and thus support\n        # csr, csc, and coo sparse matrices. By using solver=\"eigen\" we force to accept\n        # all sparse format.\n        X, y, sample_weight, Y = self._prepare_data(X, y, sample_weight, solver=\"eigen\")\n\n        # If cv is None, gcv mode will be used and we used the binarized Y\n        # since y will not be binarized in _RidgeGCV estimator.\n        # If cv is not None, a GridSearchCV with some RidgeClassifier\n        # estimators are used where y will be binarized. Thus, we pass y\n        # instead of the binarized Y.\n        target = Y if self.cv is None else y\n        super().fit(X, target, sample_weight=sample_weight, **params)\n        return self"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 5.936751842498779, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.304271221160889, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "sklearn/linear_model/_ridge.py", "name": "docstring", "type": "codeblock", "score": 3.9614744186401367, "line": 1, "text": "\"\"\"\nRidge regression\n\"\"\"\n\nimport numbers\nimport warnings\nfrom abc import ABCMeta, abstractmethod\nfrom functools import partial\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom scipy import linalg, optimize, sparse\nfrom scipy.sparse import linalg as sp_linalg\n\nfrom sklearn.base import (\n    BaseEstimator,\n    MultiOutputMixin,\n    RegressorMixin,\n    _fit_context,\n    is_classifier,\n)\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.linear_model._base import (\n    LinearClassifierMixin,\n    LinearModel,\n    _preprocess_data,\n    _rescale_data,\n)\nfrom sklearn.linear_model._sag import sag_solver\nfrom sklearn.metrics import check_scoring, get_scorer, get_scorer_names\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.utils import (\n    Bunch,\n    check_array,\n    check_consistent_length,\n    check_scalar,\n    column_or_1d,\n    compute_sample_weight,\n)\nfrom sklearn.utils._array_api import (\n    _convert_to_numpy,\n    _is_numpy_namespace,\n    _max_precision_float_dtype,\n    _ravel,\n    device,\n    ensure_common_namespace_device,\n    get_namespace,\n    get_namespace_and_device,\n)\nfrom sklearn.utils._param_validation import Interval, StrOptions, validate_params\nfrom sklearn.utils.extmath import row_norms, safe_sparse_dot\nfrom sklearn.utils.fixes import _sparse_linalg_cg\nfrom sklearn.utils.metadata_routing import (\n    MetadataRouter,\n    MethodMapping,\n    _raise_for_params,\n    _routing_enabled,\n    process_routing,\n)\nfrom sklearn.utils.sparsefuncs import mean_variance_axis\nfrom sklearn.utils.validation import (\n    _check_sample_weight,\n    check_is_fitted,\n    validate_data,\n)"}, {"file": "sklearn/linear_model/_ridge.py", "name": "_RidgeGCV._solve_eigen_covariance", "type": "codeblock", "score": 3.851304531097412, "line": 2091, "text": "class _RidgeGCV(LinearModel):\n\n    def _solve_eigen_covariance(self, alpha, y, sqrt_sw, X_mean, eigvals, V, X):\n        \"\"\"Compute dual coefficients and diagonal of G^-1.\n\n        Used when we have a decomposition of X^T.X\n        (n_samples > n_features and X is sparse).\n        \"\"\"\n        if self.fit_intercept:\n            return self._solve_eigen_covariance_intercept(\n                alpha, y, sqrt_sw, X_mean, eigvals, V, X\n            )\n        return self._solve_eigen_covariance_no_intercept(\n            alpha, y, sqrt_sw, X_mean, eigvals, V, X\n        )"}, {"file": "sklearn/linear_model/_ridge.py", "name": "Ridge.__init__", "type": "codeblock", "score": 3.8041465282440186, "line": 1209, "text": "class Ridge(MultiOutputMixin, RegressorMixin, _BaseRidge):\n\n    def __init__(\n        self,\n        alpha=1.0,\n        *,\n        fit_intercept=True,\n        copy_X=True,\n        max_iter=None,\n        tol=1e-4,\n        solver=\"auto\",\n        positive=False,\n        random_state=None,\n    ):\n        super().__init__(\n            alpha=alpha,\n            fit_intercept=fit_intercept,\n            copy_X=copy_X,\n            max_iter=max_iter,\n            tol=tol,\n            solver=solver,\n            positive=positive,\n            random_state=random_state,\n        )"}, {"file": "sklearn/linear_model/_ridge.py", "name": "_get_rescaled_operator", "type": "codeblock", "score": 3.7886829376220703, "line": 72, "text": "def _get_rescaled_operator(X, X_offset, sample_weight_sqrt):\n    \"\"\"Create LinearOperator for matrix products with implicit centering.\n\n    Matrix product `LinearOperator @ coef` returns `(X - X_offset) @ coef`.\n    \"\"\"\n\n    def matvec(b):\n        return X.dot(b) - sample_weight_sqrt * b.dot(X_offset)\n\n    def rmatvec(b):\n        return X.T.dot(b) - X_offset * b.dot(sample_weight_sqrt)\n\n    X1 = sparse.linalg.LinearOperator(shape=X.shape, matvec=matvec, rmatvec=rmatvec)\n    return X1"}, {"file": "sklearn/linear_model/_ridge.py", "name": "_solve_svd", "type": "codeblock", "score": 3.743037700653076, "line": 301, "text": "def _solve_svd(X, y, alpha, xp=None):\n    xp, _ = get_namespace(X, xp=xp)\n    U, s, Vt = xp.linalg.svd(X, full_matrices=False)\n    idx = s > 1e-15  # same default value as scipy.linalg.pinv\n    s_nnz = s[idx][:, None]\n    UTy = U.T @ y\n    d = xp.zeros((s.shape[0], alpha.shape[0]), dtype=X.dtype, device=device(X))\n    d[idx] = s_nnz / (s_nnz**2 + alpha)\n    d_UT_y = d * UTy\n    return (Vt.T @ d_UT_y).T"}], "total_results": 10}
{"repo": "scikit-learn", "query": "cv_values_ attribute description", "top_10": [{"file": "sklearn/utils/_testing.py", "name": "_check_consistency_items", "type": "codeblock", "score": 5.4839768409729, "line": 684, "text": "def _check_consistency_items(\n    items_docs,\n    type_or_desc,\n    section,\n    n_objects,\n    descr_regex_pattern=\"\",\n    ignore_types=tuple(),\n):\n    \"\"\"Helper to check docstring consistency of all `items_docs`.\n\n    If item is not present in all objects, checking is skipped and warning raised.\n    If `regex` provided, match descriptions to all descriptions.\n\n    Parameters\n    ----------\n    items_doc : dict of dict of str\n        Dictionary where the key is the string type or description, value is\n        a dictionary where the key is \"type description\" or \"description\"\n        and the value is a list of object names with the same string type or\n        description.\n\n    type_or_desc : {\"type description\", \"description\"}\n        Whether to check type description or description between objects.\n\n    section : {\"Parameters\", \"Attributes\", \"Returns\"}\n        Name of the section type.\n\n    n_objects : int\n        Total number of objects.\n\n    descr_regex_pattern : str, default=\"\"\n        Regex pattern to match for description of all objects.\n        Ignored when `type_or_desc=\"type description\".\n\n    ignore_types : tuple of str, default=()\n        Tuple of parameter/attribute/return names for which type description\n        matching is ignored. Ignored when `type_or_desc=\"description\".\n    \"\"\"\n    skipped = []\n    # ... other code"}, {"file": "sklearn/externals/_arff.py", "name": "ArffEncoder.iter_encode", "type": "codeblock", "score": 4.88093376159668, "line": 981, "text": "class ArffEncoder:\n\n    def iter_encode(self, obj):\n        '''The iterative version of `arff.ArffEncoder.encode`.\n\n        This encodes iteratively a given object and return, one-by-one, the\n        lines of the ARFF file.\n\n        :param obj: the object containing the ARFF information.\n        :return: (yields) the ARFF file as strings.\n        '''\n        # DESCRIPTION\n        if obj.get('description', None):\n            for row in obj['description'].split('\\n'):\n                yield self._encode_comment(row)\n\n        # RELATION\n        if not obj.get('relation'):\n            raise BadObject('Relation name not found or with invalid value.')\n\n        yield self._encode_relation(obj['relation'])\n        yield ''\n\n        # ATTRIBUTES\n        if not obj.get('attributes'):\n            raise BadObject('Attributes not found.')\n\n        attribute_names = set()\n        for attr in obj['attributes']:\n            # Verify for bad object format\n            if not isinstance(attr, (tuple, list)) or \\\n               len(attr) != 2 or \\\n               not isinstance(attr[0], str):\n                raise BadObject('Invalid attribute declaration \"%s\"'%str(attr))\n\n            if isinstance(attr[1], str):\n                # Verify for invalid types\n                if attr[1] not in _SIMPLE_TYPES:\n                    raise BadObject('Invalid attribute type \"%s\"'%str(attr))\n\n            # Verify for bad object format\n            elif not isinstance(attr[1], (tuple, list)):\n                raise BadObject('Invalid attribute type \"%s\"'%str(attr))\n\n            # Verify attribute name is not used twice\n            if attr[0] in attribute_names:\n                raise BadObject('Trying to use attribute name \"%s\" for the '\n                                'second time.' % str(attr[0]))\n            else:\n                attribute_names.add(attr[0])\n\n            yield self._encode_attribute(attr[0], attr[1])\n        yield ''\n        attributes = obj['attributes']\n\n        # DATA\n        yield _TK_DATA\n        if 'data' in obj:\n            data = _get_data_object_for_encoding(obj.get('data'))\n            yield from data.encode_data(obj.get('data'), attributes)\n\n        yield ''"}, {"file": "sklearn/utils/_testing.py", "name": "assert_docstring_consistency", "type": "codeblock", "score": 4.6020026206970215, "line": 761, "text": "def assert_docstring_consistency(\n    objects,\n    include_params=False,\n    exclude_params=None,\n    include_attrs=False,\n    exclude_attrs=None,\n    include_returns=False,\n    exclude_returns=None,\n    descr_regex_pattern=None,\n    ignore_types=tuple(),\n):\n    r\"\"\"Check consistency between docstring parameters/attributes/returns of objects.\n\n    Checks if parameters/attributes/returns have the same type specification and\n    description (ignoring whitespace) across `objects`. Intended to be used for\n    related classes/functions/data descriptors.\n\n    Entries that do not appear across all `objects` are ignored.\n\n    Parameters\n    ----------\n    objects : list of {classes, functions, data descriptors}\n        Objects to check.\n        Objects may be classes, functions or data descriptors with docstrings that\n        can be parsed by numpydoc.\n\n    include_params : list of str or bool, default=False\n        List of parameters to be included. If True, all parameters are included,\n        if False, checking is skipped for parameters.\n        Can only be set if `exclude_params` is None.\n\n    exclude_params : list of str or None, default=None\n        List of parameters to be excluded. If None, no parameters are excluded.\n        Can only be set if `include_params` is True.\n\n    include_attrs : list of str or bool, default=False\n        List of attributes to be included. If True, all attributes are included,\n        if False, checking is skipped for attributes.\n        Can only be set if `exclude_attrs` is None.\n\n    exclude_attrs : list of str or None, default=None\n        List of attributes to be excluded. If None, no attributes are excluded.\n        Can only be set if `include_attrs` is True.\n\n    include_returns : list of str or bool, default=False\n        List of returns to be included. If True, all returns are included,\n        if False, checking is skipped for returns.\n        Can only be set if `exclude_returns` is None.\n\n    exclude_returns : list of str or None, default=None\n        List of returns to be excluded. If None, no returns are excluded.\n        Can only be set if `include_returns` is True.\n\n    descr_regex_pattern : str, default=None\n        Regular expression to match to all descriptions of included\n        parameters/attributes/returns. If None, will revert to default behavior\n        of comparing descriptions between objects.\n\n    ignore_types : tuple of str, default=tuple()\n        Tuple of parameter/attribute/return names to exclude from type description\n        matching between objects.\n\n    Examples\n    --------\n    >>> from sklearn.metrics import (accuracy_score, classification_report,\n    ... mean_absolute_error, mean_squared_error, median_absolute_error)\n    >>> from sklearn.utils._testing import assert_docstring_consistency\n    ... # doctest: +SKIP\n    >>> assert_docstring_consistency([mean_absolute_error, mean_squared_error],\n    ... include_params=['y_true', 'y_pred', 'sample_weight'])  # doctest: +SKIP\n    >>> assert_docstring_consistency([median_absolute_error, mean_squared_error],\n    ... include_params=True)  # doctest: +SKIP\n    >>> assert_docstring_consistency([accuracy_score, classification_report],\n    ... include_params=[\"y_true\"],\n    ... descr_regex_pattern=r\"Ground truth \\(correct\\) (labels|target values)\")\n    ... # doctest: +SKIP\n    \"\"\"\n    # ... other code"}, {"file": "sklearn/externals/_arff.py", "name": "ArffDecoder._decode", "type": "codeblock", "score": 4.553133964538574, "line": 796, "text": "class ArffDecoder:\n\n    def _decode(self, s, encode_nominal=False, matrix_type=DENSE):\n        # ... other code\n        for row in s:\n            self._current_line += 1\n            # Ignore empty lines\n            row = row.strip(' \\r\\n')\n            if not row: continue\n\n            u_row = row.upper()\n\n            # DESCRIPTION -----------------------------------------------------\n            if u_row.startswith(_TK_DESCRIPTION) and STATE == _TK_DESCRIPTION:\n                obj['description'] += self._decode_comment(row) + '\\n'\n            # -----------------------------------------------------------------\n\n            # RELATION --------------------------------------------------------\n            elif u_row.startswith(_TK_RELATION):\n                if STATE != _TK_DESCRIPTION:\n                    raise BadLayout()\n\n                STATE = _TK_RELATION\n                obj['relation'] = self._decode_relation(row)\n            # -----------------------------------------------------------------\n\n            # ATTRIBUTE -------------------------------------------------------\n            elif u_row.startswith(_TK_ATTRIBUTE):\n                if STATE != _TK_RELATION and STATE != _TK_ATTRIBUTE:\n                    raise BadLayout()\n\n                STATE = _TK_ATTRIBUTE\n\n                attr = self._decode_attribute(row)\n                if attr[0] in attribute_names:\n                    raise BadAttributeName(attr[0], attribute_names[attr[0]])\n                else:\n                    attribute_names[attr[0]] = self._current_line\n                obj['attributes'].append(attr)\n\n                if isinstance(attr[1], (list, tuple)):\n                    if encode_nominal:\n                        conversor = EncodedNominalConversor(attr[1])\n                    else:\n                        conversor = NominalConversor(attr[1])\n                else:\n                    CONVERSOR_MAP = {'STRING': str,\n                                     'INTEGER': lambda x: int(float(x)),\n                                     'NUMERIC': float,\n                                     'REAL': float}\n                    conversor = CONVERSOR_MAP[attr[1]]\n\n                self._conversors.append(conversor)\n            # -----------------------------------------------------------------\n\n            # DATA ------------------------------------------------------------\n            elif u_row.startswith(_TK_DATA):\n                if STATE != _TK_ATTRIBUTE:\n                    raise BadLayout()\n\n                break\n            # -----------------------------------------------------------------\n\n            # COMMENT ---------------------------------------------------------\n            elif u_row.startswith(_TK_COMMENT):\n                pass\n            # -----------------------------------------------------------------\n        else:\n            # Never found @DATA\n            raise BadLayout()\n\n        def stream():\n            for row in s:\n                self._current_line += 1\n                row = row.strip()\n                # Ignore empty lines and comment lines.\n                if row and not row.startswith(_TK_COMMENT):\n                    yield row\n\n        # Alter the data object\n        obj['data'] = data.decode_rows(stream(), self._conversors)\n        if obj['description'].endswith('\\n'):\n            obj['description'] = obj['description'][:-1]\n\n        return obj"}, {"file": "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py", "name": "BaseHistGradientBoosting._bin_data", "type": "codeblock", "score": 4.0288472175598145, "line": 1221, "text": "class BaseHistGradientBoosting(BaseEstimator, ABC):\n\n    def _bin_data(self, X, is_training_data):\n        \"\"\"Bin data X.\n\n        If is_training_data, then fit the _bin_mapper attribute.\n        Else, the binned data is converted to a C-contiguous array.\n        \"\"\"\n\n        description = \"training\" if is_training_data else \"validation\"\n        if self.verbose:\n            print(\n                \"Binning {:.3f} GB of {} data: \".format(X.nbytes / 1e9, description),\n                end=\"\",\n                flush=True,\n            )\n        tic = time()\n        if is_training_data:\n            X_binned = self._bin_mapper.fit_transform(X)  # F-aligned array\n        else:\n            X_binned = self._bin_mapper.transform(X)  # F-aligned array\n            # We convert the array to C-contiguous since predicting is faster\n            # with this layout (training is faster on F-arrays though)\n            X_binned = np.ascontiguousarray(X_binned)\n        toc = time()\n        if self.verbose:\n            duration = toc - tic\n            print(\"{:.3f} s\".format(duration))\n\n        return X_binned"}, {"file": "sklearn/externals/_arff.py", "name": "ArffDecoder._decode", "type": "codeblock", "score": 3.7188596725463867, "line": 771, "text": "class ArffDecoder:\n\n    def _decode(self, s, encode_nominal=False, matrix_type=DENSE):\n        '''Do the job the ``encode``.'''\n\n        # Make sure this method is idempotent\n        self._current_line = 0\n\n        # If string, convert to a list of lines\n        if isinstance(s, str):\n            s = s.strip('\\r\\n ').replace('\\r\\n', '\\n').split('\\n')\n\n        # Create the return object\n        obj: ArffContainerType = {\n            'description': '',\n            'relation': '',\n            'attributes': [],\n            'data': []\n        }\n        attribute_names = {}\n\n        # Create the data helper object\n        data = _get_data_object_for_decoding(matrix_type)\n\n        # Read all lines\n        STATE = _TK_DESCRIPTION\n        s = iter(s)\n        # ... other code"}, {"file": "sklearn/base.py", "name": "BaseEstimator.__sklearn_tags__", "type": "codeblock", "score": 3.592561960220337, "line": 475, "text": "class BaseEstimator(ReprHTMLMixin, _HTMLDocumentationLinkMixin, _MetadataRequester):\n\n    def __sklearn_tags__(self):\n        return Tags(\n            estimator_type=None,\n            target_tags=TargetTags(required=False),\n            transformer_tags=None,\n            regressor_tags=None,\n            classifier_tags=None,\n        )\n\n    def _validate_params(self):\n        \"\"\"Validate types and values of constructor parameters\n\n        The expected type and values must be defined in the `_parameter_constraints`\n        class attribute, which is a dictionary `param_name: list of constraints`. See\n        the docstring of `validate_parameter_constraints` for a description of the\n        accepted constraints.\n        \"\"\"\n        validate_parameter_constraints(\n            self._parameter_constraints,\n            self.get_params(deep=False),\n            caller_name=self.__class__.__name__,\n        )"}, {"file": "sklearn/externals/_numpydoc/docscrape.py", "name": "NumpyDocString:5", "type": "codeblock", "score": 3.58463978767395, "line": 286, "text": "class NumpyDocString(Mapping):\n    empty_description = \"..\"\n\n    def _parse_see_also(self, content):\n        \"\"\"\n        func_name : Descriptive text\n            continued text\n        another_func_name : Descriptive text\n        func_name1, func_name2, :meth:`func_name`, func_name3\n\n        \"\"\"\n\n        content = dedent_lines(content)\n\n        items = []\n\n        def parse_item_name(text):\n            \"\"\"Match ':role:`name`' or 'name'.\"\"\"\n            m = self._func_rgx.match(text)\n            if not m:\n                self._error_location(f\"Error parsing See Also entry {line!r}\")\n            role = m.group(\"role\")\n            name = m.group(\"name\") if role else m.group(\"name2\")\n            return name, role, m.end()\n\n        rest = []\n        for line in content:\n            if not line.strip():\n                continue\n\n            line_match = self._line_rgx.match(line)\n            description = None\n            if line_match:\n                description = line_match.group(\"desc\")\n                if line_match.group(\"trailing\") and description:\n                    self._error_location(\n                        \"Unexpected comma or period after function list at index %d of \"\n                        'line \"%s\"' % (line_match.end(\"trailing\"), line),\n                        error=False,\n                    )\n            if not description and line.startswith(\" \"):\n                rest.append(line.strip())\n            elif line_match:\n                funcs = []\n                text = line_match.group(\"allfuncs\")\n                while True:\n                    if not text.strip():\n                        break\n                    name, role, match_end = parse_item_name(text)\n                    funcs.append((name, role))\n                    text = text[match_end:].strip()\n                    if text and text[0] == \",\":\n                        text = text[1:].strip()\n                rest = list(filter(None, [description]))\n                items.append((funcs, rest))\n            else:\n                self._error_location(f\"Error parsing See Also entry {line!r}\")\n        return items"}, {"file": "sklearn/datasets/_base.py", "name": "load_files", "type": "codeblock", "score": 3.438368558883667, "line": 131, "text": "@validate_params(\n    {\n        \"container_path\": [str, os.PathLike],\n        \"description\": [str, None],\n        \"categories\": [list, None],\n        \"load_content\": [\"boolean\"],\n        \"shuffle\": [\"boolean\"],\n        \"encoding\": [str, None],\n        \"decode_error\": [StrOptions({\"strict\", \"ignore\", \"replace\"})],\n        \"random_state\": [\"random_state\"],\n        \"allowed_extensions\": [list, None],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef load_files(\n    container_path,\n    *,\n    description=None,\n    categories=None,\n    load_content=True,\n    shuffle=True,\n    encoding=None,\n    decode_error=\"strict\",\n    random_state=0,\n    allowed_extensions=None,\n):\n    \"\"\"Load text files with categories as subfolder names.\n\n    Individual samples are assumed to be files stored a two levels folder\n    structure such as the following:\n\n    .. code-block:: text\n\n        container_folder/\n            category_1_folder/\n                file_1.txt\n                file_2.txt\n                ...\n                file_42.txt\n            category_2_folder/\n                file_43.txt\n                file_44.txt\n                ...\n\n    The folder names are used as supervised signal label names. The individual\n    file names are not important.\n\n    This function does not try to extract features into a numpy array or scipy\n    sparse matrix. In addition, if load_content is false it does not try to\n    load the files in memory.\n\n    To use text files in a scikit-learn classification or clustering algorithm,\n    you will need to use the :mod:`~sklearn.feature_extraction.text` module to\n    build a feature extraction transformer that suits your problem.\n\n    If you set load_content=True, you should also specify the encoding of the\n    text using the 'encoding' parameter. For many modern text files, 'utf-8'\n    will be the correct encoding. If you leave encoding equal to None, then the\n    content will be made of bytes instead of Unicode, and you will not be able\n    to use most functions in :mod:`~sklearn.feature_extraction.text`.\n\n    Similar feature extractors should be built for other kind of unstructured\n    data input such as images, audio, video, ...\n\n    If you want files with a specific file extension (e.g. `.txt`) then you\n    can pass a list of those file extensions to `allowed_extensions`.\n\n    Read more in the :ref:`User Guide <datasets>`.\n\n    Parameters\n    ----------\n    container_path : str\n        Path to the main folder holding one subfolder per category.\n\n    description : str, default=None\n        A paragraph describing the characteristic of the dataset: its source,\n        reference, etc.\n\n    categories : list of str, default=None\n        If None (default), load all the categories. If not None, list of\n        category names to load (other categories ignored).\n\n    load_content : bool, default=True\n        Whether to load or not the content of the different files. If true a\n        'data' attribute containing the text information is present in the data\n        structure returned. If not, a filenames attribute gives the path to the\n        files.\n\n    shuffle : bool, default=True\n        Whether or not to shuffle the data: might be important for models that\n        make the assumption that the samples are independent and identically\n        distributed (i.i.d.), such as stochastic gradient descent.\n\n    encoding : str, default=None\n        If None, do not try to decode the content of the files (e.g. for images\n        or other non-text content). If not None, encoding to use to decode text\n        files to Unicode if load_content is True.\n\n    decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n        Instruction on what to do if a byte sequence is given to analyze that\n        contains characters not of the given `encoding`. Passed as keyword\n        argument 'errors' to bytes.decode.\n\n    random_state : int, RandomState instance or None, default=0\n        Determines random number generation for dataset shuffling. Pass an int\n        for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    allowed_extensions : list of str, default=None\n        List of desired file extensions to filter the files to be loaded.\n\n    Returns\n    -------\n    data : :class:`~sklearn.utils.Bunch`\n        Dictionary-like object, with the following attributes.\n\n        data : list of str\n            Only present when `load_content=True`.\n            The raw text data to learn.\n        target : ndarray\n            The target labels (integer index).\n        target_names : list\n            The names of target classes.\n        DESCR : str\n            The full description of the dataset.\n        filenames: ndarray\n            The filenames holding the dataset.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_files\n    >>> container_path = \"./\"\n    >>> load_files(container_path)  # doctest: +SKIP\n    \"\"\"\n    # ... other code"}, {"file": "doc/api_reference.py", "name": "impl", "type": "codeblock", "score": 3.3213610649108887, "line": 36, "text": "\"\"\"\nCONFIGURING API_REFERENCE\n=========================\n\nAPI_REFERENCE maps each module name to a dictionary that consists of the following\ncomponents:\n\nshort_summary (required)\n    The text to be printed on the index page; it has nothing to do the API reference\n    page of each module.\ndescription (required, `None` if not needed)\n    The additional description for the module to be placed under the module\n    docstring, before the sections start.\nsections (required)\n    A list of sections, each of which consists of:\n    - title (required, `None` if not needed): the section title, commonly it should\n      not be `None` except for the first section of a module,\n    - description (optional): the optional additional description for the section,\n    - autosummary (required): an autosummary block, assuming current module is the\n      current module name.\n\nEssentially, the rendered page would look like the following:\n\n|---------------------------------------------------------------------------------|\n|     {{ module_name }}                                                           |\n|     =================                                                           |\n|     {{ module_docstring }}                                                      |\n|     {{ description }}                                                           |\n|                                                                                 |\n|     {{ section_title_1 }}   <-------------- Optional if one wants the first     |\n|     ---------------------                   section to directly follow          |\n|     {{ section_description_1 }}             without a second-level heading.     |\n|     {{ section_autosummary_1 }}                                                 |\n|                                                                                 |\n|     {{ section_title_2 }}                                                       |\n|     ---------------------                                                       |\n|     {{ section_description_2 }}                                                 |\n|     {{ section_autosummary_2 }}                                                 |\n|                                                                                 |\n|     More sections...                                                            |\n|---------------------------------------------------------------------------------|\n\nHooks will be automatically generated for each module and each section. For a module,\ne.g., `sklearn.feature_extraction`, the hook would be `feature_extraction_ref`; for a\nsection, e.g., \"From text\" under `sklearn.feature_extraction`, the hook would be\n`feature_extraction_ref-from-text`. However, note that a better way is to refer using\nthe :mod: directive, e.g., :mod:`sklearn.feature_extraction` for the module and\n:mod:`sklearn.feature_extraction.text` for the section. Only in case that a section\nis not a particular submodule does the hook become useful, e.g., the \"Loaders\" section\nunder `sklearn.datasets`.\n\"\"\"\n\nAPI_REFERENCE =\n # ... other code"}], "total_results": 10}
{"repo": "scikit-learn", "query": "RidgeClassifierCV cross-validation logic", "top_10": [{"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 7.0935378074646, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.08987283706665, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeCV", "type": "codeblock", "score": 4.929405212402344, "line": 2612, "text": "class RidgeCV(MultiOutputMixin, RegressorMixin, _BaseRidgeCV):\n    \"\"\"Ridge regression with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs efficient Leave-One-Out Cross-Validation.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`coefficient of determination <r2_score>` (:math:`R^2`) otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used, else,\n        :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    gcv_mode : {'auto', 'svd', 'eigen'}, default='auto'\n        Flag indicating which strategy to use when performing\n        Leave-One-Out Cross-Validation. Options are::\n\n            'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'\n            'svd' : force use of singular value decomposition of X when X is\n                dense, eigenvalue decomposition of X^T.X when X is sparse.\n            'eigen' : force computation via eigendecomposition of X.X^T\n\n        The 'auto' mode is the default and is intended to pick the cheaper\n        option of the two depending on the shape of the training data.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation values corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    alpha_per_target : bool, default=False\n        Flag indicating whether to optimize the alpha value (picked from the\n        `alphas` parameter list) for each target separately (for multi-output\n        settings: multiple prediction targets). When set to `True`, after\n        fitting, the `alpha_` attribute will contain a value for each target.\n        When set to `False`, a single alpha is used for all targets.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_alphas) or \\\n            shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation values for each alpha (only available if\n        ``store_cv_results=True`` and ``cv=None``). After ``fit()`` has been\n        called, this attribute will contain the mean squared errors if\n        `scoring is None` otherwise it will contain standardized per point\n        prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (n_features) or (n_targets, n_features)\n        Weight vector(s).\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float or ndarray of shape (n_targets,)\n        Estimated regularization parameter, or, if ``alpha_per_target=True``,\n        the estimated regularization parameter for each target.\n\n    best_score_ : float or ndarray of shape (n_targets,)\n        Score of base estimator with best alpha, or, if\n        ``alpha_per_target=True``, a score for each target.\n\n        .. versionadded:: 0.23\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Classifier based on ridge regression on {-1, 1} labels.\n    RidgeClassifierCV : Ridge classifier with built-in cross validation.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_diabetes\n    >>> from sklearn.linear_model import RidgeCV\n    >>> X, y = load_diabetes(return_X_y=True)\n    >>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.5166...\n    \"\"\""}, {"file": "sklearn/model_selection/_split.py", "name": "check_cv", "type": "codeblock", "score": 3.7881340980529785, "line": 2689, "text": "def check_cv(cv=5, y=None, *, classifier=False):\n    \"\"\"Input checker utility for building a cross-validator.\n\n    Parameters\n    ----------\n    cv : int, cross-validation generator, iterable or None, default=5\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n        - None, to use the default 5-fold cross validation,\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable that generates (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if classifier is True and ``y`` is either\n        binary or multiclass, :class:`StratifiedKFold` is used. In all other\n        cases, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value changed from 3-fold to 5-fold.\n\n    y : array-like, default=None\n        The target variable for supervised learning problems.\n\n    classifier : bool, default=False\n        Whether the task is a classification task, in which case\n        stratified KFold will be used.\n\n    Returns\n    -------\n    checked_cv : a cross-validator instance.\n        The return value is a cross-validator which generates the train/test\n        splits via the ``split`` method.\n\n    Examples\n    --------\n    >>> from sklearn.model_selection import check_cv\n    >>> check_cv(cv=5, y=None, classifier=False)\n    KFold(...)\n    >>> check_cv(cv=5, y=[1, 1, 0, 0, 0, 0], classifier=True)\n    StratifiedKFold(...)\n    \"\"\"\n    cv = 5 if cv is None else cv\n    if isinstance(cv, numbers.Integral):\n        if (\n            classifier\n            and (y is not None)\n            and (type_of_target(y, input_name=\"y\") in (\"binary\", \"multiclass\"))\n        ):\n            return StratifiedKFold(cv)\n        else:\n            return KFold(cv)\n\n    if not hasattr(cv, \"split\") or isinstance(cv, str):\n        if not isinstance(cv, Iterable) or isinstance(cv, str):\n            raise ValueError(\n                \"Expected cv as an integer, cross-validation \"\n                \"object (from sklearn.model_selection) \"\n                \"or an iterable. Got %s.\" % cv\n            )\n        return _CVIterableWrapper(cv)\n\n    return cv  # New style cv objects are passed without any modification"}, {"file": "examples/model_selection/plot_cv_indices.py", "name": "impl:23", "type": "codeblock", "score": 3.687734603881836, "line": 149, "text": "# %%\n# Let's see how it looks for the :class:`~sklearn.model_selection.KFold`\n# cross-validation object:\n\nfig, ax = plt.subplots()\ncv = KFold(n_splits)\nplot_cv_indices(cv, X, y, groups, ax, n_splits)\n\n# %%\n# As you can see, by default the KFold cross-validation iterator does not\n# take either datapoint class or group into consideration. We can change this\n# by using either:\n#\n# - ``StratifiedKFold`` to preserve the percentage of samples for each class.\n# - ``GroupKFold`` to ensure that the same group will not appear in two\n#   different folds.\n# - ``StratifiedGroupKFold`` to keep the constraint of ``GroupKFold`` while\n#   attempting to return stratified folds.\ncvs = [StratifiedKFold, GroupKFold, StratifiedGroupKFold]\n\nfor cv in cvs:\n    fig, ax = plt.subplots(figsize=(6, 3))\n    plot_cv_indices(cv(n_splits), X, y, groups, ax, n_splits)\n    ax.legend(\n        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n        [\"Testing set\", \"Training set\"],\n        loc=(1.02, 0.8),\n    )\n    # Make the legend fit\n    plt.tight_layout()\n    fig.subplots_adjust(right=0.7)\n\n# %%\n# Next we'll visualize this behavior for a number of CV iterators.\n#\n# Visualize cross-validation indices for many CV objects\n# ------------------------------------------------------\n#\n# Let's visually compare the cross validation behavior for many\n# scikit-learn cross-validation objects. Below we will loop through several\n# common cross-validation objects, visualizing the behavior of each.\n#\n# Note how some use the group/class information while others do not.\n\ncvs = [\n    KFold,\n    GroupKFold,\n    ShuffleSplit,\n    StratifiedKFold,\n    StratifiedGroupKFold,\n    GroupShuffleSplit,\n    StratifiedShuffleSplit,\n    TimeSeriesSplit,\n]"}, {"file": "sklearn/linear_model/_omp.py", "name": "OrthogonalMatchingPursuitCV", "type": "codeblock", "score": 3.682440996170044, "line": 901, "text": "class OrthogonalMatchingPursuitCV(RegressorMixin, LinearModel):\n    \"\"\"Cross-validated Orthogonal Matching Pursuit model (OMP).\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    Read more in the :ref:`User Guide <omp>`.\n\n    Parameters\n    ----------\n    copy : bool, default=True\n        Whether the design matrix X must be copied by the algorithm. A false\n        value is only helpful if X is already Fortran-ordered, otherwise a\n        copy is made anyway.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    max_iter : int, default=None\n        Maximum numbers of iterations to perform, therefore maximum features\n        to include. 10% of ``n_features`` but at least 5 if available.\n\n    cv : int, cross-validation generator or iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross-validation,\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value if None changed from 3-fold to 5-fold.\n\n    n_jobs : int, default=None\n        Number of CPUs to use during the cross validation.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    verbose : bool or int, default=False\n        Sets the verbosity amount.\n\n    Attributes\n    ----------\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function.\n\n    coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n        Parameter vector (w in the problem formulation).\n\n    n_nonzero_coefs_ : int\n        Estimated number of non-zero coefficients giving the best mean squared\n        error over the cross-validation folds.\n\n    n_iter_ : int or array-like\n        Number of active features across every target for the model refit with\n        the best hyperparameters got by cross-validating across all folds.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    orthogonal_mp : Solves n_targets Orthogonal Matching Pursuit problems.\n    orthogonal_mp_gram : Solves n_targets Orthogonal Matching Pursuit\n        problems using only the Gram matrix X.T * X and the product X.T * y.\n    lars_path : Compute Least Angle Regression or Lasso path using LARS algorithm.\n    Lars : Least Angle Regression model a.k.a. LAR.\n    LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n    OrthogonalMatchingPursuit : Orthogonal Matching Pursuit model (OMP).\n    LarsCV : Cross-validated Least Angle Regression model.\n    LassoLarsCV : Cross-validated Lasso model fit with Least Angle Regression.\n    sklearn.decomposition.sparse_encode : Generic sparse coding.\n        Each column of the result is the solution to a Lasso problem.\n\n    Notes\n    -----\n    In `fit`, once the optimal number of non-zero coefficients is found through\n    cross-validation, the model is fit again using the entire training set.\n\n    Examples\n    --------\n    >>> from sklearn.linear_model import OrthogonalMatchingPursuitCV\n    >>> from sklearn.datasets import make_regression\n    >>> X, y = make_regression(n_features=100, n_informative=10,\n    ...                        noise=4, random_state=0)\n    >>> reg = OrthogonalMatchingPursuitCV(cv=5).fit(X, y)\n    >>> reg.score(X, y)\n    0.9991\n    >>> reg.n_nonzero_coefs_\n    np.int64(10)\n    >>> reg.predict(X[:1,])\n    array([-78.3854])\n    \"\"\""}, {"file": "examples/developing_estimators/sklearn_is_fitted.py", "name": "CustomEstimator", "type": "codeblock", "score": 3.668843984603882, "line": 37, "text": "class CustomEstimator(BaseEstimator, ClassifierMixin):\n    def __init__(self, parameter=1):\n        self.parameter = parameter\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the estimator to the training data.\n        \"\"\"\n        self.classes_ = sorted(set(y))\n        # Custom attribute to track if the estimator is fitted\n        self._is_fitted = True\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Perform Predictions\n\n        If the estimator is not fitted, then raise NotFittedError\n        \"\"\"\n        check_is_fitted(self)\n        # Perform prediction logic\n        predictions = [self.classes_[0]] * len(X)\n        return predictions\n\n    def score(self, X, y):\n        \"\"\"\n        Calculate Score\n\n        If the estimator is not fitted, then raise NotFittedError\n        \"\"\"\n        check_is_fitted(self)\n        # Perform scoring logic\n        return 0.5\n\n    def __sklearn_is_fitted__(self):\n        \"\"\"\n        Check fitted status and return a Boolean value.\n        \"\"\"\n        return hasattr(self, \"_is_fitted\") and self._is_fitted"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 3.668154001235962, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV.fit", "type": "codeblock", "score": 3.566838502883911, "line": 2957, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        \"\"\"Fit Ridge classifier with cv.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features. When using GCV,\n            will be cast to float64 if necessary.\n\n        y : ndarray of shape (n_samples,)\n            Target values. Will be cast to X's dtype if necessary.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying scorer.\n\n            .. versionadded:: 1.5\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # `RidgeClassifier` does not accept \"sag\" or \"saga\" solver and thus support\n        # csr, csc, and coo sparse matrices. By using solver=\"eigen\" we force to accept\n        # all sparse format.\n        X, y, sample_weight, Y = self._prepare_data(X, y, sample_weight, solver=\"eigen\")\n\n        # If cv is None, gcv mode will be used and we used the binarized Y\n        # since y will not be binarized in _RidgeGCV estimator.\n        # If cv is not None, a GridSearchCV with some RidgeClassifier\n        # estimators are used where y will be binarized. Thus, we pass y\n        # instead of the binarized Y.\n        target = Y if self.cv is None else y\n        super().fit(X, target, sample_weight=sample_weight, **params)\n        return self"}, {"file": "sklearn/linear_model/_coordinate_descent.py", "name": "MultiTaskElasticNetCV", "type": "codeblock", "score": 3.4859585762023926, "line": 2926, "text": "class MultiTaskElasticNetCV(RegressorMixin, LinearModelCV):\n    \"\"\"Multi-task L1/L2 ElasticNet with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    The optimization objective for MultiTaskElasticNet is::\n\n        (1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n        + alpha * l1_ratio * ||W||_21\n        + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n\n    Where::\n\n        ||W||_21 = \\\\sum_i \\\\sqrt{\\\\sum_j w_{ij}^2}\n\n    i.e. the sum of norm of each row.\n\n    Read more in the :ref:`User Guide <multi_task_elastic_net>`.\n\n    .. versionadded:: 0.15\n\n    Parameters\n    ----------\n    l1_ratio : float or list of float, default=0.5\n        The ElasticNet mixing parameter, with 0 < l1_ratio <= 1.\n        For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it\n        is an L2 penalty.\n        For ``0 < l1_ratio < 1``, the penalty is a combination of L1/L2 and L2.\n        This parameter can be a list, in which case the different\n        values are tested by cross-validation and the one giving the best\n        prediction score is used. Note that a good choice of list of\n        values for l1_ratio is often to put more values close to 1\n        (i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,\n        .9, .95, .99, 1]``.\n\n    eps : float, default=1e-3\n        Length of the path. ``eps=1e-3`` means that\n        ``alpha_min / alpha_max = 1e-3``.\n\n    n_alphas : int, default=100\n        Number of alphas along the regularization path.\n\n        .. deprecated:: 1.7\n            `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`\n            instead.\n\n    alphas : array-like or int, default=None\n        Values of alphas to test along the regularization path, used for each l1_ratio.\n        If int, `alphas` values are generated automatically.\n        If array-like, list of alpha values to use.\n\n        .. versionchanged:: 1.7\n            `alphas` accepts an integer value which removes the need to pass\n            `n_alphas`.\n\n        .. deprecated:: 1.7\n            `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which\n            point the default value will be set to 100.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    max_iter : int, default=1000\n        The maximum number of iterations.\n\n    tol : float, default=1e-4\n        The tolerance for the optimization: if the updates are smaller or equal to\n        ``tol``, the optimization code checks the dual gap for optimality and continues\n        until it is smaller or equal to ``tol``.\n\n    cv : int, cross-validation generator or iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross-validation,\n        - int, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value if None changed from 3-fold to 5-fold.\n\n    copy_X : bool, default=True\n        If ``True``, X will be copied; else, it may be overwritten.\n\n    verbose : bool or int, default=0\n        Amount of verbosity.\n\n    n_jobs : int, default=None\n        Number of CPUs to use during the cross validation. Note that this is\n        used only if multiple values for l1_ratio are given.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    random_state : int, RandomState instance, default=None\n        The seed of the pseudo random number generator that selects a random\n        feature to update. Used when ``selection`` == 'random'.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    selection : {'cyclic', 'random'}, default='cyclic'\n        If set to 'random', a random coefficient is updated every iteration\n        rather than looping over features sequentially by default. This\n        (setting to 'random') often leads to significantly faster convergence\n        especially when tol is higher than 1e-4.\n\n    Attributes\n    ----------\n    intercept_ : ndarray of shape (n_targets,)\n        Independent term in decision function.\n\n    coef_ : ndarray of shape (n_targets, n_features)\n        Parameter vector (W in the cost function formula).\n        Note that ``coef_`` stores the transpose of ``W``, ``W.T``.\n\n    alpha_ : float\n        The amount of penalization chosen by cross validation.\n\n    mse_path_ : ndarray of shape (n_alphas, n_folds) or \\\n                (n_l1_ratio, n_alphas, n_folds)\n        Mean square error for the test set on each fold, varying alpha.\n\n    alphas_ : ndarray of shape (n_alphas,) or (n_l1_ratio, n_alphas)\n        The grid of alphas used for fitting, for each l1_ratio.\n\n    l1_ratio_ : float\n        Best l1_ratio obtained by cross-validation.\n\n    n_iter_ : int\n        Number of iterations run by the coordinate descent solver to reach\n        the specified tolerance for the optimal alpha.\n\n    dual_gap_ : float\n        The dual gap at the end of the optimization for the optimal alpha.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    MultiTaskElasticNet : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n    ElasticNetCV : Elastic net model with best model selection by\n        cross-validation.\n    MultiTaskLassoCV : Multi-task Lasso model trained with L1 norm\n        as regularizer and built-in cross-validation.\n\n    Notes\n    -----\n    The algorithm used to fit the model is coordinate descent.\n\n    In `fit`, once the best parameters `l1_ratio` and `alpha` are found through\n    cross-validation, the model is fit again using the entire training set.\n\n    To avoid unnecessary memory duplication the `X` and `y` arguments of the\n    `fit` method should be directly passed as Fortran-contiguous numpy arrays.\n\n    Examples\n    --------\n    >>> from sklearn import linear_model\n    >>> clf = linear_model.MultiTaskElasticNetCV(cv=3)\n    >>> clf.fit([[0,0], [1, 1], [2, 2]],\n    ...         [[0, 0], [1, 1], [2, 2]])\n    MultiTaskElasticNetCV(cv=3)\n    >>> print(clf.coef_)\n    [[0.51841231 0.479658]\n     [0.51841231 0.479658]]\n    >>> print(clf.intercept_)\n    [0.001929... 0.001929...]\n    \"\"\""}], "total_results": 10}
{"repo": "scikit-learn", "query": "multi_class option in RidgeClassifierCV", "top_10": [{"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.08987283706665, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 4.553342819213867, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "sklearn/linear_model/_logistic.py", "name": "LogisticRegression.fit", "type": "codeblock", "score": 4.056722164154053, "line": 1263, "text": "class LogisticRegression(LinearClassifierMixin, SparseCoefMixin, BaseEstimator):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None):\n        # ... other code\n        multi_class = self.multi_class\n        if self.multi_class == \"multinomial\" and len(self.classes_) == 2:\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. From then on, binary problems will be fit as proper binary \"\n                    \" logistic regression models (as if multi_class='ovr' were set).\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        elif self.multi_class in (\"multinomial\", \"auto\"):\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. From then on, it will always use 'multinomial'.\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        elif self.multi_class == \"ovr\":\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead.\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        else:\n            # Set to old default value.\n            multi_class = \"auto\"\n        multi_class = _check_multi_class(multi_class, solver, len(self.classes_))\n        # ... other code"}, {"file": "sklearn/linear_model/_logistic.py", "name": "_check_multi_class", "type": "codeblock", "score": 4.006529331207275, "line": 84, "text": "def _check_multi_class(multi_class, solver, n_classes):\n    \"\"\"Computes the multi class type, either \"multinomial\" or \"ovr\".\n\n    For `n_classes` > 2 and a solver that supports it, returns \"multinomial\".\n    For all other cases, in particular binary classification, return \"ovr\".\n    \"\"\"\n    if multi_class == \"auto\":\n        if solver in (\"liblinear\",):\n            multi_class = \"ovr\"\n        elif n_classes > 2:\n            multi_class = \"multinomial\"\n        else:\n            multi_class = \"ovr\"\n    if multi_class == \"multinomial\" and solver in (\"liblinear\",):\n        raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n    return multi_class"}, {"file": "sklearn/linear_model/_logistic.py", "name": "LogisticRegressionCV.fit", "type": "codeblock", "score": 3.999955654144287, "line": 1929, "text": "class LogisticRegressionCV(LogisticRegression, LinearClassifierMixin, BaseEstimator):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n\n        # Encode for string labels\n        label_encoder = LabelEncoder().fit(y)\n        y = label_encoder.transform(y)\n        if isinstance(class_weight, dict):\n            class_weight = {\n                label_encoder.transform([cls])[0]: v for cls, v in class_weight.items()\n            }\n\n        # The original class labels\n        classes = self.classes_ = label_encoder.classes_\n        encoded_labels = label_encoder.transform(label_encoder.classes_)\n\n        # TODO(1.8) remove multi_class\n        multi_class = self.multi_class\n        if self.multi_class == \"multinomial\" and len(self.classes_) == 2:\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. From then on, binary problems will be fit as proper binary \"\n                    \" logistic regression models (as if multi_class='ovr' were set).\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        elif self.multi_class in (\"multinomial\", \"auto\"):\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. From then on, it will always use 'multinomial'.\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        elif self.multi_class == \"ovr\":\n            warnings.warn(\n                (\n                    \"'multi_class' was deprecated in version 1.5 and will be removed in\"\n                    \" 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead.\"\n                    \" Leave it to its default value to avoid this warning.\"\n                ),\n                FutureWarning,\n            )\n        else:\n            # Set to old default value.\n            multi_class = \"auto\"\n        multi_class = _check_multi_class(multi_class, solver, len(classes))\n\n        if solver in [\"sag\", \"saga\"]:\n            max_squared_sum = row_norms(X, squared=True).max()\n        else:\n            max_squared_sum = None\n        # ... other code"}, {"file": "sklearn/metrics/_ranking.py", "name": "roc_auc_score", "type": "codeblock", "score": 3.870159149169922, "line": 491, "text": "@validate_params(\n    {\n        \"y_true\": [\"array-like\"],\n        \"y_score\": [\"array-like\"],\n        \"average\": [StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\"}), None],\n        \"sample_weight\": [\"array-like\", None],\n        \"max_fpr\": [Interval(Real, 0.0, 1, closed=\"right\"), None],\n        \"multi_class\": [StrOptions({\"raise\", \"ovr\", \"ovo\"})],\n        \"labels\": [\"array-like\", None],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef roc_auc_score(\n    y_true,\n    y_score,\n    *,\n    average=\"macro\",\n    sample_weight=None,\n    max_fpr=None,\n    multi_class=\"raise\",\n    labels=None,\n):\n    \"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\n    from prediction scores.\n\n    Note: this implementation can be used with binary, multiclass and\n    multilabel classification, but some restrictions apply (see Parameters).\n\n    Read more in the :ref:`User Guide <roc_metrics>`.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n        True labels or binary label indicators. The binary and multiclass cases\n        expect labels with shape (n_samples,) while the multilabel case expects\n        binary label indicators with shape (n_samples, n_classes).\n\n    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n        Target scores.\n\n        * In the binary case, it corresponds to an array of shape\n          `(n_samples,)`. Both probability estimates and non-thresholded\n          decision values can be provided. The probability estimates correspond\n          to the **probability of the class with the greater label**,\n          i.e. `estimator.classes_[1]` and thus\n          `estimator.predict_proba(X, y)[:, 1]`. The decision values\n          corresponds to the output of `estimator.decision_function(X, y)`.\n          See more information in the :ref:`User guide <roc_auc_binary>`;\n        * In the multiclass case, it corresponds to an array of shape\n          `(n_samples, n_classes)` of probability estimates provided by the\n          `predict_proba` method. The probability estimates **must**\n          sum to 1 across the possible classes. In addition, the order of the\n          class scores must correspond to the order of ``labels``,\n          if provided, or else to the numerical or lexicographical order of\n          the labels in ``y_true``. See more information in the\n          :ref:`User guide <roc_auc_multiclass>`;\n        * In the multilabel case, it corresponds to an array of shape\n          `(n_samples, n_classes)`. Probability estimates are provided by the\n          `predict_proba` method and the non-thresholded decision values by\n          the `decision_function` method. The probability estimates correspond\n          to the **probability of the class with the greater label for each\n          output** of the classifier. See more information in the\n          :ref:`User guide <roc_auc_multilabel>`.\n\n    average : {'micro', 'macro', 'samples', 'weighted'} or None, \\\n            default='macro'\n        If ``None``, the scores for each class are returned.\n        Otherwise, this determines the type of averaging performed on the data.\n        Note: multiclass ROC AUC currently only handles the 'macro' and\n        'weighted' averages. For multiclass targets, `average=None` is only\n        implemented for `multi_class='ovr'` and `average='micro'` is only\n        implemented for `multi_class='ovr'`.\n\n        ``'micro'``:\n            Calculate metrics globally by considering each element of the label\n            indicator matrix as a label.\n        ``'macro'``:\n            Calculate metrics for each label, and find their unweighted\n            mean.  This does not take label imbalance into account.\n        ``'weighted'``:\n            Calculate metrics for each label, and find their average, weighted\n            by support (the number of true instances for each label).\n        ``'samples'``:\n            Calculate metrics for each instance, and find their average.\n\n        Will be ignored when ``y_true`` is binary.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    max_fpr : float > 0 and <= 1, default=None\n        If not ``None``, the standardized partial AUC [2]_ over the range\n        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n        computation currently is not supported for multiclass.\n\n    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n        Only used for multiclass targets. Determines the type of configuration\n        to use. The default value raises an error, so either\n        ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n\n        ``'ovr'``:\n            Stands for One-vs-rest. Computes the AUC of each class\n            against the rest [3]_ [4]_. This\n            treats the multiclass case in the same way as the multilabel case.\n            Sensitive to class imbalance even when ``average == 'macro'``,\n            because class imbalance affects the composition of each of the\n            'rest' groupings.\n        ``'ovo'``:\n            Stands for One-vs-one. Computes the average AUC of all\n            possible pairwise combinations of classes [5]_.\n            Insensitive to class imbalance when\n            ``average == 'macro'``.\n\n    labels : array-like of shape (n_classes,), default=None\n        Only used for multiclass targets. List of labels that index the\n        classes in ``y_score``. If ``None``, the numerical or lexicographical\n        order of the labels in ``y_true`` is used.\n\n    Returns\n    -------\n    auc : float\n        Area Under the Curve score.\n\n    See Also\n    --------\n    average_precision_score : Area under the precision-recall curve.\n    roc_curve : Compute Receiver operating characteristic (ROC) curve.\n    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n        (ROC) curve given an estimator and some data.\n    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n        (ROC) curve given the true and predicted values.\n\n    Notes\n    -----\n    The Gini Coefficient is a summary measure of the ranking ability of binary\n    classifiers. It is expressed using the area under of the ROC as follows:\n\n    G = 2 * AUC - 1\n\n    Where G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation\n    will ensure that random guessing will yield a score of 0 in expectation, and it is\n    upper bounded by 1.\n\n    References\n    ----------\n    .. [1] `Wikipedia entry for the Receiver operating characteristic\n            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n\n    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n\n    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n           probability estimation trees (Section 6.2), CeDER Working Paper\n           #IS-00-04, Stern School of Business, New York University.\n\n    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n            Recognition Letters, 27(8), 861-874.\n            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n\n    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n            Under the ROC Curve for Multiple Class Classification Problems.\n            Machine Learning, 45(2), 171-186.\n            <http://link.springer.com/article/10.1023/A:1010920819831>`_\n    .. [6] `Wikipedia entry for the Gini coefficient\n            <https://en.wikipedia.org/wiki/Gini_coefficient>`_\n\n    Examples\n    --------\n    Binary case:\n\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.metrics import roc_auc_score\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\", random_state=0).fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n    0.99\n    >>> roc_auc_score(y, clf.decision_function(X))\n    0.99\n\n    Multiclass case:\n\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\").fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n    0.99\n\n    Multilabel case:\n\n    >>> import numpy as np\n    >>> from sklearn.datasets import make_multilabel_classification\n    >>> from sklearn.multioutput import MultiOutputClassifier\n    >>> X, y = make_multilabel_classification(random_state=0)\n    >>> clf = MultiOutputClassifier(clf).fit(X, y)\n    >>> # get a list of n_output containing probability arrays of shape\n    >>> # (n_samples, n_classes)\n    >>> y_score = clf.predict_proba(X)\n    >>> # extract the positive columns for each output\n    >>> y_score = np.transpose([score[:, 1] for score in y_score])\n    >>> roc_auc_score(y, y_score, average=None)\n    array([0.828, 0.852, 0.94, 0.869, 0.95])\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> clf = RidgeClassifierCV().fit(X, y)\n    >>> roc_auc_score(y, clf.decision_function(X), average=None)\n    array([0.82, 0.847, 0.93, 0.872, 0.944])\n    \"\"\"\n    # ... other code"}, {"file": "sklearn/linear_model/_logistic.py", "name": "_log_reg_scoring_path", "type": "codeblock", "score": 3.8451192378997803, "line": 759, "text": "def _log_reg_scoring_path(\n    X,\n    y,\n    train,\n    test,\n    *,\n    pos_class,\n    Cs,\n    scoring,\n    fit_intercept,\n    max_iter,\n    tol,\n    class_weight,\n    verbose,\n    solver,\n    penalty,\n    dual,\n    intercept_scaling,\n    multi_class,\n    random_state,\n    max_squared_sum,\n    sample_weight,\n    l1_ratio,\n    score_params,\n):\n    X_train = X[train]\n    X_test = X[test]\n    y_train = y[train]\n    y_test = y[test]\n\n    sw_train, sw_test = None, None\n    if sample_weight is not None:\n        sample_weight = _check_sample_weight(sample_weight, X)\n        sw_train = sample_weight[train]\n        sw_test = sample_weight[test]\n\n    coefs, Cs, n_iter = _logistic_regression_path(\n        X_train,\n        y_train,\n        Cs=Cs,\n        l1_ratio=l1_ratio,\n        fit_intercept=fit_intercept,\n        solver=solver,\n        max_iter=max_iter,\n        class_weight=class_weight,\n        pos_class=pos_class,\n        multi_class=multi_class,\n        tol=tol,\n        verbose=verbose,\n        dual=dual,\n        penalty=penalty,\n        intercept_scaling=intercept_scaling,\n        random_state=random_state,\n        check_input=False,\n        max_squared_sum=max_squared_sum,\n        sample_weight=sw_train,\n    )\n\n    log_reg = LogisticRegression(solver=solver, multi_class=multi_class)\n\n    # The score method of Logistic Regression has a classes_ attribute.\n    if multi_class == \"ovr\":\n        log_reg.classes_ = np.array([-1, 1])\n    elif multi_class == \"multinomial\":\n        log_reg.classes_ = np.unique(y_train)\n    else:\n        raise ValueError(\n            \"multi_class should be either multinomial or ovr, got %d\" % multi_class\n        )\n\n    if pos_class is not None:\n        mask = y_test == pos_class\n        y_test = np.ones(y_test.shape, dtype=np.float64)\n        y_test[~mask] = -1.0\n\n    scores = list()\n\n    scoring = get_scorer(scoring)\n    # ... other code"}, {"file": "sklearn/metrics/_ranking.py", "name": "_multiclass_roc_auc_score", "type": "codeblock", "score": 3.7179222106933594, "line": 782, "text": "def _multiclass_roc_auc_score(\n    y_true, y_score, labels, multi_class, average, sample_weight\n):\n    # ... other code\n\n    multiclass_options = (\"ovo\", \"ovr\")\n    if multi_class not in multiclass_options:\n        raise ValueError(\n            \"multi_class='{0}' is not supported \"\n            \"for multiclass ROC AUC, multi_class must be \"\n            \"in {1}\".format(multi_class, multiclass_options)\n        )\n\n    if average is None and multi_class == \"ovo\":\n        raise NotImplementedError(\n            \"average=None is not implemented for multi_class='ovo'.\"\n        )\n\n    if labels is not None:\n        labels = column_or_1d(labels)\n        classes = _unique(labels)\n        if len(classes) != len(labels):\n            raise ValueError(\"Parameter 'labels' must be unique\")\n        if not np.array_equal(classes, labels):\n            raise ValueError(\"Parameter 'labels' must be ordered\")\n        if len(classes) != y_score.shape[1]:\n            raise ValueError(\n                \"Number of given labels, {0}, not equal to the number \"\n                \"of columns in 'y_score', {1}\".format(len(classes), y_score.shape[1])\n            )\n        if len(np.setdiff1d(y_true, classes)):\n            raise ValueError(\"'y_true' contains labels not in parameter 'labels'\")\n    else:\n        classes = _unique(y_true)\n        if len(classes) != y_score.shape[1]:\n            raise ValueError(\n                \"Number of classes in y_true not equal to the number of \"\n                \"columns in 'y_score'\"\n            )\n\n    if multi_class == \"ovo\":\n        if sample_weight is not None:\n            raise ValueError(\n                \"sample_weight is not supported \"\n                \"for multiclass one-vs-one ROC AUC, \"\n                \"'sample_weight' must be None in this case.\"\n            )\n        y_true_encoded = _encode(y_true, uniques=classes)\n        # Hand & Till (2001) implementation (ovo)\n        return _average_multiclass_ovo_score(\n            _binary_roc_auc_score, y_true_encoded, y_score, average=average\n        )\n    else:\n        # ovr is same as multi-label\n        y_true_multilabel = label_binarize(y_true, classes=classes)\n        return _average_binary_score(\n            _binary_roc_auc_score,\n            y_true_multilabel,\n            y_score,\n            average,\n            sample_weight=sample_weight,\n        )"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 3.668154001235962, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/svm/_base.py", "name": "_get_liblinear_solver_type", "type": "codeblock", "score": 3.657869577407837, "line": 1017, "text": "def _get_liblinear_solver_type(multi_class, penalty, loss, dual):\n    \"\"\"Find the liblinear magic number for the solver.\n\n    This number depends on the values of the following attributes:\n      - multi_class\n      - penalty\n      - loss\n      - dual\n\n    The same number is also internally used by LibLinear to determine\n    which solver to use.\n    \"\"\"\n    # nested dicts containing level 1: available loss functions,\n    # level2: available penalties for the given loss function,\n    # level3: whether the dual solver is available for the specified\n    # combination of loss function and penalty\n    _solver_type_dict = {\n        \"logistic_regression\": {\"l1\": {False: 6}, \"l2\": {False: 0, True: 7}},\n        \"hinge\": {\"l2\": {True: 3}},\n        \"squared_hinge\": {\"l1\": {False: 5}, \"l2\": {False: 2, True: 1}},\n        \"epsilon_insensitive\": {\"l2\": {True: 13}},\n        \"squared_epsilon_insensitive\": {\"l2\": {False: 11, True: 12}},\n        \"crammer_singer\": 4,\n    }\n\n    if multi_class == \"crammer_singer\":\n        return _solver_type_dict[multi_class]\n    elif multi_class != \"ovr\":\n        raise ValueError(\n            \"`multi_class` must be one of `ovr`, `crammer_singer`, got %r\" % multi_class\n        )\n\n    _solver_pen = _solver_type_dict.get(loss, None)\n    if _solver_pen is None:\n        error_string = \"loss='%s' is not supported\" % loss\n    else:\n        _solver_dual = _solver_pen.get(penalty, None)\n        if _solver_dual is None:\n            error_string = (\n                \"The combination of penalty='%s' and loss='%s' is not supported\"\n                % (penalty, loss)\n            )\n        else:\n            solver_num = _solver_dual.get(dual, None)\n            if solver_num is None:\n                error_string = (\n                    \"The combination of penalty='%s' and \"\n                    \"loss='%s' are not supported when dual=%s\" % (penalty, loss, dual)\n                )\n            else:\n                return solver_num\n    raise ValueError(\n        \"Unsupported set of arguments: %s, Parameters: penalty=%r, loss=%r, dual=%r\"\n        % (error_string, penalty, loss, dual)\n    )"}], "total_results": 10}
{"repo": "scikit-learn", "query": "decision_function of RidgeClassifierCV", "top_10": [{"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.08987283706665, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 3.668154001235962, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV.fit", "type": "codeblock", "score": 3.566838502883911, "line": 2957, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        \"\"\"Fit Ridge classifier with cv.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features. When using GCV,\n            will be cast to float64 if necessary.\n\n        y : ndarray of shape (n_samples,)\n            Target values. Will be cast to X's dtype if necessary.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying scorer.\n\n            .. versionadded:: 1.5\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # `RidgeClassifier` does not accept \"sag\" or \"saga\" solver and thus support\n        # csr, csc, and coo sparse matrices. By using solver=\"eigen\" we force to accept\n        # all sparse format.\n        X, y, sample_weight, Y = self._prepare_data(X, y, sample_weight, solver=\"eigen\")\n\n        # If cv is None, gcv mode will be used and we used the binarized Y\n        # since y will not be binarized in _RidgeGCV estimator.\n        # If cv is not None, a GridSearchCV with some RidgeClassifier\n        # estimators are used where y will be binarized. Thus, we pass y\n        # instead of the binarized Y.\n        target = Y if self.cv is None else y\n        super().fit(X, target, sample_weight=sample_weight, **params)\n        return self"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 3.3778202533721924, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "sklearn/metrics/_ranking.py", "name": "roc_auc_score", "type": "codeblock", "score": 2.939268112182617, "line": 491, "text": "@validate_params(\n    {\n        \"y_true\": [\"array-like\"],\n        \"y_score\": [\"array-like\"],\n        \"average\": [StrOptions({\"micro\", \"macro\", \"samples\", \"weighted\"}), None],\n        \"sample_weight\": [\"array-like\", None],\n        \"max_fpr\": [Interval(Real, 0.0, 1, closed=\"right\"), None],\n        \"multi_class\": [StrOptions({\"raise\", \"ovr\", \"ovo\"})],\n        \"labels\": [\"array-like\", None],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef roc_auc_score(\n    y_true,\n    y_score,\n    *,\n    average=\"macro\",\n    sample_weight=None,\n    max_fpr=None,\n    multi_class=\"raise\",\n    labels=None,\n):\n    \"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\n    from prediction scores.\n\n    Note: this implementation can be used with binary, multiclass and\n    multilabel classification, but some restrictions apply (see Parameters).\n\n    Read more in the :ref:`User Guide <roc_metrics>`.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n        True labels or binary label indicators. The binary and multiclass cases\n        expect labels with shape (n_samples,) while the multilabel case expects\n        binary label indicators with shape (n_samples, n_classes).\n\n    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n        Target scores.\n\n        * In the binary case, it corresponds to an array of shape\n          `(n_samples,)`. Both probability estimates and non-thresholded\n          decision values can be provided. The probability estimates correspond\n          to the **probability of the class with the greater label**,\n          i.e. `estimator.classes_[1]` and thus\n          `estimator.predict_proba(X, y)[:, 1]`. The decision values\n          corresponds to the output of `estimator.decision_function(X, y)`.\n          See more information in the :ref:`User guide <roc_auc_binary>`;\n        * In the multiclass case, it corresponds to an array of shape\n          `(n_samples, n_classes)` of probability estimates provided by the\n          `predict_proba` method. The probability estimates **must**\n          sum to 1 across the possible classes. In addition, the order of the\n          class scores must correspond to the order of ``labels``,\n          if provided, or else to the numerical or lexicographical order of\n          the labels in ``y_true``. See more information in the\n          :ref:`User guide <roc_auc_multiclass>`;\n        * In the multilabel case, it corresponds to an array of shape\n          `(n_samples, n_classes)`. Probability estimates are provided by the\n          `predict_proba` method and the non-thresholded decision values by\n          the `decision_function` method. The probability estimates correspond\n          to the **probability of the class with the greater label for each\n          output** of the classifier. See more information in the\n          :ref:`User guide <roc_auc_multilabel>`.\n\n    average : {'micro', 'macro', 'samples', 'weighted'} or None, \\\n            default='macro'\n        If ``None``, the scores for each class are returned.\n        Otherwise, this determines the type of averaging performed on the data.\n        Note: multiclass ROC AUC currently only handles the 'macro' and\n        'weighted' averages. For multiclass targets, `average=None` is only\n        implemented for `multi_class='ovr'` and `average='micro'` is only\n        implemented for `multi_class='ovr'`.\n\n        ``'micro'``:\n            Calculate metrics globally by considering each element of the label\n            indicator matrix as a label.\n        ``'macro'``:\n            Calculate metrics for each label, and find their unweighted\n            mean.  This does not take label imbalance into account.\n        ``'weighted'``:\n            Calculate metrics for each label, and find their average, weighted\n            by support (the number of true instances for each label).\n        ``'samples'``:\n            Calculate metrics for each instance, and find their average.\n\n        Will be ignored when ``y_true`` is binary.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    max_fpr : float > 0 and <= 1, default=None\n        If not ``None``, the standardized partial AUC [2]_ over the range\n        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n        computation currently is not supported for multiclass.\n\n    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n        Only used for multiclass targets. Determines the type of configuration\n        to use. The default value raises an error, so either\n        ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n\n        ``'ovr'``:\n            Stands for One-vs-rest. Computes the AUC of each class\n            against the rest [3]_ [4]_. This\n            treats the multiclass case in the same way as the multilabel case.\n            Sensitive to class imbalance even when ``average == 'macro'``,\n            because class imbalance affects the composition of each of the\n            'rest' groupings.\n        ``'ovo'``:\n            Stands for One-vs-one. Computes the average AUC of all\n            possible pairwise combinations of classes [5]_.\n            Insensitive to class imbalance when\n            ``average == 'macro'``.\n\n    labels : array-like of shape (n_classes,), default=None\n        Only used for multiclass targets. List of labels that index the\n        classes in ``y_score``. If ``None``, the numerical or lexicographical\n        order of the labels in ``y_true`` is used.\n\n    Returns\n    -------\n    auc : float\n        Area Under the Curve score.\n\n    See Also\n    --------\n    average_precision_score : Area under the precision-recall curve.\n    roc_curve : Compute Receiver operating characteristic (ROC) curve.\n    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n        (ROC) curve given an estimator and some data.\n    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n        (ROC) curve given the true and predicted values.\n\n    Notes\n    -----\n    The Gini Coefficient is a summary measure of the ranking ability of binary\n    classifiers. It is expressed using the area under of the ROC as follows:\n\n    G = 2 * AUC - 1\n\n    Where G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation\n    will ensure that random guessing will yield a score of 0 in expectation, and it is\n    upper bounded by 1.\n\n    References\n    ----------\n    .. [1] `Wikipedia entry for the Receiver operating characteristic\n            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n\n    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n\n    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n           probability estimation trees (Section 6.2), CeDER Working Paper\n           #IS-00-04, Stern School of Business, New York University.\n\n    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n            Recognition Letters, 27(8), 861-874.\n            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n\n    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n            Under the ROC Curve for Multiple Class Classification Problems.\n            Machine Learning, 45(2), 171-186.\n            <http://link.springer.com/article/10.1023/A:1010920819831>`_\n    .. [6] `Wikipedia entry for the Gini coefficient\n            <https://en.wikipedia.org/wiki/Gini_coefficient>`_\n\n    Examples\n    --------\n    Binary case:\n\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.metrics import roc_auc_score\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\", random_state=0).fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n    0.99\n    >>> roc_auc_score(y, clf.decision_function(X))\n    0.99\n\n    Multiclass case:\n\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> clf = LogisticRegression(solver=\"newton-cholesky\").fit(X, y)\n    >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n    0.99\n\n    Multilabel case:\n\n    >>> import numpy as np\n    >>> from sklearn.datasets import make_multilabel_classification\n    >>> from sklearn.multioutput import MultiOutputClassifier\n    >>> X, y = make_multilabel_classification(random_state=0)\n    >>> clf = MultiOutputClassifier(clf).fit(X, y)\n    >>> # get a list of n_output containing probability arrays of shape\n    >>> # (n_samples, n_classes)\n    >>> y_score = clf.predict_proba(X)\n    >>> # extract the positive columns for each output\n    >>> y_score = np.transpose([score[:, 1] for score in y_score])\n    >>> roc_auc_score(y, y_score, average=None)\n    array([0.828, 0.852, 0.94, 0.869, 0.95])\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> clf = RidgeClassifierCV().fit(X, y)\n    >>> roc_auc_score(y, clf.decision_function(X), average=None)\n    array([0.82, 0.847, 0.93, 0.872, 0.944])\n    \"\"\"\n    # ... other code"}, {"file": "sklearn/pipeline.py", "name": "Pipeline.decision_function", "type": "codeblock", "score": 2.897594928741455, "line": 869, "text": "class Pipeline(_BaseComposition):\n\n    @available_if(_final_estimator_has(\"decision_function\"))\n    def decision_function(self, X, **params):\n        \"\"\"Transform the data, and apply `decision_function` with the final estimator.\n\n        Call `transform` of each transformer in the pipeline. The transformed\n        data are finally passed to the final estimator that calls\n        `decision_function` method. Only valid if the final estimator\n        implements `decision_function`.\n\n        Parameters\n        ----------\n        X : iterable\n            Data to predict on. Must fulfill input requirements of first step\n            of the pipeline.\n\n        **params : dict of string -> object\n            Parameters requested and accepted by steps. Each step must have\n            requested certain metadata for these parameters to be forwarded to\n            them.\n\n            .. versionadded:: 1.4\n                Only available if `enable_metadata_routing=True`. See\n                :ref:`Metadata Routing User Guide <metadata_routing>` for more\n                details.\n\n        Returns\n        -------\n        y_score : ndarray of shape (n_samples, n_classes)\n            Result of calling `decision_function` on the final estimator.\n        \"\"\"\n        check_is_fitted(self)\n        _raise_for_params(params, self, \"decision_function\")\n\n        # not branching here since params is only available if\n        # enable_metadata_routing=True\n        routed_params = process_routing(self, \"decision_function\", **params)\n\n        Xt = X\n        for _, name, transform in self._iter(with_final=False):\n            Xt = transform.transform(\n                Xt, **routed_params.get(name, {}).get(\"transform\", {})\n            )\n        return self.steps[-1][1].decision_function(\n            Xt,\n            **routed_params.get(self.steps[-1][0], {}).get(\"decision_function\", {}),\n        )"}, {"file": "sklearn/semi_supervised/_self_training.py", "name": "SelfTrainingClassifier.decision_function", "type": "codeblock", "score": 2.8875439167022705, "line": 412, "text": "class SelfTrainingClassifier(ClassifierMixin, MetaEstimatorMixin, BaseEstimator):\n\n    @available_if(_estimator_has(\"decision_function\"))\n    def decision_function(self, X, **params):\n        \"\"\"Call decision function of the `estimator`.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Array representing the data.\n\n        **params : dict of str -> object\n            Parameters to pass to the underlying estimator's\n            ``decision_function`` method.\n\n            .. versionadded:: 1.6\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        y : ndarray of shape (n_samples, n_features)\n            Result of the decision function of the `estimator`.\n        \"\"\"\n        check_is_fitted(self)\n        _raise_for_params(params, self, \"decision_function\")\n\n        if _routing_enabled():\n            # metadata routing is enabled.\n            routed_params = process_routing(self, \"decision_function\", **params)\n        else:\n            routed_params = Bunch(estimator=Bunch(decision_function={}))\n\n        X = validate_data(\n            self,\n            X,\n            accept_sparse=True,\n            ensure_all_finite=False,\n            reset=False,\n        )\n        return self.estimator_.decision_function(\n            X, **routed_params.estimator.decision_function\n        )"}, {"file": "sklearn/model_selection/_search.py", "name": "BaseSearchCV.decision_function", "type": "codeblock", "score": 2.85288405418396, "line": 648, "text": "class BaseSearchCV(MetaEstimatorMixin, BaseEstimator, metaclass=ABCMeta):\n\n    @available_if(_search_estimator_has(\"decision_function\"))\n    def decision_function(self, X):\n        \"\"\"Call decision_function on the estimator with the best found parameters.\n\n        Only available if ``refit=True`` and the underlying estimator supports\n        ``decision_function``.\n\n        Parameters\n        ----------\n        X : indexable, length n_samples\n            Must fulfill the input assumptions of the\n            underlying estimator.\n\n        Returns\n        -------\n        y_score : ndarray of shape (n_samples,) or (n_samples, n_classes) \\\n                or (n_samples, n_classes * (n_classes-1) / 2)\n            Result of the decision function for `X` based on the estimator with\n            the best found parameters.\n        \"\"\"\n        check_is_fitted(self)\n        return self.best_estimator_.decision_function(X)"}, {"file": "sklearn/multioutput.py", "name": "ClassifierChain.decision_function", "type": "codeblock", "score": 2.8511719703674316, "line": 1120, "text": "class ClassifierChain(MetaEstimatorMixin, ClassifierMixin, _BaseChain):\n\n    @_available_if_base_estimator_has(\"decision_function\")\n    def decision_function(self, X):\n        \"\"\"Evaluate the decision_function of the models in the chain.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input data.\n\n        Returns\n        -------\n        Y_decision : array-like of shape (n_samples, n_classes)\n            Returns the decision function of the sample for each model\n            in the chain.\n        \"\"\"\n        return self._get_predictions(X, output_method=\"decision_function\")"}, {"file": "sklearn/multiclass.py", "name": "OneVsRestClassifier.decision_function", "type": "codeblock", "score": 2.846554756164551, "line": 564, "text": "class OneVsRestClassifier(\n    MultiOutputMixin,\n    ClassifierMixin,\n    MetaEstimatorMixin,\n    BaseEstimator,\n):\n\n    @available_if(_estimators_has(\"decision_function\"))\n    def decision_function(self, X):\n        \"\"\"Decision function for the OneVsRestClassifier.\n\n        Return the distance of each sample from the decision boundary for each\n        class. This can only be used with estimators which implement the\n        `decision_function` method.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input data.\n\n        Returns\n        -------\n        T : array-like of shape (n_samples, n_classes) or (n_samples,) for \\\n            binary classification.\n            Result of calling `decision_function` on the final estimator.\n\n            .. versionchanged:: 0.19\n                output shape changed to ``(n_samples,)`` to conform to\n                scikit-learn conventions for binary classification.\n        \"\"\"\n        check_is_fitted(self)\n        if len(self.estimators_) == 1:\n            return self.estimators_[0].decision_function(X)\n        return np.array(\n            [est.decision_function(X).ravel() for est in self.estimators_]\n        ).T"}], "total_results": 10}
{"repo": "scikit-learn", "query": "tests covering store_cv_values True", "top_10": [{"file": "sklearn/utils/estimator_checks.py", "name": "_enforce_estimator_tags_X", "type": "codeblock", "score": 4.106412887573242, "line": 3966, "text": "def _enforce_estimator_tags_X(estimator, X, X_test=None, kernel=linear_kernel):\n    # Estimators with `1darray` in `X_types` tag only accept\n    # X of shape (`n_samples`,)\n    if get_tags(estimator).input_tags.one_d_array:\n        X = X[:, 0]\n        if X_test is not None:\n            X_test = X_test[:, 0]  # pragma: no cover\n    # Estimators with a `requires_positive_X` tag only accept\n    # strictly positive data\n    if get_tags(estimator).input_tags.positive_only:\n        X = X - X.min()\n        if X_test is not None:\n            X_test = X_test - X_test.min()  # pragma: no cover\n    if get_tags(estimator).input_tags.categorical:\n        dtype = np.float64 if get_tags(estimator).input_tags.allow_nan else np.int32\n        X = np.round((X - X.min())).astype(dtype)\n        if X_test is not None:\n            X_test = np.round((X_test - X_test.min())).astype(dtype)  # pragma: no cover\n\n    if estimator.__class__.__name__ == \"SkewedChi2Sampler\":\n        # SkewedChi2Sampler requires X > -skewdness in transform\n        X = X - X.min()\n        if X_test is not None:\n            X_test = X_test - X_test.min()  # pragma: no cover\n\n    X_res = X\n\n    # Pairwise estimators only accept\n    # X of shape (`n_samples`, `n_samples`)\n    if _is_pairwise_metric(estimator):\n        X_res = pairwise_distances(X, metric=\"euclidean\")\n        if X_test is not None:\n            X_test = pairwise_distances(\n                X_test, X, metric=\"euclidean\"\n            )  # pragma: no cover\n    elif get_tags(estimator).input_tags.pairwise:\n        X_res = kernel(X, X)\n        if X_test is not None:\n            X_test = kernel(X_test, X)  # pragma: no cover\n    if X_test is not None:\n        return X_res, X_test\n    return X_res"}, {"file": "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py", "name": "BaseHistGradientBoosting._encode_y", "type": "codeblock", "score": 3.8974926471710205, "line": 1448, "text": "class BaseHistGradientBoosting(BaseEstimator, ABC):\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_nan = True\n        return tags\n\n    @abstractmethod\n    def _get_loss(self, sample_weight):\n        pass\n\n    @abstractmethod\n    def _encode_y(self, y=None):\n        pass  # pragma: no cover\n\n    @abstractmethod\n    def _encode_y_val(self, y=None):\n        pass  # pragma: no cover\n\n    @property\n    def n_iter_(self):\n        \"\"\"Number of iterations of the boosting process.\"\"\"\n        check_is_fitted(self)\n        return len(self._predictors)\n\n\nclass HistGradientBoostingRegressor(RegressorMixin, BaseHistGradientBoosting):"}, {"file": "sklearn/utils/estimator_checks.py", "name": "_check_set_output_transform_pandas_context", "type": "codeblock", "score": 3.7854905128479004, "line": 5223, "text": "def _check_set_output_transform_pandas_context(name, transformer_orig, context):\n    try:\n        import pandas as pd\n    except ImportError:  # pragma: no cover\n        raise SkipTest(\"pandas is not installed: not checking set output\")\n\n    _check_set_output_transform_dataframe(\n        name,\n        transformer_orig,\n        dataframe_lib=\"pandas\",\n        is_supported_dataframe=lambda X: isinstance(X, pd.DataFrame),\n        create_dataframe=lambda X, columns, index: pd.DataFrame(\n            X, columns=columns, copy=False, index=index\n        ),\n        assert_frame_equal=pd.testing.assert_frame_equal,\n        context=context,\n    )\n\n\ndef check_set_output_transform_pandas(name, transformer_orig):\n    _check_set_output_transform_pandas_context(name, transformer_orig, \"local\")\n\n\ndef check_global_output_transform_pandas(name, transformer_orig):\n    _check_set_output_transform_pandas_context(name, transformer_orig, \"global\")"}, {"file": "sklearn/utils/fixes.py", "name": "_in_unstable_openblas_configuration", "type": "codeblock", "score": 3.772732734680176, "line": 345, "text": "def _in_unstable_openblas_configuration():\n    \"\"\"Return True if in an unstable configuration for OpenBLAS\"\"\"\n\n    # Import libraries which might load OpenBLAS.\n    import numpy  # noqa: F401\n    import scipy  # noqa: F401\n\n    modules_info = _get_threadpool_controller().info()\n\n    open_blas_used = any(info[\"internal_api\"] == \"openblas\" for info in modules_info)\n    if not open_blas_used:\n        return False\n\n    # OpenBLAS 0.3.16 fixed instability for arm64, see:\n    # https://github.com/xianyi/OpenBLAS/blob/1b6db3dbba672b4f8af935bd43a1ff6cff4d20b7/Changelog.txt#L56-L58\n    openblas_arm64_stable_version = parse_version(\"0.3.16\")\n    for info in modules_info:\n        if info[\"internal_api\"] != \"openblas\":\n            continue\n        openblas_version = info.get(\"version\")\n        openblas_architecture = info.get(\"architecture\")\n        if openblas_version is None or openblas_architecture is None:\n            # Cannot be sure that OpenBLAS is good enough. Assume unstable:\n            return True  # pragma: no cover\n        if (\n            openblas_architecture == \"neoversen1\"\n            and parse_version(openblas_version) < openblas_arm64_stable_version\n        ):\n            # See discussions in https://github.com/numpy/numpy/issues/19411\n            return True  # pragma: no cover\n    return False"}, {"file": "sklearn/externals/array_api_extra/testing.py", "name": "docstring", "type": "codeblock", "score": 3.7055821418762207, "line": 1, "text": "\"\"\"\nPublic testing utilities.\n\nSee also _lib._testing for additional private testing utilities.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport enum\nimport warnings\nfrom collections.abc import Callable, Generator, Iterator, Sequence\nfrom functools import wraps\nfrom types import ModuleType\nfrom typing import TYPE_CHECKING, Any, ParamSpec, TypeVar, cast\n\nfrom ._lib._utils._compat import is_dask_namespace, is_jax_namespace\nfrom ._lib._utils._helpers import jax_autojit, pickle_flatten, pickle_unflatten\n\n__all__ = [\"lazy_xp_function\", \"patch_lazy_xp_functions\"]\n\nif TYPE_CHECKING:  # pragma: no cover\n    # TODO import override from typing (requires Python >=3.12)\n    import pytest\n    from dask.typing import Graph, Key, SchedulerGetCallable\n    from typing_extensions import override\n\nelse:\n    # Sphinx hacks\n    SchedulerGetCallable = object\n\n    def override(func):\n        return func\n\n\nP = ParamSpec(\"P\")\nT = TypeVar(\"T\")\n\n_ufuncs_tags: dict[object, dict[str, Any]] = {}\n\n\nclass Deprecated(enum.Enum):\n    \"\"\"Unique type for deprecated parameters.\"\"\"\n\n    DEPRECATED = 1\n\n\nDEPRECATED = Deprecated.DEPRECATED"}, {"file": "sklearn/utils/estimator_checks.py", "name": "check_set_output_transform_polars", "type": "codeblock", "score": 3.6367781162261963, "line": 5250, "text": "def _check_set_output_transform_polars_context(name, transformer_orig, context):\n    try:\n        import polars as pl\n        from polars.testing import assert_frame_equal\n    except ImportError:  # pragma: no cover\n        raise SkipTest(\"polars is not installed: not checking set output\")\n\n    def create_dataframe(X, columns, index):\n        if isinstance(columns, np.ndarray):\n            columns = columns.tolist()\n\n        return pl.DataFrame(X, schema=columns, orient=\"row\")\n\n    _check_set_output_transform_dataframe(\n        name,\n        transformer_orig,\n        dataframe_lib=\"polars\",\n        is_supported_dataframe=lambda X: isinstance(X, pl.DataFrame),\n        create_dataframe=create_dataframe,\n        assert_frame_equal=assert_frame_equal,\n        context=context,\n    )\n\n\ndef check_set_output_transform_polars(name, transformer_orig):\n    _check_set_output_transform_polars_context(name, transformer_orig, \"local\")\n\n\ndef check_global_set_output_transform_polars(name, transformer_orig):\n    _check_set_output_transform_polars_context(name, transformer_orig, \"global\")"}, {"file": "sklearn/utils/extmath.py", "name": "_randomized_eigsh", "type": "codeblock", "score": 3.4551126956939697, "line": 751, "text": "def _randomized_eigsh(\n    M,\n    n_components,\n    *,\n    n_oversamples=10,\n    n_iter=\"auto\",\n    power_iteration_normalizer=\"auto\",\n    selection=\"module\",\n    random_state=None,\n):\n    if selection == \"value\":  # pragma: no cover\n        # to do : an algorithm can be found in the Halko et al reference\n        raise NotImplementedError()\n\n    elif selection == \"module\":\n        # Note: no need for deterministic U and Vt (flip_sign=True),\n        # as we only use the dot product UVt afterwards\n        U, S, Vt = randomized_svd(\n            M,\n            n_components=n_components,\n            n_oversamples=n_oversamples,\n            n_iter=n_iter,\n            power_iteration_normalizer=power_iteration_normalizer,\n            flip_sign=False,\n            random_state=random_state,\n        )\n\n        eigvecs = U[:, :n_components]\n        eigvals = S[:n_components]\n\n        # Conversion of Singular values into Eigenvalues:\n        # For any eigenvalue t, the corresponding singular value is |t|.\n        # So if there is a negative eigenvalue t, the corresponding singular\n        # value will be -t, and the left (U) and right (V) singular vectors\n        # will have opposite signs.\n        # Fastest way: see <https://stackoverflow.com/a/61974002/7262247>\n        diag_VtU = np.einsum(\"ji,ij->j\", Vt[:n_components, :], U[:, :n_components])\n        signs = np.sign(diag_VtU)\n        eigvals = eigvals * signs\n\n    else:  # pragma: no cover\n        raise ValueError(\"Invalid `selection`: %r\" % selection)\n\n    return eigvals, eigvecs"}, {"file": "sklearn/datasets/_arff_parser.py", "name": "_pandas_arff_parser", "type": "codeblock", "score": 3.3827686309814453, "line": 375, "text": "def _pandas_arff_parser(\n    gzip_file,\n    output_arrays_type,\n    openml_columns_info,\n    feature_names_to_select,\n    target_names_to_select,\n    read_csv_kwargs=None,\n):\n    # ... other code\n    for name in openml_columns_info:\n        column_dtype = openml_columns_info[name][\"data_type\"]\n        if column_dtype.lower() == \"integer\":\n            # Use Int64 to infer missing values from data\n            # XXX: this line is not covered by our tests. Is this really needed?\n            dtypes[name] = \"Int64\"\n        elif column_dtype.lower() == \"nominal\":\n            dtypes[name] = \"category\"\n    # since we will not pass `names` when reading the ARFF file, we need to translate\n    # `dtypes` from column names to column indices to pass to `pandas.read_csv`\n    dtypes_positional = {\n        col_idx: dtypes[name]\n        for col_idx, name in enumerate(openml_columns_info)\n        if name in dtypes\n    }\n\n    default_read_csv_kwargs = {\n        \"header\": None,\n        \"index_col\": False,  # always force pandas to not use the first column as index\n        \"na_values\": [\"?\"],  # missing values are represented by `?`\n        \"keep_default_na\": False,  # only `?` is a missing value given the ARFF specs\n        \"comment\": \"%\",  # skip line starting by `%` since they are comments\n        \"quotechar\": '\"',  # delimiter to use for quoted strings\n        \"skipinitialspace\": True,  # skip spaces after delimiter to follow ARFF specs\n        \"escapechar\": \"\\\\\",\n        \"dtype\": dtypes_positional,\n    }\n    read_csv_kwargs = {**default_read_csv_kwargs, **(read_csv_kwargs or {})}\n    frame = pd.read_csv(gzip_file, **read_csv_kwargs)\n    # ... other code"}, {"file": "sklearn/ensemble/_base.py", "name": "_BaseHeterogeneousEnsemble.__sklearn_tags__", "type": "codeblock", "score": 3.151301860809326, "line": 297, "text": "class _BaseHeterogeneousEnsemble(\n    MetaEstimatorMixin, _BaseComposition, metaclass=ABCMeta\n):\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        try:\n            tags.input_tags.allow_nan = all(\n                get_tags(est[1]).input_tags.allow_nan if est[1] != \"drop\" else True\n                for est in self.estimators\n            )\n            tags.input_tags.sparse = all(\n                get_tags(est[1]).input_tags.sparse if est[1] != \"drop\" else True\n                for est in self.estimators\n            )\n        except Exception:\n            # If `estimators` does not comply with our API (list of tuples) then it will\n            # fail. In this case, we assume that `allow_nan` and `sparse` are False but\n            # the parameter validation will raise an error during `fit`.\n            pass  # pragma: no cover\n        return tags"}, {"file": "sklearn/model_selection/_split.py", "name": "TimeSeriesSplit", "type": "codeblock", "score": 3.1347768306732178, "line": 1108, "text": "class TimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator.\n\n    Provides train/test indices to split time-ordered data, where other\n    cross-validation methods are inappropriate, as they would lead to training\n    on future data and evaluating on past data.\n    To ensure comparable metrics across folds, samples must be equally spaced.\n    Once this condition is met, each test set covers the same time duration,\n    while the train set size accumulates data from previous splits.\n\n    This cross-validation object is a variation of :class:`KFold`.\n    In the k-th split, it returns the first k folds as the train set and the\n    (k+1)-th fold as the test set.\n\n    Note that, unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n\n    Read more in the :ref:`User Guide <time_series_split>`.\n\n    For visualisation of cross-validation behaviour and\n    comparison between common scikit-learn split methods\n    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`\n\n    .. versionadded:: 0.18\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n\n        .. versionchanged:: 0.22\n            ``n_splits`` default value changed from 3 to 5.\n\n    max_train_size : int, default=None\n        Maximum size for a single training set.\n\n    test_size : int, default=None\n        Used to limit the size of the test set. Defaults to\n        ``n_samples // (n_splits + 1)``, which is the maximum allowed value\n        with ``gap=0``.\n\n        .. versionadded:: 0.24\n\n    gap : int, default=0\n        Number of samples to exclude from the end of each train set before\n        the test set.\n\n        .. versionadded:: 0.24\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import TimeSeriesSplit\n    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> tscv = TimeSeriesSplit()\n    >>> print(tscv)\n    TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n    >>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n    ...     print(f\"Fold {i}:\")\n    ...     print(f\"  Train: index={train_index}\")\n    ...     print(f\"  Test:  index={test_index}\")\n    Fold 0:\n      Train: index=[0]\n      Test:  index=[1]\n    Fold 1:\n      Train: index=[0 1]\n      Test:  index=[2]\n    Fold 2:\n      Train: index=[0 1 2]\n      Test:  index=[3]\n    Fold 3:\n      Train: index=[0 1 2 3]\n      Test:  index=[4]\n    Fold 4:\n      Train: index=[0 1 2 3 4]\n      Test:  index=[5]\n    >>> # Fix test_size to 2 with 12 samples\n    >>> X = np.random.randn(12, 2)\n    >>> y = np.random.randint(0, 2, 12)\n    >>> tscv = TimeSeriesSplit(n_splits=3, test_size=2)\n    >>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n    ...     print(f\"Fold {i}:\")\n    ...     print(f\"  Train: index={train_index}\")\n    ...     print(f\"  Test:  index={test_index}\")\n    Fold 0:\n      Train: index=[0 1 2 3 4 5]\n      Test:  index=[6 7]\n    Fold 1:\n      Train: index=[0 1 2 3 4 5 6 7]\n      Test:  index=[8 9]\n    Fold 2:\n      Train: index=[0 1 2 3 4 5 6 7 8 9]\n      Test:  index=[10 11]\n    >>> # Add in a 2 period gap\n    >>> tscv = TimeSeriesSplit(n_splits=3, test_size=2, gap=2)\n    >>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n    ...     print(f\"Fold {i}:\")\n    ...     print(f\"  Train: index={train_index}\")\n    ...     print(f\"  Test:  index={test_index}\")\n    Fold 0:\n      Train: index=[0 1 2 3]\n      Test:  index=[6 7]\n    Fold 1:\n      Train: index=[0 1 2 3 4 5]\n      Test:  index=[8 9]\n    Fold 2:\n      Train: index=[0 1 2 3 4 5 6 7]\n      Test:  index=[10 11]\n\n    For a more extended example see\n    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`.\n\n    Notes\n    -----\n    The training set has size ``i * n_samples // (n_splits + 1)\n    + n_samples % (n_splits + 1)`` in the ``i`` th split,\n    with a test set of size ``n_samples//(n_splits + 1)`` by default,\n    where ``n_samples`` is the number of samples. Note that this\n    formula is only valid when ``test_size`` and ``max_train_size`` are\n    left to their default values.\n    \"\"\""}], "total_results": 10}
{"repo": "scikit-learn", "query": "RidgeCV vs RidgeClassifierCV difference", "top_10": [{"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 6.668328762054443, "line": 63, "text": "__all__ = [\n    \"ARDRegression\",\n    \"BayesianRidge\",\n    \"ElasticNet\",\n    \"ElasticNetCV\",\n    \"GammaRegressor\",\n    \"HuberRegressor\",\n    \"Lars\",\n    \"LarsCV\",\n    \"Lasso\",\n    \"LassoCV\",\n    \"LassoLars\",\n    \"LassoLarsCV\",\n    \"LassoLarsIC\",\n    \"LinearRegression\",\n    \"LogisticRegression\",\n    \"LogisticRegressionCV\",\n    \"MultiTaskElasticNet\",\n    \"MultiTaskElasticNetCV\",\n    \"MultiTaskLasso\",\n    \"MultiTaskLassoCV\",\n    \"OrthogonalMatchingPursuit\",\n    \"OrthogonalMatchingPursuitCV\",\n    \"PassiveAggressiveClassifier\",\n    \"PassiveAggressiveRegressor\",\n    \"Perceptron\",\n    \"PoissonRegressor\",\n    \"QuantileRegressor\",\n    \"RANSACRegressor\",\n    \"Ridge\",\n    \"RidgeCV\",\n    \"RidgeClassifier\",\n    \"RidgeClassifierCV\",\n    \"SGDClassifier\",\n    \"SGDOneClassSVM\",\n    \"SGDRegressor\",\n    \"TheilSenRegressor\",\n    \"TweedieRegressor\",\n    \"enet_path\",\n    \"lars_path\",\n    \"lars_path_gram\",\n    \"lasso_path\",\n    \"orthogonal_mp\",\n    \"orthogonal_mp_gram\",\n    \"ridge_regression\",\n]"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 5.08987283706665, "line": 2931, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    _parameter_constraints: dict = {\n        **_BaseRidgeCV._parameter_constraints,\n        \"class_weight\": [dict, StrOptions({\"balanced\"}), None],\n    }\n    for param in (\"gcv_mode\", \"alpha_per_target\"):\n        _parameter_constraints.pop(param)\n\n    def __init__(\n        self,\n        alphas=(0.1, 1.0, 10.0),\n        *,\n        fit_intercept=True,\n        scoring=None,\n        cv=None,\n        class_weight=None,\n        store_cv_results=False,\n    ):\n        super().__init__(\n            alphas=alphas,\n            fit_intercept=fit_intercept,\n            scoring=scoring,\n            cv=cv,\n            store_cv_results=store_cv_results,\n        )\n        self.class_weight = class_weight"}, {"file": "sklearn/linear_model/__init__.py", "name": "docstring", "type": "codeblock", "score": 5.088479042053223, "line": 1, "text": "\"\"\"A variety of linear models.\"\"\"\n\nfrom sklearn.linear_model._base import LinearRegression\nfrom sklearn.linear_model._bayes import ARDRegression, BayesianRidge\nfrom sklearn.linear_model._coordinate_descent import (\n    ElasticNet,\n    ElasticNetCV,\n    Lasso,\n    LassoCV,\n    MultiTaskElasticNet,\n    MultiTaskElasticNetCV,\n    MultiTaskLasso,\n    MultiTaskLassoCV,\n    enet_path,\n    lasso_path,\n)\nfrom sklearn.linear_model._glm import GammaRegressor, PoissonRegressor, TweedieRegressor\nfrom sklearn.linear_model._huber import HuberRegressor\nfrom sklearn.linear_model._least_angle import (\n    Lars,\n    LarsCV,\n    LassoLars,\n    LassoLarsCV,\n    LassoLarsIC,\n    lars_path,\n    lars_path_gram,\n)\nfrom sklearn.linear_model._logistic import LogisticRegression, LogisticRegressionCV\nfrom sklearn.linear_model._omp import (\n    OrthogonalMatchingPursuit,\n    OrthogonalMatchingPursuitCV,\n    orthogonal_mp,\n    orthogonal_mp_gram,\n)\nfrom sklearn.linear_model._passive_aggressive import (\n    PassiveAggressiveClassifier,\n    PassiveAggressiveRegressor,\n)\nfrom sklearn.linear_model._perceptron import Perceptron\nfrom sklearn.linear_model._quantile import QuantileRegressor\nfrom sklearn.linear_model._ransac import RANSACRegressor\nfrom sklearn.linear_model._ridge import (\n    Ridge,\n    RidgeClassifier,\n    RidgeClassifierCV,\n    RidgeCV,\n    ridge_regression,\n)\nfrom sklearn.linear_model._stochastic_gradient import (\n    SGDClassifier,\n    SGDOneClassSVM,\n    SGDRegressor,\n)\nfrom sklearn.linear_model._theil_sen import TheilSenRegressor"}, {"file": "examples/compose/plot_transformed_target.py", "name": "impl:53", "type": "codeblock", "score": 4.986040115356445, "line": 149, "text": "# #################\n#\n\n# %%\n\n# %%\n\n\n# %%\n\nax0.hist(y, bins=100, density=True)\nax0.set_ylabel(\"Probability\")\nax0.set_xlabel(\"Target\")\nax0.set_title(\"Target distribution\")\n\nax1.hist(y_trans, bins=100, density=True)\nax1.set_ylabel(\"Probability\")\nax1.set_xlabel(\"Target\")\nax1.set_title(\"Transformed target distribution\")\n\nf.suptitle(\"Ames housing data: selling price\", y=1.05)\nplt.tight_layout()\n\n# %%\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n# %%\n# The effect of the transformer is weaker than on the synthetic data. However,\n# the transformation results in an increase in :math:`R^2` and large decrease\n# of the MedAE. The residual plot (predicted target - true target vs predicted\n# target) without target transformation takes on a curved, 'reverse smile'\n# shape due to residual values that vary depending on the value of predicted\n# target. With target transformation, the shape is more linear indicating\n# better model fit.\nfrom sklearn.preprocessing import QuantileTransformer\n\nf, (ax0, ax1) = plt.subplots(2, 2, sharey=\"row\", figsize=(6.5, 8))\n\nridge_cv = RidgeCV().fit(X_train, y_train)\ny_pred_ridge = ridge_cv.predict(X_test)\n\nridge_cv_with_trans_target = TransformedTargetRegressor(\n    regressor=RidgeCV(),\n    transformer=QuantileTransformer(n_quantiles=900, output_distribution=\"normal\"),\n).fit(X_train, y_train)\ny_pred_ridge_with_trans_target = ridge_cv_with_trans_target.predict(X_test)\n\n# plot the actual vs predicted values\nPredictionErrorDisplay.from_predictions(\n    y_test,\n    y_pred_ridge,\n    kind=\"actual_vs_predicted\",\n    ax=ax0[0],\n    scatter_kwargs={\"alpha\": 0.5},\n)\nPredictionErrorDisplay.from_predictions(\n    y_test,\n    y_pred_ridge_with_trans_target,\n    kind=\"actual_vs_predicted\",\n    ax=ax0[1],\n    scatter_kwargs={\"alpha\": 0.5},\n)\n\n# Add the score in the legend of each axis"}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV", "type": "codeblock", "score": 4.515519142150879, "line": 2801, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n    \"\"\"Ridge classifier with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs Leave-One-Out Cross-Validation. Currently,\n    only the n_features > n_samples case is handled efficiently.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`accuracy <accuracy_score>` otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    class_weight : dict or 'balanced', default=None\n        Weights associated with classes in the form ``{class_label: weight}``.\n        If not given, all classes are supposed to have weight one.\n\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation results corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n        ``cv=None``). After ``fit()`` has been called, this attribute will\n        contain the mean squared errors if `scoring is None` otherwise it\n        will contain standardized per point prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n        Coefficient of the features in the decision function.\n\n        ``coef_`` is of shape (1, n_features) when the given problem is binary.\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float\n        Estimated regularization parameter.\n\n    best_score_ : float\n        Score of base estimator with best alpha.\n\n        .. versionadded:: 0.23\n\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Ridge classifier.\n    RidgeCV : Ridge regression with built-in cross validation.\n\n    Notes\n    -----\n    For multi-class classification, n_class classifiers are trained in\n    a one-versus-all approach. Concretely, this is implemented by taking\n    advantage of the multi-variate response support in Ridge.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.linear_model import RidgeClassifierCV\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.9630...\n    \"\"\""}, {"file": "examples/linear_model/plot_logistic_multinomial.py", "name": "plot_hyperplanes", "type": "codeblock", "score": 3.9171605110168457, "line": 134, "text": "# %%\n\n\n# %%\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n\nfor model, title, ax in [\n    (\n        logistic_regression_multinomial,\n        \"Multinomial Logistic Regression Hyperplanes\",\n        ax1,\n    ),\n    (logistic_regression_ovr, \"One-vs-Rest Logistic Regression Hyperplanes\", ax2),\n]:\n    hyperplane_handles, hyperplane_labels = plot_hyperplanes(model, X, ax)\n    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, edgecolor=\"k\")\n    scatter_handles, scatter_labels = scatter.legend_elements()\n\n    all_handles = hyperplane_handles + scatter_handles\n    all_labels = hyperplane_labels + scatter_labels\n\n    ax.legend(all_handles, all_labels, title=\"Classes\")\n    ax.set_title(title)\n\nplt.show()\n\n# %%\n# While the hyperplanes for classes 0 and 2 are quite similar between the two methods,\n# we observe that the hyperplane for class 1 is notably different. This difference stems\n# from the fundamental approaches of one-vs-rest and multinomial logistic regression:\n#\n# For one-vs-rest logistic regression:\n#\n# - Each hyperplane is determined independently by considering one class against all\n#   others.\n# - For class 1, the hyperplane represents the decision boundary that best separates\n#   class 1 from the combined classes 0 and 2.\n# - This binary approach can lead to simpler decision boundaries but may not capture\n#   complex relationships between all classes simultaneously.\n# - There is no possible interpretation of the conditional class probabilities.\n#\n# For multinomial logistic regression:\n#\n# - All hyperplanes are determined simultaneously, considering the relationships between\n#   all classes at once.\n# - The loss minimized by the model is a proper scoring rule, which means that the model\n#   is optimized to estimate the conditional class probabilities that are, therefore,\n#   meaningful.\n# - Each hyperplane represents the decision boundary where the probability of one class\n#   becomes higher than the others, based on the overall probability distribution.\n# - This approach can capture more nuanced relationships between classes, potentially\n#   leading to more accurate classification in multi-class problems.\n#\n# The difference in hyperplanes, especially for class 1, highlights how these methods\n# can produce different decision boundaries despite similar overall accuracy.\n#\n# In practice, using multinomial logistic regression is recommended since it minimizes a\n# well-formulated loss function, leading to better-calibrated class probabilities and\n# thus more interpretable results. When it comes to decision boundaries, one should\n# formulate a utility function to transform the class probabilities into a meaningful\n# quantity for the problem at hand. One-vs-rest allows for different decision boundaries\n# but does not allow for fine-grained control over the trade-off between the classes as\n# a utility function would."}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeCV", "type": "codeblock", "score": 3.8546664714813232, "line": 2612, "text": "class RidgeCV(MultiOutputMixin, RegressorMixin, _BaseRidgeCV):\n    \"\"\"Ridge regression with built-in cross-validation.\n\n    See glossary entry for :term:`cross-validation estimator`.\n\n    By default, it performs efficient Leave-One-Out Cross-Validation.\n\n    Read more in the :ref:`User Guide <ridge_regression>`.\n\n    Parameters\n    ----------\n    alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n        Array of alpha values to try.\n        Regularization strength; must be a positive float. Regularization\n        improves the conditioning of the problem and reduces the variance of\n        the estimates. Larger values specify stronger regularization.\n        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n        :class:`~sklearn.linear_model.LogisticRegression` or\n        :class:`~sklearn.svm.LinearSVC`.\n        If using Leave-One-Out cross-validation, alphas must be strictly positive.\n\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (i.e. data is expected to be centered).\n\n    scoring : str, callable, default=None\n        The scoring method to use for cross-validation. Options:\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: negative :ref:`mean squared error <mean_squared_error>` if cv is\n          None (i.e. when using leave-one-out cross-validation), or\n          :ref:`coefficient of determination <r2_score>` (:math:`R^2`) otherwise.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the efficient Leave-One-Out cross-validation\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used, else,\n        :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    gcv_mode : {'auto', 'svd', 'eigen'}, default='auto'\n        Flag indicating which strategy to use when performing\n        Leave-One-Out Cross-Validation. Options are::\n\n            'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'\n            'svd' : force use of singular value decomposition of X when X is\n                dense, eigenvalue decomposition of X^T.X when X is sparse.\n            'eigen' : force computation via eigendecomposition of X.X^T\n\n        The 'auto' mode is the default and is intended to pick the cheaper\n        option of the two depending on the shape of the training data.\n\n    store_cv_results : bool, default=False\n        Flag indicating if the cross-validation values corresponding to\n        each alpha should be stored in the ``cv_results_`` attribute (see\n        below). This flag is only compatible with ``cv=None`` (i.e. using\n        Leave-One-Out Cross-Validation).\n\n        .. versionchanged:: 1.5\n            Parameter name changed from `store_cv_values` to `store_cv_results`.\n\n    alpha_per_target : bool, default=False\n        Flag indicating whether to optimize the alpha value (picked from the\n        `alphas` parameter list) for each target separately (for multi-output\n        settings: multiple prediction targets). When set to `True`, after\n        fitting, the `alpha_` attribute will contain a value for each target.\n        When set to `False`, a single alpha is used for all targets.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    cv_results_ : ndarray of shape (n_samples, n_alphas) or \\\n            shape (n_samples, n_targets, n_alphas), optional\n        Cross-validation values for each alpha (only available if\n        ``store_cv_results=True`` and ``cv=None``). After ``fit()`` has been\n        called, this attribute will contain the mean squared errors if\n        `scoring is None` otherwise it will contain standardized per point\n        prediction values.\n\n        .. versionchanged:: 1.5\n            `cv_values_` changed to `cv_results_`.\n\n    coef_ : ndarray of shape (n_features) or (n_targets, n_features)\n        Weight vector(s).\n\n    intercept_ : float or ndarray of shape (n_targets,)\n        Independent term in decision function. Set to 0.0 if\n        ``fit_intercept = False``.\n\n    alpha_ : float or ndarray of shape (n_targets,)\n        Estimated regularization parameter, or, if ``alpha_per_target=True``,\n        the estimated regularization parameter for each target.\n\n    best_score_ : float or ndarray of shape (n_targets,)\n        Score of base estimator with best alpha, or, if\n        ``alpha_per_target=True``, a score for each target.\n\n        .. versionadded:: 0.23\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    Ridge : Ridge regression.\n    RidgeClassifier : Classifier based on ridge regression on {-1, 1} labels.\n    RidgeClassifierCV : Ridge classifier with built-in cross validation.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_diabetes\n    >>> from sklearn.linear_model import RidgeCV\n    >>> X, y = load_diabetes(return_X_y=True)\n    >>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n    >>> clf.score(X, y)\n    0.5166...\n    \"\"\""}, {"file": "examples/svm/plot_iris_svc.py", "name": "docstring", "type": "codeblock", "score": 3.8448004722595215, "line": 1, "text": "\"\"\"\n==================================================\nPlot different SVM classifiers in the iris dataset\n==================================================\n\nComparison of different linear SVM classifiers on a 2D projection of the iris\ndataset. We only consider the first 2 features of this dataset:\n\n- Sepal length\n- Sepal width\n\nThis example shows how to plot the decision surface for four SVM classifiers\nwith different kernels.\n\nThe linear models ``LinearSVC()`` and ``SVC(kernel='linear')`` yield slightly\ndifferent decision boundaries. This can be a consequence of the following\ndifferences:\n\n- ``LinearSVC`` minimizes the squared hinge loss while ``SVC`` minimizes the\n  regular hinge loss.\n\n- ``LinearSVC`` uses the One-vs-All (also known as One-vs-Rest) multiclass\n  reduction while ``SVC`` uses the One-vs-One multiclass reduction.\n\nBoth linear models have linear decision boundaries (intersecting hyperplanes)\nwhile the non-linear kernel models (polynomial or Gaussian RBF) have more\nflexible non-linear decision boundaries with shapes that depend on the kind of\nkernel and its parameters.\n\n.. NOTE:: while plotting the decision function of classifiers for toy 2D\n   datasets can help get an intuitive understanding of their respective\n   expressive power, be aware that those intuitions don't always generalize to\n   more realistic high-dimensional problems.\n\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import datasets, svm\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\n# import some data to play with\niris = datasets.load_iris()\n# Take the first two features. We could avoid this by using a two-dim dataset\nX = iris.data[:, :2]\ny = iris.target\n\n# we create an instance of SVM and fit out data. We do not scale our\n# data since we want to plot the support vectors\nC = 1.0  # SVM regularization parameter\nmodels = (\n    svm.SVC(kernel=\"linear\", C=C),\n    svm.LinearSVC(C=C, max_iter=10000),\n    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n)\nmodels = (clf.fit(X, y) for clf in models)\n\n# title for the plots"}, {"file": "examples/model_selection/plot_cv_predict.py", "name": "docstring", "type": "codeblock", "score": 3.591757297515869, "line": 1, "text": "\"\"\"\n====================================\nPlotting Cross-Validated Predictions\n====================================\n\nThis example shows how to use\n:func:`~sklearn.model_selection.cross_val_predict` together with\n:class:`~sklearn.metrics.PredictionErrorDisplay` to visualize prediction\nerrors.\n\"\"\"\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression\n\nX, y = load_diabetes(return_X_y=True)\nlr = LinearRegression()\n\n# %%\n# :func:`~sklearn.model_selection.cross_val_predict` returns an array of the\n# same size of `y` where each entry is a prediction obtained by cross\n# validation.\nfrom sklearn.model_selection import cross_val_predict\n\ny_pred = cross_val_predict(lr, X, y, cv=10)\n\n# %%\n# Since `cv=10`, it means that we trained 10 models and each model was\n# used to predict on one of the 10 folds. We can now use the\n# :class:`~sklearn.metrics.PredictionErrorDisplay` to visualize the\n# prediction errors.\n#\n# On the left axis, we plot the observed values :math:`y` vs. the predicted\n# values :math:`\\hat{y}` given by the models. On the right axis, we plot the\n# residuals (i.e. the difference between the observed values and the predicted\n# values) vs. the predicted values.\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import PredictionErrorDisplay\n\nfig, axs = plt.subplots(ncols=2, figsize=(8, 4))\nPredictionErrorDisplay.from_predictions(\n    y,\n    y_pred=y_pred,\n    kind=\"actual_vs_predicted\",\n    subsample=100,\n    ax=axs[0],\n    random_state=0,\n)\naxs[0].set_title(\"Actual vs. Predicted values\")\nPredictionErrorDisplay.from_predictions(\n    y,\n    y_pred=y_pred,\n    kind=\"residual_vs_predicted\",\n    subsample=100,\n    ax=axs[1],\n    random_state=0,\n)\naxs[1].set_title(\"Residuals vs. Predicted Values\")\nfig.suptitle(\"Plotting cross-validated predictions\")\nplt.tight_layout()\nplt.show()\n\n# %%\n# It is important to note that we used\n# :func:`~sklearn.model_selection.cross_val_predict` for visualization\n# purpose only in this example.\n#\n# It would be problematic to\n# quantitatively assess the model performance by computing a single\n# performance metric from the concatenated predictions returned by\n# :func:`~sklearn.model_selection.cross_val_predict`\n# when the different CV folds vary by size and distributions.\n#\n# It is recommended to compute per-fold performance metrics using:\n# :func:`~sklearn.model_selection.cross_val_score` or\n# :func:`~sklearn.model_selection.cross_validate` instead."}, {"file": "sklearn/linear_model/_ridge.py", "name": "RidgeClassifierCV.fit", "type": "codeblock", "score": 3.566838502883911, "line": 2957, "text": "class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        \"\"\"Fit Ridge classifier with cv.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features. When using GCV,\n            will be cast to float64 if necessary.\n\n        y : ndarray of shape (n_samples,)\n            Target values. Will be cast to X's dtype if necessary.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying scorer.\n\n            .. versionadded:: 1.5\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # `RidgeClassifier` does not accept \"sag\" or \"saga\" solver and thus support\n        # csr, csc, and coo sparse matrices. By using solver=\"eigen\" we force to accept\n        # all sparse format.\n        X, y, sample_weight, Y = self._prepare_data(X, y, sample_weight, solver=\"eigen\")\n\n        # If cv is None, gcv mode will be used and we used the binarized Y\n        # since y will not be binarized in _RidgeGCV estimator.\n        # If cv is not None, a GridSearchCV with some RidgeClassifier\n        # estimators are used where y will be binarized. Thus, we pass y\n        # instead of the binarized Y.\n        target = Y if self.cv is None else y\n        super().fit(X, target, sample_weight=sample_weight, **params)\n        return self"}], "total_results": 10}
{"repo": "scikit-learn", "query": "warning about cv_values memory", "top_10": [{"file": "sklearn/linear_model/_coordinate_descent.py", "name": "LinearModelCV.fit", "type": "codeblock", "score": 5.100305557250977, "line": 1660, "text": "class LinearModelCV(MultiOutputMixin, LinearModel, ABC):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None, **params):\n        # ... other code\n        if self.n_alphas == \"deprecated\":\n            self._alphas = 100\n        else:\n            warnings.warn(\n                \"'n_alphas' was deprecated in 1.7 and will be removed in 1.9. \"\n                \"'alphas' now accepts an integer value which removes the need to pass \"\n                \"'n_alphas'. The default value of 'alphas' will change from None to \"\n                \"100 in 1.9. Pass an explicit value to 'alphas' and leave 'n_alphas' \"\n                \"to its default value to silence this warning.\",\n                FutureWarning,\n            )\n            self._alphas = self.n_alphas\n\n        if isinstance(self.alphas, str) and self.alphas == \"warn\":\n            # - If self.n_alphas == \"deprecated\", both are left to their default values\n            #   so we don't warn since the future default behavior will be the same as\n            #   the current default behavior.\n            # - If self.n_alphas != \"deprecated\", then we already warned about it\n            #   and the warning message mentions the future self.alphas default, so\n            #   no need to warn a second time.\n            pass\n        elif self.alphas is None:\n            warnings.warn(\n                \"'alphas=None' is deprecated and will be removed in 1.9, at which \"\n                \"point the default value will be set to 100. Set 'alphas=100' \"\n                \"to silence this warning.\",\n                FutureWarning,\n            )\n        else:\n            self._alphas = self.alphas\n\n        # This makes sure that there is no duplication in memory.\n        # Dealing right with copy_X is important in the following:\n        # Multiple functions touch X and subsamples of X and can induce a\n        # lot of duplication of memory.\n        # There is no need copy X if the model is fit without an intercept.\n        copy_X = self.copy_X and self.fit_intercept  # TODO: Sample_weights?\n\n        check_y_params = dict(\n            copy=False, dtype=[np.float64, np.float32], ensure_2d=False\n        )\n        # ... other code"}, {"file": "examples/compose/plot_compare_reduction.py", "name": "impl:15", "type": "codeblock", "score": 3.9129066467285156, "line": 78, "text": "mean_scores = mean_scores.max(axis=0)\n# create a dataframe to ease plotting\nmean_scores = pd.DataFrame(\n    mean_scores.T, index=N_FEATURES_OPTIONS, columns=reducer_labels\n)\n\nax = mean_scores.plot.bar()\nax.set_title(\"Comparing feature reduction techniques\")\nax.set_xlabel(\"Reduced number of features\")\nax.set_ylabel(\"Digit classification accuracy\")\nax.set_ylim((0, 1))\nax.legend(loc=\"upper left\")\n\nplt.show()\n\n# %%\n# Caching transformers within a ``Pipeline``\n# ##########################################\n#\n# It is sometimes worthwhile storing the state of a specific transformer\n# since it could be used again. Using a pipeline in ``GridSearchCV`` triggers\n# such situations. Therefore, we use the argument ``memory`` to enable caching.\n#\n# .. warning::\n#     Note that this example is, however, only an illustration since for this\n#     specific case fitting PCA is not necessarily slower than loading the\n#     cache. Hence, use the ``memory`` constructor parameter when the fitting\n#     of a transformer is costly.\n\nfrom shutil import rmtree\n\nfrom joblib import Memory\n\n# Create a temporary folder to store the transformers of the pipeline\nlocation = \"cachedir\"\nmemory = Memory(location=location, verbose=10)\ncached_pipe = Pipeline(\n    [(\"reduce_dim\", PCA()), (\"classify\", LinearSVC(dual=False, max_iter=10000))],\n    memory=memory,\n)\n\n# This time, a cached pipeline will be used within the grid search\n\n\n# Delete the temporary cache before exiting\nmemory.clear(warn=False)\nrmtree(location)\n\n# %%\n# The ``PCA`` fitting is only computed at the evaluation of the first\n# configuration of the ``C`` parameter of the ``LinearSVC`` classifier. The\n# other configurations of ``C`` will trigger the loading of the cached ``PCA``\n# estimator data, leading to save processing time. Therefore, the use of\n# caching the pipeline using ``memory`` is highly beneficial when fitting\n# a transformer is costly."}, {"file": "sklearn/model_selection/_validation.py", "name": "_warn_or_raise_about_fit_failures", "type": "codeblock", "score": 3.855320930480957, "line": 457, "text": "def _warn_or_raise_about_fit_failures(results, error_score):\n    fit_errors = [\n        result[\"fit_error\"] for result in results if result[\"fit_error\"] is not None\n    ]\n    if fit_errors:\n        num_failed_fits = len(fit_errors)\n        num_fits = len(results)\n        fit_errors_counter = Counter(fit_errors)\n        delimiter = \"-\" * 80 + \"\\n\"\n        fit_errors_summary = \"\\n\".join(\n            f\"{delimiter}{n} fits failed with the following error:\\n{error}\"\n            for error, n in fit_errors_counter.items()\n        )\n\n        if num_failed_fits == num_fits:\n            all_fits_failed_message = (\n                f\"\\nAll the {num_fits} fits failed.\\n\"\n                \"It is very likely that your model is misconfigured.\\n\"\n                \"You can try to debug the error by setting error_score='raise'.\\n\\n\"\n                f\"Below are more details about the failures:\\n{fit_errors_summary}\"\n            )\n            raise ValueError(all_fits_failed_message)\n\n        else:\n            some_fits_failed_message = (\n                f\"\\n{num_failed_fits} fits failed out of a total of {num_fits}.\\n\"\n                \"The score on these train-test partitions for these parameters\"\n                f\" will be set to {error_score}.\\n\"\n                \"If these failures are not expected, you can try to debug them \"\n                \"by setting error_score='raise'.\\n\\n\"\n                f\"Below are more details about the failures:\\n{fit_errors_summary}\"\n            )\n            warnings.warn(some_fits_failed_message, FitFailedWarning)"}, {"file": "sklearn/cluster/_optics.py", "name": "OPTICS.fit", "type": "codeblock", "score": 3.7276482582092285, "line": 300, "text": "class OPTICS(ClusterMixin, BaseEstimator):\n\n    @_fit_context(\n        # Optics.metric is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self, X, y=None):\n        \"\"\"Perform OPTICS clustering.\n\n        Extracts an ordered list of points and reachability distances, and\n        performs initial clustering using ``max_eps`` distance specified at\n        OPTICS object instantiation.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features), or \\\n                (n_samples, n_samples) if metric='precomputed'\n            A feature array, or array of distances between samples if\n            metric='precomputed'. If a sparse matrix is provided, it will be\n            converted into CSR format.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Returns a fitted instance of self.\n        \"\"\"\n        dtype = bool if self.metric in PAIRWISE_BOOLEAN_FUNCTIONS else float\n        if dtype is bool and X.dtype != bool:\n            msg = (\n                \"Data will be converted to boolean for\"\n                f\" metric {self.metric}, to avoid this warning,\"\n                \" you may convert the data prior to calling fit.\"\n            )\n            warnings.warn(msg, DataConversionWarning)\n\n        X = validate_data(self, X, dtype=dtype, accept_sparse=\"csr\")\n        if self.metric == \"precomputed\" and issparse(X):\n            X = X.copy()  # copy to avoid in-place modification\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", SparseEfficiencyWarning)\n                # Set each diagonal to an explicit value so each point is its\n                # own neighbor\n                X.setdiag(X.diagonal())\n        memory = check_memory(self.memory)\n\n        (\n            self.ordering_,\n            self.core_distances_,\n            self.reachability_,\n            self.predecessor_,\n        ) = memory.cache(compute_optics_graph)(\n            X=X,\n            min_samples=self.min_samples,\n            algorithm=self.algorithm,\n            leaf_size=self.leaf_size,\n            metric=self.metric,\n            metric_params=self.metric_params,\n            p=self.p,\n            n_jobs=self.n_jobs,\n            max_eps=self.max_eps,\n        )\n\n        # Extract clusters from the calculated orders and reachability\n        # ... other code"}, {"file": "sklearn/cluster/_kmeans.py", "name": "MiniBatchKMeans._warn_mkl_vcomp", "type": "codeblock", "score": 3.6810755729675293, "line": 1960, "text": "class MiniBatchKMeans(_BaseKMeans):\n\n    def _warn_mkl_vcomp(self, n_active_threads):\n        \"\"\"Warn when vcomp and mkl are both present\"\"\"\n        warnings.warn(\n            \"MiniBatchKMeans is known to have a memory leak on \"\n            \"Windows with MKL, when there are less chunks than \"\n            \"available threads. You can prevent it by setting \"\n            f\"batch_size >= {self._n_threads * CHUNK_SIZE} or by \"\n            \"setting the environment variable \"\n            f\"OMP_NUM_THREADS={n_active_threads}\"\n        )"}, {"file": "sklearn/utils/validation.py", "name": "_check_psd_eigenvalues", "type": "codeblock", "score": 3.4907288551330566, "line": 2030, "text": "def _check_psd_eigenvalues(lambdas, enable_warnings=False):\n    # ... other code\n    if max_eig < 0:\n        raise ValueError(\n            \"All eigenvalues are negative (maximum is %g). \"\n            \"Either the matrix is not PSD, or there was an \"\n            \"issue while computing the eigendecomposition of \"\n            \"the matrix.\" % max_eig\n        )\n\n    else:\n        min_eig = lambdas.min()\n        if (\n            min_eig < -significant_neg_ratio * max_eig\n            and min_eig < -significant_neg_value\n        ):\n            raise ValueError(\n                \"There are significant negative eigenvalues (%g\"\n                \" of the maximum positive). Either the matrix is \"\n                \"not PSD, or there was an issue while computing \"\n                \"the eigendecomposition of the matrix.\" % (-min_eig / max_eig)\n            )\n        elif min_eig < 0:\n            # Remove all negative values and warn about it\n            if enable_warnings:\n                warnings.warn(\n                    \"There are negative eigenvalues (%g of the \"\n                    \"maximum positive). Either the matrix is not \"\n                    \"PSD, or there was an issue while computing the\"\n                    \" eigendecomposition of the matrix. Negative \"\n                    \"eigenvalues will be replaced with 0.\" % (-min_eig / max_eig),\n                    PositiveSpectrumWarning,\n                )\n            lambdas[lambdas < 0] = 0\n\n    # Check for conditioning (small positive non-zeros)\n    too_small_lambdas = (0 < lambdas) & (lambdas < small_pos_ratio * max_eig)\n    if too_small_lambdas.any():\n        if enable_warnings:\n            warnings.warn(\n                \"Badly conditioned PSD matrix spectrum: the largest \"\n                \"eigenvalue is more than %g times the smallest. \"\n                \"Small eigenvalues will be replaced with 0.\"\n                \"\" % (1 / small_pos_ratio),\n                PositiveSpectrumWarning,\n            )\n        lambdas[too_small_lambdas] = 0\n\n    return lambdas"}, {"file": "sklearn/cluster/_kmeans.py", "name": "KMeans._check_params_vs_input", "type": "codeblock", "score": 3.1851067543029785, "line": 1377, "text": "class KMeans(_BaseKMeans):\n\n    _parameter_constraints: dict = {\n        **_BaseKMeans._parameter_constraints,\n        \"copy_x\": [\"boolean\"],\n        \"algorithm\": [StrOptions({\"lloyd\", \"elkan\"})],\n    }\n\n    def __init__(\n        self,\n        n_clusters=8,\n        *,\n        init=\"k-means++\",\n        n_init=\"auto\",\n        max_iter=300,\n        tol=1e-4,\n        verbose=0,\n        random_state=None,\n        copy_x=True,\n        algorithm=\"lloyd\",\n    ):\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            n_init=n_init,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            random_state=random_state,\n        )\n\n        self.copy_x = copy_x\n        self.algorithm = algorithm\n\n    def _check_params_vs_input(self, X):\n        super()._check_params_vs_input(X, default_n_init=10)\n\n        self._algorithm = self.algorithm\n        if self._algorithm == \"elkan\" and self.n_clusters == 1:\n            warnings.warn(\n                (\n                    \"algorithm='elkan' doesn't make sense for a single \"\n                    \"cluster. Using 'lloyd' instead.\"\n                ),\n                RuntimeWarning,\n            )\n            self._algorithm = \"lloyd\"\n\n    def _warn_mkl_vcomp(self, n_active_threads):\n        \"\"\"Warn when vcomp and mkl are both present\"\"\"\n        warnings.warn(\n            \"KMeans is known to have a memory leak on Windows \"\n            \"with MKL, when there are less chunks than available \"\n            \"threads. You can avoid it by setting the environment\"\n            f\" variable OMP_NUM_THREADS={n_active_threads}.\"\n        )"}, {"file": "sklearn/utils/_chunking.py", "name": "get_chunk_n_rows", "type": "codeblock", "score": 3.1073524951934814, "line": 140, "text": "def get_chunk_n_rows(row_bytes, *, max_n_rows=None, working_memory=None):\n    \"\"\"Calculate how many rows can be processed within `working_memory`.\n\n    Parameters\n    ----------\n    row_bytes : int\n        The expected number of bytes of memory that will be consumed\n        during the processing of each row.\n    max_n_rows : int, default=None\n        The maximum return value.\n    working_memory : int or float, default=None\n        The number of rows to fit inside this number of MiB will be\n        returned. When None (default), the value of\n        ``sklearn.get_config()['working_memory']`` is used.\n\n    Returns\n    -------\n    int\n        The number of rows which can be processed within `working_memory`.\n\n    Warns\n    -----\n    Issues a UserWarning if `row_bytes exceeds `working_memory` MiB.\n    \"\"\"\n\n    if working_memory is None:\n        working_memory = get_config()[\"working_memory\"]\n\n    chunk_n_rows = int(working_memory * (2**20) // row_bytes)\n    if max_n_rows is not None:\n        chunk_n_rows = min(chunk_n_rows, max_n_rows)\n    if chunk_n_rows < 1:\n        warnings.warn(\n            \"Could not adhere to working_memory config. \"\n            \"Currently %.0fMiB, %.0fMiB required.\"\n            % (working_memory, np.ceil(row_bytes * 2**-20))\n        )\n        chunk_n_rows = 1\n    return chunk_n_rows"}, {"file": "sklearn/cluster/_bisect_k_means.py", "name": "BisectingKMeans.__init__", "type": "codeblock", "score": 3.0701122283935547, "line": 217, "text": "class BisectingKMeans(_BaseKMeans):\n\n    _parameter_constraints: dict = {\n        **_BaseKMeans._parameter_constraints,\n        \"init\": [StrOptions({\"k-means++\", \"random\"}), callable],\n        \"n_init\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"copy_x\": [\"boolean\"],\n        \"algorithm\": [StrOptions({\"lloyd\", \"elkan\"})],\n        \"bisecting_strategy\": [StrOptions({\"biggest_inertia\", \"largest_cluster\"})],\n    }\n\n    def __init__(\n        self,\n        n_clusters=8,\n        *,\n        init=\"random\",\n        n_init=1,\n        random_state=None,\n        max_iter=300,\n        verbose=0,\n        tol=1e-4,\n        copy_x=True,\n        algorithm=\"lloyd\",\n        bisecting_strategy=\"biggest_inertia\",\n    ):\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            max_iter=max_iter,\n            verbose=verbose,\n            random_state=random_state,\n            tol=tol,\n            n_init=n_init,\n        )\n\n        self.copy_x = copy_x\n        self.algorithm = algorithm\n        self.bisecting_strategy = bisecting_strategy\n\n    def _warn_mkl_vcomp(self, n_active_threads):\n        \"\"\"Warn when vcomp and mkl are both present\"\"\"\n        warnings.warn(\n            \"BisectingKMeans is known to have a memory leak on Windows \"\n            \"with MKL, when there are less chunks than available \"\n            \"threads. You can avoid it by setting the environment\"\n            f\" variable OMP_NUM_THREADS={n_active_threads}.\"\n        )"}, {"file": "sklearn/utils/validation.py", "name": "check_memory", "type": "codeblock", "score": 3.0699164867401123, "line": 405, "text": "def check_memory(memory):\n    \"\"\"Check that ``memory`` is joblib.Memory-like.\n\n    joblib.Memory-like means that ``memory`` can be converted into a\n    joblib.Memory instance (typically a str denoting the ``location``)\n    or has the same interface (has a ``cache`` method).\n\n    Parameters\n    ----------\n    memory : None, str or object with the joblib.Memory interface\n        - If string, the location where to create the `joblib.Memory` interface.\n        - If None, no caching is done and the Memory object is completely transparent.\n\n    Returns\n    -------\n    memory : object with the joblib.Memory interface\n        A correct joblib.Memory object.\n\n    Raises\n    ------\n    ValueError\n        If ``memory`` is not joblib.Memory-like.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_memory\n    >>> check_memory(\"caching_dir\")\n    Memory(location=caching_dir/joblib)\n    \"\"\"\n    if memory is None or isinstance(memory, str):\n        memory = joblib.Memory(location=memory, verbose=0)\n    elif not hasattr(memory, \"cache\"):\n        raise ValueError(\n            \"'memory' should be None, a string or have the same\"\n            \" interface as joblib.Memory.\"\n            \" Got memory='{}' instead.\".format(memory)\n        )\n    return memory"}], "total_results": 10}
{"repo": "scikit-learn", "query": "linear_model ridge.py parameters", "top_10": [{"file": "examples/linear_model/plot_ridge_path.py", "name": "docstring", "type": "codeblock", "score": 4.937808036804199, "line": 1, "text": "\"\"\"\n===========================================================\nPlot Ridge coefficients as a function of the regularization\n===========================================================\n\nShows the effect of collinearity in the coefficients of an estimator.\n\n.. currentmodule:: sklearn.linear_model\n\n:class:`Ridge` Regression is the estimator used in this example.\nEach color represents a different feature of the\ncoefficient vector, and this is displayed as a function of the\nregularization parameter.\n\nThis example also shows the usefulness of applying Ridge regression\nto highly ill-conditioned matrices. For such matrices, a slight\nchange in the target variable can cause huge variances in the\ncalculated weights. In such cases, it is useful to set a certain\nregularization (alpha) to reduce this variation (noise).\n\nWhen alpha is very large, the regularization effect dominates the\nsquared loss function and the coefficients tend to zero.\nAt the end of the path, as alpha tends toward zero\nand the solution tends towards the ordinary least squares, coefficients\nexhibit big oscillations. In practice it is necessary to tune alpha\nin such a way that a balance is maintained between both.\n\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import linear_model\n\n# X is the 10x10 Hilbert matrix\nX = 1.0 / (np.arange(1, 11) + np.arange(0, 10)[:, np.newaxis])\ny = np.ones(10)\n\n# %%\n# Compute paths\n# -------------\n\nn_alphas = 200\nalphas = np.logspace(-10, -2, n_alphas)\n\ncoefs = []\nfor a in alphas:\n    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)\n    ridge.fit(X, y)\n    coefs.append(ridge.coef_)\n\n# %%\n# Display results\n# ---------------\n\nax = plt.gca()\n\nax.plot(alphas, coefs)\nax.set_xscale(\"log\")\nax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\nplt.xlabel(\"alpha\")\nplt.ylabel(\"weights\")\nplt.title(\"Ridge Coefficients vs Regularization Strength (alpha)\")\nplt.axis(\"tight\")\nplt.legend(\n    [f\"Feature {i + 1}\" for i in range(X.shape[1])], loc=\"best\", fontsize=\"small\"\n)\nplt.show()"}, {"file": "examples/linear_model/plot_huber_vs_ridge.py", "name": "docstring", "type": "codeblock", "score": 4.898257255554199, "line": 1, "text": "\"\"\"\n=======================================================\nHuberRegressor vs Ridge on dataset with strong outliers\n=======================================================\n\nFit Ridge and HuberRegressor on a dataset with outliers.\n\nThe example shows that the predictions in ridge are strongly influenced\nby the outliers present in the dataset. The Huber regressor is less\ninfluenced by the outliers since the model uses the linear loss for these.\nAs the parameter epsilon is increased for the Huber regressor, the decision\nfunction approaches that of the ridge.\n\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import HuberRegressor, Ridge\n\n# Generate toy data.\nrng = np.random.RandomState(0)\nX, y = make_regression(\n    n_samples=20, n_features=1, random_state=0, noise=4.0, bias=100.0\n)\n\n# Add four strong outliers to the dataset.\nX_outliers = rng.normal(0, 0.5, size=(4, 1))\ny_outliers = rng.normal(0, 2.0, size=4)\nX_outliers[:2, :] += X.max() + X.mean() / 4.0\nX_outliers[2:, :] += X.min() - X.mean() / 4.0\ny_outliers[:2] += y.min() - y.mean() / 4.0\ny_outliers[2:] += y.max() + y.mean() / 4.0\nX = np.vstack((X, X_outliers))\ny = np.concatenate((y, y_outliers))\nplt.plot(X, y, \"b.\")\n\n# Fit the huber regressor over a series of epsilon values.\ncolors = [\"r-\", \"b-\", \"y-\", \"m-\"]\n\nx = np.linspace(X.min(), X.max(), 7)\nepsilon_values = [1, 1.5, 1.75, 1.9]\nfor k, epsilon in enumerate(epsilon_values):\n    huber = HuberRegressor(alpha=0.0, epsilon=epsilon)\n    huber.fit(X, y)\n    coef_ = huber.coef_ * x + huber.intercept_\n    plt.plot(x, coef_, colors[k], label=\"huber loss, %s\" % epsilon)\n\n# Fit a ridge regressor to compare it to huber regressor.\nridge = Ridge(alpha=0.0, random_state=0)\nridge.fit(X, y)\ncoef_ridge = ridge.coef_\ncoef_ = ridge.coef_ * x + ridge.intercept_\nplt.plot(x, coef_, \"g-\", label=\"ridge regression\")\n\nplt.title(\"Comparison of HuberRegressor vs Ridge\")\nplt.xlabel(\"X\")\nplt.ylabel(\"y\")\nplt.legend(loc=0)\nplt.show()"}, {"file": "examples/linear_model/plot_ridge_coeffs.py", "name": "docstring:2", "type": "codeblock", "score": 4.630600452423096, "line": 76, "text": "X, y, w = make_regression(\n    n_samples=100, n_features=10, n_informative=8, coef=True, random_state=1\n)\n\n# Obtain the true coefficients\nprint(f\"The true coefficient of this regression problem are:\\n{w}\")\n\n# %%\n# Training the Ridge Regressor\n# ****************************\n# We use :class:`~sklearn.linear_model.Ridge`, a linear model with L2\n# regularization. We train several models, each with a different value for the\n# model parameter `alpha`, which is a positive constant that multiplies the\n# penalty term, controlling the regularization strength. For each trained model\n# we then compute the error between the true coefficients `w` and the\n# coefficients found by the model `clf`. We store the identified coefficients\n# and the calculated errors for the corresponding coefficients in lists, which\n# makes it convenient for us to plot them.\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\nclf = Ridge()\n\n# Generate values for `alpha` that are evenly distributed on a logarithmic scale\nalphas = np.logspace(-3, 4, 200)\ncoefs = []\nerrors_coefs = []\n\n# Train the model with different regularisation strengths\nfor a in alphas:\n    clf.set_params(alpha=a).fit(X, y)\n    coefs.append(clf.coef_)\n    errors_coefs.append(mean_squared_error(clf.coef_, w))\n\n# %%\n# Plotting trained Coefficients and Mean Squared Errors\n# *****************************************************\n# We now plot the 10 different regularized coefficients as a function of the\n# regularization parameter `alpha` where each color represents a different\n# coefficient.\n#\n# On the right-hand-side, we plot how the errors of the coefficients from the\n# estimator change as a function of regularization.\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nalphas = pd.Index(alphas, name=\"alpha\")\ncoefs = pd.DataFrame(coefs, index=alphas, columns=[f\"Feature {i}\" for i in range(10)])\nerrors = pd.Series(errors_coefs, index=alphas, name=\"Mean squared error\")\n\nfig, axs = plt.subplots(1, 2, figsize=(20, 6))\n\ncoefs.plot(\n    ax=axs[0],\n    logx=True,\n    title=\"Ridge coefficients as a function of the regularization strength\",\n)\naxs[0].set_ylabel(\"Ridge coefficient values\")"}, {"file": "examples/linear_model/plot_poisson_regression_non_normal_loss.py", "name": "impl:24", "type": "codeblock", "score": 4.475706100463867, "line": 204, "text": "print(\"Constant mean frequency evaluation:\")\nscore_estimator(dummy, df_test)\n\n# %%\n# (Generalized) linear models\n# ---------------------------\n#\n# We start by modeling the target variable with the (l2 penalized) least\n# squares linear regression model, more commonly known as Ridge regression. We\n# use a low penalization `alpha`, as we expect such a linear model to under-fit\n# on such a large dataset.\n\nfrom sklearn.linear_model import Ridge\n\nridge_glm = Pipeline(\n    [\n        (\"preprocessor\", linear_model_preprocessor),\n        (\"regressor\", Ridge(alpha=1e-6)),\n    ]\n).fit(df_train, df_train[\"Frequency\"], regressor__sample_weight=df_train[\"Exposure\"])\n\n# %%\n# The Poisson deviance cannot be computed on non-positive values predicted by\n# the model. For models that do return a few non-positive predictions (e.g.\n# :class:`~sklearn.linear_model.Ridge`) we ignore the corresponding samples,\n# meaning that the obtained Poisson deviance is approximate. An alternative\n# approach could be to use :class:`~sklearn.compose.TransformedTargetRegressor`\n# meta-estimator to map ``y_pred`` to a strictly positive domain.\n\nprint(\"Ridge evaluation:\")\nscore_estimator(ridge_glm, df_test)\n\n# %%\n# Next we fit the Poisson regressor on the target variable. We set the\n# regularization strength ``alpha`` to approximately 1e-6 over number of\n# samples (i.e. `1e-12`) in order to mimic the Ridge regressor whose L2 penalty\n# term scales differently with the number of samples.\n#\n# Since the Poisson regressor internally models the log of the expected target\n# value instead of the expected value directly (log vs identity link function),\n# the relationship between X and y is not exactly linear anymore. Therefore the\n# Poisson regressor is called a Generalized Linear Model (GLM) rather than a\n# vanilla linear model as is the case for Ridge regression.\n\nfrom sklearn.linear_model import PoissonRegressor\n\nn_samples = df_train.shape[0]\n\npoisson_glm = Pipeline(\n    [\n        (\"preprocessor\", linear_model_preprocessor),\n        (\"regressor\", PoissonRegressor(alpha=1e-12, solver=\"newton-cholesky\")),\n    ]\n)\npoisson_glm.fit(\n    df_train, df_train[\"Frequency\"], regressor__sample_weight=df_train[\"Exposure\"]\n)"}, {"file": "examples/linear_model/plot_ols_ridge.py", "name": "impl:11", "type": "codeblock", "score": 4.458545684814453, "line": 71, "text": "ax[0].plot(\n    X_train,\n    regressor.predict(X_train),\n    linewidth=3,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[0].set(xlabel=\"Feature\", ylabel=\"Target\", title=\"Train set\")\nax[0].legend()\n\nax[1].scatter(X_test, y_test, label=\"Test data points\")\nax[1].plot(X_test, y_pred, linewidth=3, color=\"tab:orange\", label=\"Model predictions\")\nax[1].set(xlabel=\"Feature\", ylabel=\"Target\", title=\"Test set\")\nax[1].legend()\n\nfig.suptitle(\"Linear Regression\")\n\nplt.show()\n\n# %%\n#\n# OLS on this single-feature subset learns a linear function that minimizes\n# the mean squared error on the training data. We can see how well (or poorly)\n# it generalizes by looking at the R^2 score and mean squared error on the\n# test set. In higher dimensions, pure OLS often overfits, especially if the\n# data is noisy. Regularization techniques (like Ridge or Lasso) can help\n# reduce that.\n\n# %%\n# Ordinary Least Squares and Ridge Regression Variance\n# ----------------------------------------------------------\n#\n# Next, we illustrate the problem of high variance more clearly by using\n# a tiny synthetic dataset. We sample only two data points, then repeatedly\n# add small Gaussian noise to them and refit both OLS and Ridge. We plot\n# each new line to see how much OLS can jump around, whereas Ridge remains\n# more stable thanks to its penalty term.\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import linear_model\n\nX_train = np.c_[0.5, 1].T\ny_train = [0.5, 1]\nX_test = np.c_[0, 2].T\n\nnp.random.seed(0)\n\nclassifiers = dict(\n    ols=linear_model.LinearRegression(), ridge=linear_model.Ridge(alpha=0.1)\n)"}, {"file": "benchmarks/bench_glm.py", "name": "docstring", "type": "codeblock", "score": 4.398614406585693, "line": 1, "text": "\"\"\"\nA comparison of different methods in GLM\n\nData comes from a random square matrix.\n\n\"\"\"\n\nfrom datetime import datetime\n\nimport numpy as np\n\nfrom sklearn import linear_model\n\nif __name__ == \"__main__\":\n    import matplotlib.pyplot as plt\n\n    n_iter = 40\n\n    time_ridge = np.empty(n_iter)\n    time_ols = np.empty(n_iter)\n    time_lasso = np.empty(n_iter)\n\n    dimensions = 500 * np.arange(1, n_iter + 1)\n\n    for i in range(n_iter):\n        print(\"Iteration %s of %s\" % (i, n_iter))\n\n        n_samples, n_features = 10 * i + 3, 10 * i + 3\n\n        X = np.random.randn(n_samples, n_features)\n        Y = np.random.randn(n_samples)\n\n        start = datetime.now()\n        ridge = linear_model.Ridge(alpha=1.0)\n        ridge.fit(X, Y)\n        time_ridge[i] = (datetime.now() - start).total_seconds()\n\n        start = datetime.now()\n        ols = linear_model.LinearRegression()\n        ols.fit(X, Y)\n        time_ols[i] = (datetime.now() - start).total_seconds()\n\n        start = datetime.now()\n        lasso = linear_model.LassoLars()\n        lasso.fit(X, Y)\n        time_lasso[i] = (datetime.now() - start).total_seconds()\n\n    plt.figure(\"scikit-learn GLM benchmark results\")\n    plt.xlabel(\"Dimensions\")\n    plt.ylabel(\"Time (s)\")\n    plt.plot(dimensions, time_ridge, color=\"r\")\n    plt.plot(dimensions, time_ols, color=\"g\")\n    plt.plot(dimensions, time_lasso, color=\"b\")\n\n    plt.legend([\"Ridge\", \"OLS\", \"LassoLars\"], loc=\"upper left\")\n    plt.axis(\"tight\")\n    plt.show()"}, {"file": "examples/linear_model/plot_ols_ridge.py", "name": "docstring", "type": "codeblock", "score": 4.365021228790283, "line": 1, "text": "\"\"\"\n===========================================\nOrdinary Least Squares and Ridge Regression\n===========================================\n\n1. Ordinary Least Squares:\n   We illustrate how to use the ordinary least squares (OLS) model,\n   :class:`~sklearn.linear_model.LinearRegression`, on a single feature of\n   the diabetes dataset. We train on a subset of the data, evaluate on a\n   test set, and visualize the predictions.\n\n2. Ordinary Least Squares and Ridge Regression Variance:\n   We then show how OLS can have high variance when the data is sparse or\n   noisy, by fitting on a very small synthetic sample repeatedly. Ridge\n   regression, :class:`~sklearn.linear_model.Ridge`, reduces this variance\n   by penalizing (shrinking) the coefficients, leading to more stable\n   predictions.\n\n\"\"\"\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_diabetes(return_X_y=True)\nX = X[:, [2]]  # Use only one feature\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, shuffle=False)\n\n# %%\n# Linear regression model\n# -----------------------\n#\n# We create a linear regression model and fit it on the training data. Note that by\n# default, an intercept is added to the model. We can control this behavior by setting\n# the `fit_intercept` parameter.\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression().fit(X_train, y_train)\n\n# %%\n# Model evaluation\n# ----------------\n#\n# We evaluate the model's performance on the test set using the mean squared error\n# and the coefficient of determination.\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ny_pred = regressor.predict(X_test)\n\nprint(f\"Mean squared error: {mean_squared_error(y_test, y_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y_test, y_pred):.2f}\")\n\n# %%\n# Plotting the results\n# --------------------\n#\n# Finally, we visualize the results on the train and test data.\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n\nax[0].scatter(X_train, y_train, label=\"Train data points\")\n\nplt.show()"}, {"file": "sklearn/linear_model/_ridge.py", "name": "Ridge.__sklearn_tags__", "type": "codeblock", "score": 4.323735237121582, "line": 1232, "text": "class Ridge(MultiOutputMixin, RegressorMixin, _BaseRidge):\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"Fit Ridge regression model.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Training data.\n\n        y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n            Target values.\n\n        sample_weight : float or ndarray of shape (n_samples,), default=None\n            Individual weights for each sample. If given a float, every sample\n            will have the same weight.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X), self.solver)\n        xp, _ = get_namespace(X, y, sample_weight)\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=_accept_sparse,\n            dtype=[xp.float64, xp.float32],\n            force_writeable=True,\n            multi_output=True,\n            y_numeric=True,\n        )\n        return super().fit(X, y, sample_weight=sample_weight)\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.array_api_support = True\n        tags.input_tags.sparse = (self.solver != \"svd\") and (\n            self.solver != \"cholesky\" or not self.fit_intercept\n        )\n        return tags"}, {"file": "examples/linear_model/plot_bayesian_ridge_curvefit.py", "name": "docstring", "type": "codeblock", "score": 4.128363132476807, "line": 1, "text": "\"\"\"\n============================================\nCurve Fitting with Bayesian Ridge Regression\n============================================\n\nComputes a Bayesian Ridge Regression of Sinusoids.\n\nSee :ref:`bayesian_ridge_regression` for more information on the regressor.\n\nIn general, when fitting a curve with a polynomial by Bayesian ridge\nregression, the selection of initial values of\nthe regularization parameters (alpha, lambda) may be important.\nThis is because the regularization parameters are determined by an iterative\nprocedure that depends on initial values.\n\nIn this example, the sinusoid is approximated by a polynomial using different\npairs of initial values.\n\nWhen starting from the default values (alpha_init = 1.90, lambda_init = 1.),\nthe bias of the resulting curve is large, and the variance is small.\nSo, lambda_init should be relatively small (1.e-3) so as to reduce the bias.\n\nAlso, by evaluating log marginal likelihood (L) of\nthese models, we can determine which one is better.\nIt can be concluded that the model with larger L is more likely.\n\n\"\"\"\nimport numpy as np\n\n\ndef func(x):\n    return np.sin(2 * np.pi * x)\n\n\nsize = 25\nrng = np.random.RandomState(1234)\nx_train = rng.uniform(0.0, 1.0, size)\ny_train = func(x_train) + rng.normal(scale=0.1, size=size)\nx_test = np.linspace(0.0, 1.0, 100)\n\n\n# %%\n# Fit by cubic polynomial\n# -----------------------\nfrom sklearn.linear_model import BayesianRidge\n\nn_order = 3\nX_train = np.vander(x_train, n_order + 1, increasing=True)\nX_test = np.vander(x_test, n_order + 1, increasing=True)\nreg = BayesianRidge(tol=1e-6, fit_intercept=False, compute_score=True)\n\n# %%\n# Plot the true and predicted curves with log marginal likelihood (L)\n# -------------------------------------------------------------------\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))"}, {"file": "sklearn/linear_model/_ridge.py", "name": "Ridge.__init__", "type": "codeblock", "score": 4.059060573577881, "line": 1209, "text": "class Ridge(MultiOutputMixin, RegressorMixin, _BaseRidge):\n\n    def __init__(\n        self,\n        alpha=1.0,\n        *,\n        fit_intercept=True,\n        copy_X=True,\n        max_iter=None,\n        tol=1e-4,\n        solver=\"auto\",\n        positive=False,\n        random_state=None,\n    ):\n        super().__init__(\n            alpha=alpha,\n            fit_intercept=fit_intercept,\n            copy_X=copy_X,\n            max_iter=max_iter,\n            tol=tol,\n            solver=solver,\n            positive=positive,\n            random_state=random_state,\n        )"}], "total_results": 10}
