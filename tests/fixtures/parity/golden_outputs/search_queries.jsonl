{"repo": "LocAgent", "query": "graph builder", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.2905020713806152, "line": 453, "text": "def get_inner_nodes(query_node, src_node, graph):\n    inner_nodes = []\n    for _, dst_node, attr in graph.edges(src_node, data=True):\n        if attr['type'] == EDGE_TYPE_CONTAINS and dst_node != quer"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.1727683544158936, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.157541036605835, "line": 387, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n    # ... other code\n    for node, attributes in graph.nodes(data=True):\n        if attributes.get('type') not in [NODE_TYPE_CLASS, "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.1364524364471436, "line": 741, "text": "def main():\n    # Generate Dependency Graph\n    graph = build_graph(args.repo_path, global_import=args.global_import)\n\n    if args.visualize:\n        visualize_graph(graph)\n\n    inherit_list = []\n    "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.103729009628296, "line": 716, "text": "def traverse_directory_structure(graph, root='/'):\n    def traverse(node, prefix, is_last):\n        if node == root:\n            print(f\"{node}\")\n            new_prefix = ''\n        else:\n            "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.070451498031616, "line": 283, "text": "# Traverse all the Python files under repo_path, construct dependency graphs \n# with node types: directory, file, class, function\ndef build_graph(repo_path, fuzzy_search=True, global_import=False):\n  "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.9005087614059448, "line": 365, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n\n    # check last traversed directory\n    while len(dir_stack) > 0:\n        if not dir_include_stack[-1]:\n            graph.remove_n"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 1.8290294408798218, "line": 49, "text": "class RepoEntitySearcher:\n    \"\"\"Retrieve Entity IDs and Code Snippets from Repository Graph\"\"\"\n\n    def __init__(self, graph):\n        self.G = graph\n        self._global_name_dict = None\n        sel"}, {"file": "plugins/location_tools/retriever/fuzzy_retriever.py", "name": "", "type": "codeblock", "score": 1.8270928859710693, "line": 1, "text": "from rapidfuzz import process, fuzz\nimport re\nimport pickle\nfrom typing import Dict, List, Optional\nimport networkx as nx\nfrom dependency_graph.traverse_graph import is_test_file\nfrom dependency_graph"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 1.7081562280654907, "line": 24, "text": "def mean_shortest_distance(graph, list_a, list_b):\n    # Step 1: Compute shortest distances\n    mean_distances = []\n\n    for b in list_b:\n        shortest_dist_to_a = float('inf')  # Initialize with a"}], "total_results": 10}
{"repo": "LocAgent", "query": "dependency traversal", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 4.93794059753418, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 4.660987854003906, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 4.260440349578857, "line": 71, "text": "_TREE_EXAMPLE = \"\"\"\nExample Usage:\n1. Exploring Outward Dependencies:\n    ```\n    explore_tree_structure(\n        start_entities=['src/module_a.py:ClassA'],\n        direction='downstream',\n        tra"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 4.243746757507324, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 4.209333896636963, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.6474199295043945, "line": 175, "text": "class ReferenceScope(str, Enum):\n    EXTERNAL = 'external'\n    DEPENDENCY = 'dependency'  # External dependency\n    FILE = 'file'  # File in repository\n    PROJECT = 'project'\n    CLASS = 'class'\n    "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.386530876159668, "line": 716, "text": "def traverse_directory_structure(graph, root='/'):\n    def traverse(node, prefix, is_last):\n        if node == root:\n            print(f\"{node}\")\n            new_prefix = ''\n        else:\n            "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.257059335708618, "line": 492, "text": "def traverse_json_structure(G, root, direction='downstream', hops=2,\n                            node_type_filter: Optional[List[str]] = None,\n                            edge_type_filter: Optional[Li"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.076345682144165, "line": 413, "text": "def traverse_tree_structure(G, root, direction='downstream', hops=2,\n                            node_type_filter: Optional[List[str]] = None,\n                            edge_type_filter: Optional[Li"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.0413405895233154, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}], "total_results": 10}
{"repo": "LocAgent", "query": "BM25 search", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 4.162037372589111, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.416057586669922, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.405210256576538, "line": 905, "text": "def _validate_graph_explorer_inputs(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 1,\n        node_type_filter: Optional[List[str]] = None,\n "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.3390538692474365, "line": 782, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.053377628326416, "line": 319, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        found_entities_dict = search_entity_in_global_dict(term, include_files)\n        if "}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.893404483795166, "line": 1, "text": "import os\nimport pickle\nimport Stemmer\nimport fnmatch\nimport mimetypes\nfrom typing import Dict, List, Optional\n\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core import Document"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.779942512512207, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7068397998809814, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.6128168106079102, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5409942865371704, "line": 542, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n\n    files, _, "}], "total_results": 10}
{"repo": "LocAgent", "query": "code blocks parser", "top_10": [{"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.434222936630249, "line": 746, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # ... other code\n        if not current_span:\n     "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.3786654472351074, "line": 395, "text": "class CodeParser:\n\n    def find_in_tree(self, node: Node) -> Optional[NodeMatch]:\n        if self.apply_gpt_tweaks:\n            match = self.find_match_with_gpt_tweaks(node)\n            if match:\n    "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.309668779373169, "line": 703, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # Set documentation phase on comments in the start "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.089146137237549, "line": 810, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        #        parent_block_path=current_span.parent_bloc"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.0439014434814453, "line": 290, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.8420166969299316, "line": 834, "text": "class CodeParser:\n\n    def _create_span_id(self, block: CodeBlock, label: Optional[str] = None):\n        if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n            structure_block = block\n      "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.577815532684326, "line": 307, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.5651822090148926, "line": 1, "text": "import logging\nimport re\nfrom dataclasses import dataclass, field\nfrom importlib import resources\nfrom typing import Callable, List, Optional, Tuple\n\nimport networkx as nx\nfrom llama_index.core import"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.5604119300842285, "line": 184, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/codeblocks/parser/python.py", "name": "", "type": "codeblock", "score": 2.479404926300049, "line": 1, "text": "import logging\n\nfrom tree_sitter_languages import get_language\n\nfrom repo_index.codeblocks.codeblocks import (\n    CodeBlock,\n    CodeBlockType,\n    ReferenceScope,\n    RelationshipType,\n    Validatio"}], "total_results": 10}
{"repo": "LocAgent", "query": "AST parsing", "top_10": [{"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 4.161075592041016, "line": 217, "text": "def parse_python_file(file_path, file_content=None):\n    \"\"\"Parse a Python file to extract class and function definitions with their line numbers.\n    :param file_path: Path to the Python file.\n    :r"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 4.109907150268555, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.2141523361206055, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.0272274017333984, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 3.0055887699127197, "line": 34, "text": "# class ClassDocstringVisitor(cst.CSTVisitor):\n#     def __init__(self):\n#         self.class_docstrings = []\n\n#     def visit_ClassDef(self, node: cst.ClassDef):\n#         # Extract the docstring if "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.961493730545044, "line": 518, "text": "def analyze_init(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    invocations = []\n    inherita"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.393083095550537, "line": 176, "text": "# Parese the given file, use CodeAnalyzer to extract classes and helper functions from the file\ndef analyze_file(filepath):\n    with open(filepath, 'r') as file:\n        code = file.read()\n        # c"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.1820156574249268, "line": 152, "text": "class CodeAnalyzer(ast.NodeVisitor):\n\n    def _visit_func(self, node):\n        function_name = node.name\n        full_function_name = '.'.join(self.node_name_stack + [function_name])\n        self.node"}, {"file": "util/actions/action_parser.py", "name": "", "type": "codeblock", "score": 1.7285280227661133, "line": 138, "text": "class CodeActActionParserFinish:\n    def check_condition(self, action_str: str) -> bool:\n        self.finish_command = re.search(r'<finish>.*</finish>', action_str, re.DOTALL)\n        return self.fini"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.6519134044647217, "line": 387, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n    # ... other code\n    for node, attributes in graph.nodes(data=True):\n        if attributes.get('type') not in [NODE_TYPE_CLASS, "}], "total_results": 10}
{"repo": "LocAgent", "query": "tree-sitter integration", "top_10": [{"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 3.1789743900299072, "line": 42, "text": "class EpicSplitter(NodeParser):\n    language: str = Field(\n        default=\"python\", description=\"Language of the code blocks to parse.\"\n    )\n\n    text_splitter: TextSplitter = Field(\n        descrip"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.77713942527771, "line": 153, "text": "@deprecated('Use BlockSpans to define code block visibility instead')\nclass PathTree(BaseModel):\n\n    def add_to_tree(self, path: Optional[list[str]] = None):\n        if path is None:\n            retu"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.748077630996704, "line": 106, "text": "NON_CODE_BLOCKS = [\n    CodeBlockType.BLOCK_DELIMITER,\n    CodeBlockType.COMMENT,\n    CodeBlockType.COMMENTED_OUT_CODE,\n    CodeBlockType.EXPORT,\n    CodeBlockType.IMPORT,\n    CodeBlockType.ERROR,\n   "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.3287620544433594, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.1292011737823486, "line": 34, "text": "# class ClassDocstringVisitor(cst.CSTVisitor):\n#     def __init__(self):\n#         self.class_docstrings = []\n\n#     def visit_ClassDef(self, node: cst.ClassDef):\n#         # Extract the docstring if "}, {"file": "plugins/location_tools/utils/compress_file.py", "name": "", "type": "codeblock", "score": 2.0848517417907715, "line": 52, "text": "code = \"\"\"\n\\\"\\\"\\\"\nthis is a module\n...\n\\\"\\\"\\\"\nconst = {1,2,3}\nimport os\n\nclass fooClass:\n    '''this is a class'''\n\n    def __init__(self, x):\n        '''initialization.'''\n        self.x = x\n\n    def"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.9268405437469482, "line": 675, "text": "class CodeParser:\n\n    def parse(self, content, file_path: Optional[str] = None) -> Module:\n        if isinstance(content, str):\n            content_in_bytes = bytes(content, self.encoding)\n        el"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.9218178987503052, "line": 176, "text": "# Parese the given file, use CodeAnalyzer to extract classes and helper functions from the file\ndef analyze_file(filepath):\n    with open(filepath, 'r') as file:\n        code = file.read()\n        # c"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.7998381853103638, "line": 161, "text": "def parse_global_var_from_code(file_content: str) -> dict[str, dict]:\n    \"\"\"Parse global variables.\"\"\"\n    try:\n        tree = cst.parse_module(file_content)\n    except:\n        return file_content\n\n"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.5970991849899292, "line": 518, "text": "def analyze_init(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    invocations = []\n    inherita"}], "total_results": 10}
{"repo": "LocAgent", "query": "entity extraction", "top_10": [{"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.686105251312256, "line": 61, "text": "def get_loc_results_from_raw_outputs(instance_id, raw_outputs, include_variable=False):\n    G = pickle.load(\n            open(f\"{GRAPH_INDEX_DIR}/{instance_id}.pkl\", \"rb\")\n        )\n    searcher = Rep"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.477712869644165, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.4413914680480957, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.4380176067352295, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.3928048610687256, "line": 905, "text": "def _validate_graph_explorer_inputs(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 1,\n        node_type_filter: Optional[List[str]] = None,\n "}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.3041434288024902, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n\n_SEARCHENTITY_DESCRIPTION = \"\"\"\nSearches the codebase to retrieve the complete imple"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.232013702392578, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.157871961593628, "line": 689, "text": "def get_entity_contents(entity_names: List[str]):\n    searcher = get_graph_entity_searcher()\n\n    result = ''\n    for name in entity_names:\n        name = name.strip().strip('.')\n        if not name: "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.0908989906311035, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}, {"file": "plugins/location_tools/utils/util.py", "name": "", "type": "codeblock", "score": 1.988323450088501, "line": 34, "text": "def get_meta_data(target_id, dataset:str=\"princeton-nlp/SWE-bench_Lite\", split:str = \"test\"):\n    swe_bench_data = load_dataset(dataset, split=split)\n    bench_data = [x for x in swe_bench_data if x[\""}], "total_results": 10}
{"repo": "LocAgent", "query": "qualified name resolution", "top_10": [{"file": "util/prompts/general_prompt.py", "name": "", "type": "codeblock", "score": 2.2106547355651855, "line": 1, "text": "PR_TEMPLATE = \"\"\"\n--- BEGIN PROBLEM STATEMENT ---\nTitle: {title}\n\n{description}\n--- END PROBLEM STATEMENT ---\n\n\"\"\"\n\n\nSYSTEM_PROMPT=\"\"\"You're an experienced software tester and static analysis expert. "}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 1.9489119052886963, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.415470838546753, "line": 689, "text": "def get_entity_contents(entity_names: List[str]):\n    searcher = get_graph_entity_searcher()\n\n    result = ''\n    for name in entity_names:\n        name = name.strip().strip('.')\n        if not name: "}, {"file": "plugins/location_tools/utils/dependency.py", "name": "", "type": "codeblock", "score": 1.3389697074890137, "line": 1, "text": "from types import ModuleType\n\n\ndef import_functions(\n    module: ModuleType, function_names: list[str], target_globals: dict\n) -> None:\n    for name in function_names:\n        if hasattr(module, name)"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.3000297546386719, "line": 217, "text": "def parse_python_file(file_path, file_content=None):\n    \"\"\"Parse a Python file to extract class and function definitions with their line numbers.\n    :param file_path: Path to the Python file.\n    :r"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.2805986404418945, "line": 69, "text": "# def get_module_from_line_number_with_file_structure(line, file_structure, include_class=False, merge_init=True):\ndef get_module_from_line_number_with_file_structure(line, file_structure, \n          "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 1.2661794424057007, "line": 31, "text": "def add_quotes_to_nodes(G):\n    H = nx.MultiDiGraph()\n\n    # Map old node names to new node names\n    node_mapping = {node: f'\"{node}\"' for node in G.nodes}\n\n    # Add nodes with updated names and cop"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.25332772731781, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n\n_SEARCHENTITY_DESCRIPTION = \"\"\"\nSearches the codebase to retrieve the complete imple"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.2390670776367188, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.2221031188964844, "line": 44, "text": "def check_moduel_existed(module, file_structure):\n    s = file_structure\n    module_type = module.split(':')[0].strip()\n    module_name = module.split(':')[-1].strip()\n\n    if module_type == 'function"}], "total_results": 10}
{"repo": "LocAgent", "query": "import resolution", "top_10": [{"file": "util/prompts/general_prompt.py", "name": "", "type": "codeblock", "score": 2.2106547355651855, "line": 1, "text": "PR_TEMPLATE = \"\"\"\n--- BEGIN PROBLEM STATEMENT ---\nTitle: {title}\n\n{description}\n--- END PROBLEM STATEMENT ---\n\n\"\"\"\n\n\nSYSTEM_PROMPT=\"\"\"You're an experienced software tester and static analysis expert. "}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 1.6733651161193848, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.1671329736709595, "line": 1, "text": "import argparse\nimport os\nimport json\nimport logging\nimport logging.handlers\nimport time\nimport toml\nfrom queue import Empty\nfrom typing import List\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfro"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.1510204076766968, "line": 1, "text": "import os\nimport json\nimport re\nimport subprocess\nimport tempfile\nimport collections\nimport argparse\nimport logging\nimport logging.handlers\nfrom datetime import datetime\nfrom collections import defaul"}, {"file": "build_bm25_index.py", "name": "", "type": "codeblock", "score": 1.1499189138412476, "line": 1, "text": "import argparse\nimport json\nimport os\nimport pickle\nimport time\nfrom pathlib import Path\nimport subprocess\nimport torch.multiprocessing as mp\nimport os.path as osp\nfrom datasets import load_dataset\n# "}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.1489686965942383, "line": 1, "text": "import os\nimport pickle\nimport Stemmer\nimport fnmatch\nimport mimetypes\nfrom typing import Dict, List, Optional\n\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core import Document"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.147470474243164, "line": 1, "text": "import fnmatch\nimport json\nimport logging\nimport mimetypes\nimport os\nimport shutil\nimport tempfile\nfrom typing import Dict, List, Optional\n\nimport requests\nfrom llama_index.core import SimpleDirectory"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 1.1465150117874146, "line": 1, "text": "from util.utils import convert_to_json, load_jsonl\nfrom util.process_output import parse_keyword_json_obj\nimport json\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nimport litellm\nimport os\nf"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.133442997932434, "line": 1, "text": "import pickle\nimport json\nimport os\nimport re\nfrom collections import defaultdict\nfrom typing import List, Optional\nimport collections\nfrom copy import deepcopy\nimport uuid\nimport networkx as nx\nfrom "}, {"file": "repo_index/repository.py", "name": "", "type": "codeblock", "score": 1.1279813051223755, "line": 1, "text": "import difflib\nimport glob\nimport logging\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nfrom pydantic import BaseModel\n\nfrom repo_index.codeblocks import get_parser_by_path\n"}], "total_results": 10}
{"repo": "LocAgent", "query": "function call analysis", "top_10": [{"file": "util/prompts/general_prompt.py", "name": "", "type": "codeblock", "score": 4.594455718994141, "line": 1, "text": "PR_TEMPLATE = \"\"\"\n--- BEGIN PROBLEM STATEMENT ---\nTitle: {title}\n\n{description}\n--- END PROBLEM STATEMENT ---\n\n\"\"\"\n\n\nSYSTEM_PROMPT=\"\"\"You're an experienced software tester and static analysis expert. "}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 3.4419474601745605, "line": 1, "text": "\"\"\"Convert function calling messages to non-function calling messages and vice versa.\n\nThis will inject prompts so that models that doesn't support function calling\ncan still be used with function cal"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 3.1916542053222656, "line": 237, "text": "def convert_tool_call_to_string(tool_call: dict) -> str:\n    \"\"\"Convert tool call to content in string format.\"\"\"\n    if 'function' not in tool_call:\n        raise FunctionCallConversionError(\"Tool ca"}, {"file": "util/runtime/exceptions.py", "name": "", "type": "codeblock", "score": 2.989229679107666, "line": 86, "text": "class OperationCancelled(Exception):\n    \"\"\"Exception raised when an operation is cancelled (e.g. by a keyboard interrupt).\"\"\"\n\n    def __init__(self, message='Operation was cancelled'):\n        super"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.950023889541626, "line": 223, "text": "IN_CONTEXT_LEARNING_EXAMPLE_SUFFIX = \"\"\"\n--------------------- END OF NEW TASK DESCRIPTION ---------------------\n\nPLEASE follow the format strictly! PLEASE EMIT ONE AND ONLY ONE FUNCTION CALL PER MESS"}, {"file": "util/runtime/function_calling.py", "name": "", "type": "codeblock", "score": 2.711670398712158, "line": 41, "text": "def response_to_actions(response: ModelResponse) -> list[Action]:\n    actions: list[Action] = []\n    assert len(response.choices) == 1, 'Only one choice is supported for now'\n    assistant_msg = respo"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.6836371421813965, "line": 307, "text": "def convert_fncall_messages_to_non_fncall_messages(\n    messages: list[dict],\n    tools: list[ChatCompletionToolParam],\n    add_in_context_learning_example: bool = True,\n) -> list[dict]:\n    \"\"\"Conver"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.678252696990967, "line": 563, "text": "def convert_non_fncall_messages_to_fncall_messages(\n    messages: list[dict],\n    tools: list[ChatCompletionToolParam],\n) -> list[dict]:\n    \"\"\"Convert non-function calling messages back to function c"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.405034303665161, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.3599131107330322, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}], "total_results": 10}
{"repo": "LocAgent", "query": "class inheritance", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.832608699798584, "line": 387, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n    # ... other code\n    for node, attributes in graph.nodes(data=True):\n        if attributes.get('type') not in [NODE_TYPE_CLASS, "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.4101860523223877, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.322814702987671, "line": 518, "text": "def analyze_init(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    invocations = []\n    inherita"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.982917308807373, "line": 71, "text": "_TREE_EXAMPLE = \"\"\"\nExample Usage:\n1. Exploring Outward Dependencies:\n    ```\n    explore_tree_structure(\n        start_entities=['src/module_a.py:ClassA'],\n        direction='downstream',\n        tra"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.9764271974563599, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.9051858186721802, "line": 1, "text": "import argparse\nimport ast\nimport os\nimport re\nfrom collections import Counter, defaultdict\nfrom typing import List\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7435650825500488, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.6225178241729736, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 0.6378833055496216, "line": 296, "text": "def run_localize(rank, args, bug_queue, log_queue, output_file_lock, traj_file_lock):\n    queue_handler = logging.handlers.QueueHandler(log_queue)\n    logger = logging.getLogger()\n    logger.setLevel("}, {"file": "repo_index/types.py", "name": "", "type": "codeblock", "score": 0.5089500546455383, "line": 24, "text": "class ActionRequest(BaseModel):\n    pass\n\n    @property\n    def action_name(self):\n        return self.__class__.__name__\n\n\nclass EmptyRequest(ActionRequest):\n    pass\n\n\nclass Finish(ActionRequest):\n "}], "total_results": 10}
{"repo": "LocAgent", "query": "directory traversal", "top_10": [{"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 4.177595138549805, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.934479236602783, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.4757237434387207, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.1805357933044434, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.058274269104004, "line": 71, "text": "_TREE_EXAMPLE = \"\"\"\nExample Usage:\n1. Exploring Outward Dependencies:\n    ```\n    explore_tree_structure(\n        start_entities=['src/module_a.py:ClassA'],\n        direction='downstream',\n        tra"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.758847236633301, "line": 365, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n\n    # check last traversed directory\n    while len(dir_stack) > 0:\n        if not dir_include_stack[-1]:\n            graph.remove_n"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.4161691665649414, "line": 283, "text": "# Traverse all the Python files under repo_path, construct dependency graphs \n# with node types: directory, file, class, function\ndef build_graph(repo_path, fuzzy_search=True, global_import=False):\n  "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.386530876159668, "line": 716, "text": "def traverse_directory_structure(graph, root='/'):\n    def traverse(node, prefix, is_last):\n        if node == root:\n            print(f\"{node}\")\n            new_prefix = ''\n        else:\n            "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.257059335708618, "line": 492, "text": "def traverse_json_structure(G, root, direction='downstream', hops=2,\n                            node_type_filter: Optional[List[str]] = None,\n                            edge_type_filter: Optional[Li"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.076345682144165, "line": 413, "text": "def traverse_tree_structure(G, root, direction='downstream', hops=2,\n                            node_type_filter: Optional[List[str]] = None,\n                            edge_type_filter: Optional[Li"}], "total_results": 10}
{"repo": "LocAgent", "query": "file filtering", "top_10": [{"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 3.037827491760254, "line": 559, "text": "class CodeIndex:\n\n    def _vector_search(\n        self,\n        query: str = '',\n        exact_query_match: bool = False,\n        category: str = 'implementation',\n        file_pattern: Optional[str] "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 2.7212443351745605, "line": 50, "text": "# litellm.set_verbose=True\n# os.environ['LITELLM_LOG'] = 'DEBUG\n\n\ndef filter_dataset(dataset, filter_column: str, used_list: str):\n    file_path = os.path.join(os.path.dirname(os.path.abspath(__file__"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 2.344433546066284, "line": 199, "text": "def extract_module_from_patch(instance, repo_dir, max_edit_file_num=1,\n                              logger=None, \n                              include_gvar=False,\n                              rank="}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.342409610748291, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 2.2931363582611084, "line": 391, "text": "class CodeIndex:\n\n    def find_by_name(\n        self,\n        class_names: Optional[List[str]] = None,\n        function_names: Optional[List[str]] = None,\n        file_pattern: Optional[str] = None,\n "}, {"file": "plugins/location_tools/utils/util.py", "name": "", "type": "codeblock", "score": 2.1441564559936523, "line": 1, "text": "from datasets import load_dataset\nimport os\nimport fnmatch\nfrom collections import defaultdict\nimport re\nfrom util.benchmark.setup_repo import setup_repo\n\n\n# SET THIS IF YOU WANT TO USE THE PREPROCESS"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.1436915397644043, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.0814876556396484, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.8958743810653687, "line": 371, "text": "class CodeIndex:\n\n    def semantic_search(\n        self,\n        query: Optional[str] = None,\n        code_snippet: Optional[str] = None,\n        class_names: Optional[List[str]] = None,\n        funct"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.810821294784546, "line": 469, "text": "class CodeIndex:\n\n    def find_by_name(\n        self,\n        class_names: Optional[List[str]] = None,\n        function_names: Optional[List[str]] = None,\n        file_pattern: Optional[str] = None,\n "}], "total_results": 10}
{"repo": "LocAgent", "query": "index serialization", "top_10": [{"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 1.42686927318573, "line": 372, "text": "class CodeBlock(BaseModel):\n\n    def insert_children(self, index: int, children: List['CodeBlock']):\n        for child in children:\n            self.insert_child(index, child)\n            index += 1\n\n"}, {"file": "repo_index/index/__init__.py", "name": "", "type": "codeblock", "score": 1.4251469373703003, "line": 1, "text": "from repo_index.index.code_index import CodeIndex\nfrom repo_index.index.settings import IndexSettings\nfrom repo_index.index.simple_faiss import SimpleFaissVectorStore\n\n__all__ = ['CodeIndex', 'IndexSe"}, {"file": "repo_index/index/embed_model.py", "name": "", "type": "codeblock", "score": 1.2984868288040161, "line": 1, "text": "import os\n\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\n\n\ndef get_embed_model(model_name: str) -> BaseEmbedding:\n    if model_name.startswith('voyage'):\n        try:\n            fro"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.2942782640457153, "line": 1, "text": "import fnmatch\nimport json\nimport logging\nimport mimetypes\nimport os\nimport shutil\nimport tempfile\nfrom typing import Dict, List, Optional\n\nimport requests\nfrom llama_index.core import SimpleDirectory"}, {"file": "repo_index/index/simple_faiss.py", "name": "", "type": "codeblock", "score": 1.1397862434387207, "line": 104, "text": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def add(\n        self,\n        nodes: List[BaseNode],\n        **add_kwargs: Any,\n    ) -> List[str]:\n        \"\"\"Add nodes to index.\"\"\"\n\n    "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 1.118795394897461, "line": 300, "text": "def traverse_graph_structure(G, roots, direction='downstream', hops=2,\n                             node_type_filter: Optional[List[str]] = None,\n                             edge_type_filter: Optiona"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.1063669919967651, "line": 141, "text": "class CodeIndex:\n\n    @classmethod\n    def from_url(cls, url: str, persist_dir: str, file_repo: FileRepository):\n        try:\n            response = requests.get(url, stream=True)\n            response"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.073087215423584, "line": 810, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        #        parent_block_path=current_span.parent_bloc"}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 1.0707850456237793, "line": 1, "text": "import re\nimport time\nfrom collections.abc import Callable, Sequence\nfrom typing import Any, Optional\n\nfrom llama_index.core.bridge.pydantic import Field\nfrom llama_index.core.callbacks import Callbac"}, {"file": "repo_index/index/simple_faiss.py", "name": "", "type": "codeblock", "score": 1.0567901134490967, "line": 219, "text": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def persist(\n        self,\n        persist_dir: str = DEFAULT_PERSIST_DIR,\n        fs: Optional[fsspec.AbstractFileSystem] = None,\n    ) -> "}], "total_results": 10}
{"repo": "LocAgent", "query": "search ranking", "top_10": [{"file": "repo_index/index/types.py", "name": "", "type": "codeblock", "score": 3.0852057933807373, "line": 31, "text": "class SearchCodeHit(BaseModel):\n    file_path: str = Field(\n        description='The file path where the relevant code is found.'\n    )\n    spans: List[SpanHit] = Field(\n        default_factory=list,\n"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 2.5186328887939453, "line": 405, "text": "def run_extract_locations_from_patch(rank, \n                                  queue, log_queue, output_file_lock,\n                                  repo_playground, output_file, max_edit_file_num\n    "}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.5137388706207275, "line": 137, "text": "def merge_sample_locations(found_files, found_modules, found_entities, ranking_method='majority'):\n\n    def rank_locs(found_locs, ranking_method=\"majority\"):\n        flat_locs = [loc for sublist in fo"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.4357194900512695, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "build_bm25_index.py", "name": "", "type": "codeblock", "score": 2.4101366996765137, "line": 22, "text": "def run(rank, repo_queue, repo_path, out_path,\n        download_repo=False, instance_data=None, similarity_top_k=10):\n    while True:\n        try:\n            repo_name = repo_queue.get_nowait()\n     "}, {"file": "repo_index/file_context.py", "name": "", "type": "codeblock", "score": 2.3644323348999023, "line": 517, "text": "class FileContext:\n\n    def add_ranked_spans(\n        self,\n        ranked_spans: List[RankedFileSpan],\n        decay_rate: float = 1.05,\n        min_tokens: int = 50,\n    ):\n        if not ranked_spa"}, {"file": "dependency_graph/batch_build_graph.py", "name": "", "type": "codeblock", "score": 2.3051817417144775, "line": 1, "text": "import argparse\nimport json\nimport os\nimport pickle\nimport time\nfrom pathlib import Path\nimport subprocess\nimport torch.multiprocessing as mp\nimport os.path as osp\nfrom datasets import load_dataset\nfr"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 2.2964231967926025, "line": 296, "text": "def run_localize(rank, args, bug_queue, log_queue, output_file_lock, traj_file_lock):\n    queue_handler = logging.handlers.QueueHandler(log_queue)\n    logger = logging.getLogger()\n    logger.setLevel("}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.1234116554260254, "line": 55, "text": "def set_current_issue(instance_id: str = None, \n                      instance_data: dict = None,\n                      dataset: str = \"princeton-nlp/SWE-bench_Lite\", split: str = \"test\", rank=0):\n   "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 2.018803834915161, "line": 545, "text": "class CodeIndex:\n\n    def _found_class(self, block: CodeBlock, class_names: list[str]):\n        for class_name in class_names:\n            parent_class = block.find_type_in_parents(CodeBlockType.CLASS"}], "total_results": 10}
{"repo": "LocAgent", "query": "result formatting", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.2372798919677734, "line": 689, "text": "def get_entity_contents(entity_names: List[str]):\n    searcher = get_graph_entity_searcher()\n\n    result = ''\n    for name in entity_names:\n        name = name.strip().strip('.')\n        if not name: "}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.995542526245117, "line": 223, "text": "IN_CONTEXT_LEARNING_EXAMPLE_SUFFIX = \"\"\"\n--------------------- END OF NEW TASK DESCRIPTION ---------------------\n\nPLEASE follow the format strictly! PLEASE EMIT ONE AND ONLY ONE FUNCTION CALL PER MESS"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.5304391384124756, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.319060802459717, "line": 50, "text": "IN_CONTEXT_LEARNING_EXAMPLE_PREFIX = \"\"\"\nHere's a running example of how to perform a task with the provided tools.\n\n--------------------- START OF EXAMPLE ---------------------\n\nUSER: Create a list o"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.188103675842285, "line": 597, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    # ... other"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.9985713958740234, "line": 181, "text": "class CodeIndex:\n\n    def search(\n        self,\n        query: Optional[str] = None,\n        code_snippet: Optional[str] = None,\n        class_names: Optional[List[str]] = None,\n        function_names"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 1.920950174331665, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.8706340789794922, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7964434623718262, "line": 448, "text": "def rank_and_aggr_query_results(query_results, fixed_query_info_list):\n    query_info_list_dict = {}\n\n    for qr in query_results:\n        # Convert the query_info_list to a tuple so it can be used as"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7713013887405396, "line": 618, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    # ... other"}], "total_results": 10}
{"repo": "LocAgent", "query": "error handling", "top_10": [{"file": "repo_index/codeblocks/parser/python.py", "name": "", "type": "codeblock", "score": 2.0571908950805664, "line": 1, "text": "import logging\n\nfrom tree_sitter_languages import get_language\n\nfrom repo_index.codeblocks.codeblocks import (\n    CodeBlock,\n    CodeBlockType,\n    ReferenceScope,\n    RelationshipType,\n    Validatio"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.834051251411438, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 1.756543517112732, "line": 954, "text": "class CodeBlock(BaseModel):\n\n    def get_all_relationships(\n        self, exclude_types: Optional[List[CodeBlockType]] = None\n    ) -> List[Relationship]:\n        if exclude_types is None:\n           "}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 1.6598299741744995, "line": 756, "text": "def convert_from_multiple_tool_calls_to_single_tool_call_messages(\n    messages: list[dict],\n    ignore_final_tool_result: bool = False,\n) -> list[dict]:\n    \"\"\"Break one message with multiple tool ca"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.6076751947402954, "line": 144, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 1.5811512470245361, "line": 407, "text": "class CodeBlock(BaseModel):\n\n    def sync_indentation(self, original_block: 'CodeBlock', updated_block: 'CodeBlock'):\n        original_indentation_length = len(original_block.indentation) + len(\n     "}, {"file": "repo_index/file_context.py", "name": "", "type": "codeblock", "score": 1.5458078384399414, "line": 365, "text": "class ContextFile(BaseModel):\n\n    def expand_small_classes(self, max_tokens: int):\n        \"\"\"\n        Expand small classes with no other spans selected if the context allows it.\n\n        TODO: This "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.5380104780197144, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 1.518650770187378, "line": 24, "text": "def mean_shortest_distance(graph, list_a, list_b):\n    # Step 1: Compute shortest distances\n    mean_distances = []\n\n    for b in list_b:\n        shortest_dist_to_a = float('inf')  # Initialize with a"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 1.4679491519927979, "line": 1, "text": "import re\nfrom enum import Enum\nfrom typing import List, Optional, Set\n\nfrom pydantic import BaseModel, Field, root_validator, validator\nfrom typing_extensions import deprecated\n\nfrom repo_index.codeb"}], "total_results": 10}
{"repo": "LocAgent", "query": "logging configuration", "top_10": [{"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 3.5671675205230713, "line": 1, "text": "import os\nimport openai\nimport litellm\nimport pandas as pd\nimport time\nimport logging\nfrom util.utils import load_jsonl\nimport json\nimport argparse\nfrom datasets import load_dataset\n\n\n# Configure logg"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.450404167175293, "line": 1, "text": "import argparse\nimport os\nimport json\nimport torch\nfrom datasets import Dataset\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nfrom unsloth.chat_templates import get_c"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.8202159404754639, "line": 463, "text": "def generate_oracle_locations_for_data_file(dataset_file, n_limit,\n                                          max_edit_file_num=1, \n                                          repo_base_dir='playground/l"}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 1.714215636253357, "line": 68, "text": "def classify_with_retry(problem_statement, model, retries=3, delay=1):\n    for attempt in range(retries):\n        try:\n            category = classify_problem_statement(problem_statement, model=model)"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.6964519023895264, "line": 609, "text": "def main():\n    # ... other code\n    parser.add_argument(\"--simple_desc\", action=\"store_true\", \n                        help=\"Use simplified function descriptions due to certain LLM limitations. Set t"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.620788335800171, "line": 50, "text": "def main():\n    args = parse_args()\n    os.makedirs(os.path.join(args.output_dir, args.exp_name), exist_ok=True)\n    # save args to json\n    with open(os.path.join(args.output_dir, args.exp_name, \"arg"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.5793204307556152, "line": 703, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # Set documentation phase on comments in the start "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.5121625661849976, "line": 147, "text": "def auto_search_process(result_queue,\n                        model_name, messages, fake_user_msg,\n                        tools = None,\n                        traj_data=None,\n                       "}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 1.4589869976043701, "line": 1, "text": "import logging\nimport os\nimport subprocess\n\nlogger = logging.getLogger(__name__)\n\n\ndef setup_github_repo(repo: str, base_commit: str, base_dir: str = '/tmp/repos') -> str:\n    repo_name = get_repo_dir"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.4389547109603882, "line": 102, "text": "def apply_patch_str(patch, apply_file_path, hunk_size):\n    # Write the patch string to a temporary file\n    with tempfile.NamedTemporaryFile(delete=False, mode='w') as temp_patch_file:\n        temp_p"}], "total_results": 10}
{"repo": "LocAgent", "query": "test utilities", "top_10": [{"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 2.445535659790039, "line": 1, "text": "import os\nfrom typing import Optional\nfrom datasets import load_dataset\nfrom util.benchmark.git_repo_manager import setup_github_repo\nimport argparse\n\n\ndef load_instances(\n    dataset_name: str = \"pri"}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 2.1855952739715576, "line": 24, "text": "def setup_repo(\n    instance_data: Optional[dict] = None,\n    instance_id: str = None,\n    repo_base_dir: Optional[str] = None,\n    dataset: str = \"princeton-nlp/SWE-bench_Lite\",\n    split: str = \"tes"}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 2.1652493476867676, "line": 52, "text": "if __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dataset\", type=str, default=\"princeton-nlp/SWE-bench_Lite\")\n    parser.add_argument(\"--split\", type=str, de"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.13834285736084, "line": 1, "text": "import re\nfrom collections import defaultdict\nfrom typing import Optional, List\n\nimport networkx as nx\n\nfrom dependency_graph.build_graph import (\n    VALID_EDGE_TYPES, VALID_NODE_TYPES, \n    NODE_TYP"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.9459433555603027, "line": 513, "text": "if __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--repo_base_dir', type=str, default='playground/repo_base')\n    parser.add_argument('--output_dir', type=str,"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.9049838781356812, "line": 677, "text": "class CodeIndex:\n\n    def run_ingestion(\n        self,\n        repo_path: Optional[str] = None,\n        input_files: Optional[list[str]] = None,\n        num_workers: Optional[int] = None,\n    ):\n     "}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.9049838781356812, "line": 35, "text": "def build_code_retriever_from_repo(repo_path,\n                                   similarity_top_k=10,\n                                   min_chunk_size=100,\n                                   chunk_si"}, {"file": "plugins/location_tools/utils/compress_file.py", "name": "", "type": "codeblock", "score": 1.7326810359954834, "line": 52, "text": "code = \"\"\"\n\\\"\\\"\\\"\nthis is a module\n...\n\\\"\\\"\\\"\nconst = {1,2,3}\nimport os\n\nclass fooClass:\n    '''this is a class'''\n\n    def __init__(self, x):\n        '''initialization.'''\n        self.x = x\n\n    def"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.7230674028396606, "line": 559, "text": "class CodeIndex:\n\n    def _vector_search(\n        self,\n        query: str = '',\n        exact_query_match: bool = False,\n        category: str = 'implementation',\n        file_pattern: Optional[str] "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.6844615936279297, "line": 542, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n\n    files, _, "}], "total_results": 10}
{"repo": "LocAgent", "query": "benchmark metrics", "top_10": [{"file": "evaluation/eval_metric.py", "name": "", "type": "codeblock", "score": 3.27042555809021, "line": 381, "text": "def evaluate_results(loc_file, level2key_dict, \n                     dataset='czlll/SWE-bench_Lite', split='test', \n                     selected_list=None,\n                     metrics=['acc', 'ndcg'"}, {"file": "evaluation/eval_metric.py", "name": "", "type": "codeblock", "score": 3.117337465286255, "line": 214, "text": "def cal_metrics_w_file(gt_file, loc_file, key,\n                level,\n                k_values, # < 100\n                metrics=['acc', 'ndcg', 'precision', 'recall', 'map'],\n                filter_li"}, {"file": "evaluation/eval_metric.py", "name": "", "type": "codeblock", "score": 2.9091546535491943, "line": 317, "text": "def cal_metrics_w_dataset(loc_file, key,\n                eval_level,\n                dataset, split, \n                k_values,\n                metrics,\n                selected_list=None,\n           "}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.7876375913619995, "line": 160, "text": "def main():\n    # ... other code\n    print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n    print(f\"Peak reserved memory = {used_memory} GB.\")\n    print(f\"Peak "}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.6205874681472778, "line": 1, "text": "import os\nimport json\nimport re\nimport subprocess\nimport tempfile\nimport collections\nimport argparse\nimport logging\nimport logging.handlers\nfrom datetime import datetime\nfrom collections import defaul"}, {"file": "evaluation/eval_metric.py", "name": "", "type": "codeblock", "score": 1.5248268842697144, "line": 279, "text": "def cal_metrics_w_dataset(loc_file, key,\n                eval_level,\n                dataset, split, \n                k_values,\n                metrics,\n                selected_list=None,\n           "}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 1.485237717628479, "line": 1, "text": "import os\nfrom typing import Optional\nfrom datasets import load_dataset\nfrom util.benchmark.git_repo_manager import setup_github_repo\nimport argparse\n\n\ndef load_instances(\n    dataset_name: str = \"pri"}, {"file": "evaluation/eval_metric.py", "name": "", "type": "codeblock", "score": 1.4066553115844727, "line": 166, "text": "def cal_metrics_w_file(gt_file, loc_file, key,\n                level,\n                k_values, # < 100\n                metrics=['acc', 'ndcg', 'precision', 'recall', 'map'],\n                filter_li"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.3584047555923462, "line": 106, "text": "def main():\n    # ... other code\n\n\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=dataset,\n        dataset_text_field=\"text\",\n        max_seq_length="}, {"file": "util/benchmark/parse_patch.py", "name": "", "type": "codeblock", "score": 1.1803416013717651, "line": 1, "text": "import os\nimport re\nimport collections\nfrom tqdm import tqdm\nimport unidiff\nfrom unidiff.errors import UnidiffParseError\nimport json\nfrom collections import defaultdict\n\n\ndef get_oracle_filenames(patc"}], "total_results": 10}
{"repo": "LocAgent", "query": "find all functions in module", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.297377824783325, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.2423479557037354, "line": 156, "text": "def get_module_name_by_line_num(file_path: str, line_num: int):\n    # TODO: \n    # if the given line isn't in a function of a class and the class is large, \n    # find the nearest two member functions"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.0893657207489014, "line": 239, "text": "def parse_node_id(nid: str):\n    nfile = nid.split(':')[0]\n    nname = nid.split(':')[-1]\n    return nfile, nname\n\n\ndef search_entity_in_global_dict(term: str, include_files: Optional[List[str]] = Non"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.0090231895446777, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.9659037590026855, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.900587797164917, "line": 71, "text": "_TREE_EXAMPLE = \"\"\"\nExample Usage:\n1. Exploring Outward Dependencies:\n    ```\n    explore_tree_structure(\n        start_entities=['src/module_a.py:ClassA'],\n        direction='downstream',\n        tra"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.827147960662842, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.806138753890991, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "repo_index/file_context.py", "name": "", "type": "codeblock", "score": 2.7910494804382324, "line": 293, "text": "class ContextFile(BaseModel):\n\n    def add_line_span(self, start_line: int, end_line: int):\n        module = self.file.module\n\n        logger.info(f'Adding line span {start_line} - {end_line} to {self"}, {"file": "util/actions/action_parser.py", "name": "", "type": "codeblock", "score": 2.7208383083343506, "line": 104, "text": "class CodeActActionParserIPythonRunCell:\n    # def parse(self, action_str: str) -> list:\n    #     \"\"\"\n    #     Extracts and stores the commands within all <execute_ipython> tags.\n    #     \"\"\"\n    #"}], "total_results": 10}
{"repo": "LocAgent", "query": "locate class definition", "top_10": [{"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 4.125319480895996, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 3.0359301567077637, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.7731263637542725, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.582024097442627, "line": 63, "text": "FAKE_USER_MSG_FOR_LOC = (\n    'Verify if the found locations contain all the necessary information to address the issue, and check for any relevant references in other parts of the codebase that may n"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.516599416732788, "line": 298, "text": "def get_edit_entities_from_raw_locs(found_edit_locs, \n                                    searcher: RepoEntitySearcher,\n                                    ranking_method='majority',\n                 "}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 2.2903404235839844, "line": 1, "text": "import os\nimport json\nimport re\nimport subprocess\nimport tempfile\nimport collections\nimport argparse\nimport logging\nimport logging.handlers\nfrom datetime import datetime\nfrom collections import defaul"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.1754932403564453, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.0184996128082275, "line": 137, "text": "def merge_sample_locations(found_files, found_modules, found_entities, ranking_method='majority'):\n\n    def rank_locs(found_locs, ranking_method=\"majority\"):\n        flat_locs = [loc for sublist in fo"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.9392023086547852, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.792087435722351, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}], "total_results": 10}
{"repo": "LocAgent", "query": "search for import statements", "top_10": [{"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 3.5125956535339355, "line": 1, "text": "import os\nimport openai\nimport litellm\nimport pandas as pd\nimport time\nimport logging\nfrom util.utils import load_jsonl\nimport json\nimport argparse\nfrom datasets import load_dataset\n\n\n# Configure logg"}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 3.4265565872192383, "line": 39, "text": "# def preprocess_statement(statement):\n#     if not statement or not isinstance(statement, str):\n#         return \"\"\n#     max_length = 2000\n#     if len(statement) > max_length:\n#         return stat"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 3.005969524383545, "line": 144, "text": "def map_import_lines(codes):\n    in_import_statement = False\n    open_parens = 0\n    line_labels = {}  # Dictionary to store line number and its label (True/False)\n    for code in codes:\n        conte"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.9410083293914795, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.8970863819122314, "line": 36, "text": "class CodeBlockType(Enum):\n    MODULE = (\n        'Module',\n        CodeBlockTypeGroup.STRUCTURE,\n    )  # TODO: Module shouldn't be a STRUCTURE\n    CLASS = ('Class', CodeBlockTypeGroup.STRUCTURE)\n   "}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.7514829635620117, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.3587327003479004, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "repo_index/utils/xml.py", "name": "", "type": "codeblock", "score": 2.2866132259368896, "line": 1, "text": "import re\nfrom typing import List\n\n\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -> List[str]:\n    ext_list = re.findall(f'<{tag}>(.+?)</{tag}>', string, re.DOTALL)\n    if stri"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.254270315170288, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}, {"file": "plugins/location_tools/utils/util.py", "name": "", "type": "codeblock", "score": 2.22017240524292, "line": 1, "text": "from datasets import load_dataset\nimport os\nimport fnmatch\nfrom collections import defaultdict\nimport re\nfrom util.benchmark.setup_repo import setup_repo\n\n\n# SET THIS IF YOU WANT TO USE THE PREPROCESS"}], "total_results": 10}
{"repo": "LocAgent", "query": "find function calls to", "top_10": [{"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 3.4419474601745605, "line": 1, "text": "\"\"\"Convert function calling messages to non-function calling messages and vice versa.\n\nThis will inject prompts so that models that doesn't support function calling\ncan still be used with function cal"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 3.1916542053222656, "line": 237, "text": "def convert_tool_call_to_string(tool_call: dict) -> str:\n    \"\"\"Convert tool call to content in string format.\"\"\"\n    if 'function' not in tool_call:\n        raise FunctionCallConversionError(\"Tool ca"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.0002806186676025, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "util/runtime/exceptions.py", "name": "", "type": "codeblock", "score": 2.989229679107666, "line": 86, "text": "class OperationCancelled(Exception):\n    \"\"\"Exception raised when an operation is cancelled (e.g. by a keyboard interrupt).\"\"\"\n\n    def __init__(self, message='Operation was cancelled'):\n        super"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.950023889541626, "line": 223, "text": "IN_CONTEXT_LEARNING_EXAMPLE_SUFFIX = \"\"\"\n--------------------- END OF NEW TASK DESCRIPTION ---------------------\n\nPLEASE follow the format strictly! PLEASE EMIT ONE AND ONLY ONE FUNCTION CALL PER MESS"}, {"file": "util/runtime/function_calling.py", "name": "", "type": "codeblock", "score": 2.7566237449645996, "line": 2, "text": "\"\"\"This file contains the function calling implementation for different actions.\n\"\"\"\n\nimport json\nfrom litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    Model"}, {"file": "util/runtime/function_calling.py", "name": "", "type": "codeblock", "score": 2.711670398712158, "line": 41, "text": "def response_to_actions(response: ModelResponse) -> list[Action]:\n    actions: list[Action] = []\n    assert len(response.choices) == 1, 'Only one choice is supported for now'\n    assistant_msg = respo"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.6836371421813965, "line": 307, "text": "def convert_fncall_messages_to_non_fncall_messages(\n    messages: list[dict],\n    tools: list[ChatCompletionToolParam],\n    add_in_context_learning_example: bool = True,\n) -> list[dict]:\n    \"\"\"Conver"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 2.678252696990967, "line": 563, "text": "def convert_non_fncall_messages_to_fncall_messages(\n    messages: list[dict],\n    tools: list[ChatCompletionToolParam],\n) -> list[dict]:\n    \"\"\"Convert non-function calling messages back to function c"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.405034303665161, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}], "total_results": 10}
{"repo": "LocAgent", "query": "locate error handling code", "top_10": [{"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 3.559429883956909, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 3.0421533584594727, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 3.0214436054229736, "line": 298, "text": "def get_edit_entities_from_raw_locs(found_edit_locs, \n                                    searcher: RepoEntitySearcher,\n                                    ranking_method='majority',\n                 "}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.944714307785034, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.582024097442627, "line": 63, "text": "FAKE_USER_MSG_FOR_LOC = (\n    'Verify if the found locations contain all the necessary information to address the issue, and check for any relevant references in other parts of the codebase that may n"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.4732861518859863, "line": 33, "text": "def handle_edge_cases(code):\n    # hard-coded edge cases\n    code = code.replace('\\ufeff', '')\n    code = code.replace('constants.False', '_False')\n    code = code.replace('constants.True', '_True')\n "}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.3515872955322266, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.332179069519043, "line": 144, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.286611318588257, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.193427324295044, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}], "total_results": 10}
{"repo": "LocAgent", "query": "search for docstrings", "top_10": [{"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.8093104362487793, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.6836905479431152, "line": 782, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "dependency_graph/__init__.py", "name": "", "type": "codeblock", "score": 2.0546653270721436, "line": 1, "text": "# from dependency_graph.traverse_graph import RepoSearcher\nfrom dependency_graph.traverse_graph import (\n    RepoEntitySearcher, \n    RepoDependencySearcher,\n    traverse_tree_structure,\n    traverse_"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.95687997341156, "line": 34, "text": "# class ClassDocstringVisitor(cst.CSTVisitor):\n#     def __init__(self):\n#         self.class_docstrings = []\n\n#     def visit_ClassDef(self, node: cst.ClassDef):\n#         # Extract the docstring if "}, {"file": "plugins/__init__.py", "name": "", "type": "codeblock", "score": 1.8995448350906372, "line": 1, "text": "# Requirements\nfrom plugins.location_tools import (\n    # AgentSkillsPlugin,\n    LocationToolsRequirement,\n)\n# from openhands.runtime.plugins.jupyter import JupyterPlugin, JupyterRequirement\nfrom plug"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.779942512512207, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.7692325115203857, "line": 703, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # Set documentation phase on comments in the start "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7068397998809814, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.6128168106079102, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5676873922348022, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}], "total_results": 10}
{"repo": "LocAgent", "query": "find test cases for", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 4.031057357788086, "line": 239, "text": "def parse_node_id(nid: str):\n    nfile = nid.split(':')[0]\n    nname = nid.split(':')[-1]\n    return nfile, nname\n\n\ndef search_entity_in_global_dict(term: str, include_files: Optional[List[str]] = Non"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.13834285736084, "line": 1, "text": "import re\nfrom collections import defaultdict\nfrom typing import Optional, List\n\nimport networkx as nx\n\nfrom dependency_graph.build_graph import (\n    VALID_EDGE_TYPES, VALID_NODE_TYPES, \n    NODE_TYP"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.1060128211975098, "line": 319, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        found_entities_dict = search_entity_in_global_dict(term, include_files)\n        if "}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.9049838781356812, "line": 35, "text": "def build_code_retriever_from_repo(repo_path,\n                                   similarity_top_k=10,\n                                   min_chunk_size=100,\n                                   chunk_si"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.9049838781356812, "line": 677, "text": "class CodeIndex:\n\n    def run_ingestion(\n        self,\n        repo_path: Optional[str] = None,\n        input_files: Optional[list[str]] = None,\n        num_workers: Optional[int] = None,\n    ):\n     "}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 1.7949516773223877, "line": 24, "text": "def mean_shortest_distance(graph, list_a, list_b):\n    # Step 1: Compute shortest distances\n    mean_distances = []\n\n    for b in list_b:\n        shortest_dist_to_a = float('inf')  # Initialize with a"}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 1.7708712816238403, "line": 1, "text": "import os\nfrom typing import Optional\nfrom datasets import load_dataset\nfrom util.benchmark.git_repo_manager import setup_github_repo\nimport argparse\n\n\ndef load_instances(\n    dataset_name: str = \"pri"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.7230674028396606, "line": 559, "text": "class CodeIndex:\n\n    def _vector_search(\n        self,\n        query: str = '',\n        exact_query_match: bool = False,\n        category: str = 'implementation',\n        file_pattern: Optional[str] "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.7122293710708618, "line": 33, "text": "def handle_edge_cases(code):\n    # hard-coded edge cases\n    code = code.replace('\\ufeff', '')\n    code = code.replace('constants.False', '_False')\n    code = code.replace('constants.True', '_True')\n "}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 1.7055877447128296, "line": 24, "text": "def setup_repo(\n    instance_data: Optional[dict] = None,\n    instance_id: str = None,\n    repo_base_dir: Optional[str] = None,\n    dataset: str = \"princeton-nlp/SWE-bench_Lite\",\n    split: str = \"tes"}], "total_results": 10}
{"repo": "LocAgent", "query": "locate configuration", "top_10": [{"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 2.688467025756836, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.582024097442627, "line": 63, "text": "FAKE_USER_MSG_FOR_LOC = (\n    'Verify if the found locations contain all the necessary information to address the issue, and check for any relevant references in other parts of the codebase that may n"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.516599416732788, "line": 298, "text": "def get_edit_entities_from_raw_locs(found_edit_locs, \n                                    searcher: RepoEntitySearcher,\n                                    ranking_method='majority',\n                 "}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.450404167175293, "line": 1, "text": "import argparse\nimport os\nimport json\nimport torch\nfrom datasets import Dataset\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nfrom unsloth.chat_templates import get_c"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.411088228225708, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.0184996128082275, "line": 137, "text": "def merge_sample_locations(found_files, found_modules, found_entities, ranking_method='majority'):\n\n    def rank_locs(found_locs, ranking_method=\"majority\"):\n        flat_locs = [loc for sublist in fo"}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 1.8448179960250854, "line": 1, "text": "import os\nimport openai\nimport litellm\nimport pandas as pd\nimport time\nimport logging\nfrom util.utils import load_jsonl\nimport json\nimport argparse\nfrom datasets import load_dataset\n\n\n# Configure logg"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.792087435722351, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.620788335800171, "line": 50, "text": "def main():\n    args = parse_args()\n    os.makedirs(os.path.join(args.output_dir, args.exp_name), exist_ok=True)\n    # save args to json\n    with open(os.path.join(args.output_dir, args.exp_name, \"arg"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.5793204307556152, "line": 703, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # Set documentation phase on comments in the start "}], "total_results": 10}
{"repo": "LocAgent", "query": "search for main entry point", "top_10": [{"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 3.9404168128967285, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.771182060241699, "line": 160, "text": "def main():\n    # ... other code\n    print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n    print(f\"Peak reserved memory = {used_memory} GB.\")\n    print(f\"Peak "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.736367702484131, "line": 741, "text": "def main():\n    # Generate Dependency Graph\n    graph = build_graph(args.repo_path, global_import=args.global_import)\n\n    if args.visualize:\n        visualize_graph(graph)\n\n    inherit_list = []\n    "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 2.42195200920105, "line": 609, "text": "def main():\n    # ... other code\n    parser.add_argument(\"--simple_desc\", action=\"store_true\", \n                        help=\"Use simplified function descriptions due to certain LLM limitations. Set t"}, {"file": "util/utils.py", "name": "", "type": "codeblock", "score": 2.3048343658447266, "line": 1, "text": "import json\nimport os\n\n\ndef convert_to_json(obj):\n    if isinstance(obj, list):\n        res_obj = []\n        for o in obj:\n            try:\n                json_o = json.loads(o.model_dump_json())\n   "}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.0811336040496826, "line": 50, "text": "def main():\n    args = parse_args()\n    os.makedirs(os.path.join(args.output_dir, args.exp_name), exist_ok=True)\n    # save args to json\n    with open(os.path.join(args.output_dir, args.exp_name, \"arg"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.0045220851898193, "line": 106, "text": "def main():\n    # ... other code\n\n\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=dataset,\n        dataset_text_field=\"text\",\n        max_seq_length="}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.887282133102417, "line": 578, "text": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--localize\", action=\"store_true\")\n    parser.add_argument(\"--merge\", action=\"store_true\")\n    parser.add_argument(\"--use_exa"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.779942512512207, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7068397998809814, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}], "total_results": 10}
{"repo": "LocAgent", "query": "find exception handlers", "top_10": [{"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 3.4558303356170654, "line": 405, "text": "def run_extract_locations_from_patch(rank, \n                                  queue, log_queue, output_file_lock,\n                                  repo_playground, output_file, max_edit_file_num\n    "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 2.5389671325683594, "line": 485, "text": "def localize(args):\n    bench_data = load_dataset(args.dataset, split=args.split)\n    bench_tests = filter_dataset(bench_data, 'instance_id', args.used_list)\n    if args.eval_n_limit:\n        eval_n_l"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 2.4864652156829834, "line": 463, "text": "def generate_oracle_locations_for_data_file(dataset_file, n_limit,\n                                          max_edit_file_num=1, \n                                          repo_base_dir='playground/l"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 2.236616611480713, "line": 296, "text": "def run_localize(rank, args, bug_queue, log_queue, output_file_lock, traj_file_lock):\n    queue_handler = logging.handlers.QueueHandler(log_queue)\n    logger = logging.getLogger()\n    logger.setLevel("}, {"file": "util/runtime/exceptions.py", "name": "", "type": "codeblock", "score": 1.682554006576538, "line": 86, "text": "class OperationCancelled(Exception):\n    \"\"\"Exception raised when an operation is cancelled (e.g. by a keyboard interrupt).\"\"\"\n\n    def __init__(self, message='Operation was cancelled'):\n        super"}, {"file": "util/runtime/exceptions.py", "name": "", "type": "codeblock", "score": 1.6238622665405273, "line": 1, "text": "class AgentNoInstructionError(Exception):\n    def __init__(self, message='Instruction must be provided'):\n        super().__init__(message)\n\n\nclass AgentEventTypeError(Exception):\n    def __init__(sel"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.598156213760376, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.5519897937774658, "line": 1, "text": "import os\nimport json\nimport re\nimport subprocess\nimport tempfile\nimport collections\nimport argparse\nimport logging\nimport logging.handlers\nfrom datetime import datetime\nfrom collections import defaul"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5371854305267334, "line": 319, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        found_entities_dict = search_entity_in_global_dict(term, include_files)\n        if "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 1.5347532033920288, "line": 141, "text": "class CodeIndex:\n\n    @classmethod\n    def from_url(cls, url: str, persist_dir: str, file_repo: FileRepository):\n        try:\n            response = requests.get(url, stream=True)\n            response"}], "total_results": 10}
{"repo": "LocAgent", "query": "locate utility functions", "top_10": [{"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 4.104702472686768, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 3.704035997390747, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 3.0723021030426025, "line": 63, "text": "FAKE_USER_MSG_FOR_LOC = (\n    'Verify if the found locations contain all the necessary information to address the issue, and check for any relevant references in other parts of the codebase that may n"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.9829306602478027, "line": 298, "text": "def get_edit_entities_from_raw_locs(found_edit_locs, \n                                    searcher: RepoEntitySearcher,\n                                    ranking_method='majority',\n                 "}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.8331594467163086, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.5614354610443115, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.428140878677368, "line": 137, "text": "def merge_sample_locations(found_files, found_modules, found_entities, ranking_method='majority'):\n\n    def rank_locs(found_locs, ranking_method=\"majority\"):\n        flat_locs = [loc for sublist in fo"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.3089048862457275, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.30220627784729, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.7993824481964111, "line": 166, "text": "ExploreTreeStructure = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='explore_tree_structure',\n        description=_STRUCTURE_EXPLORER_D"}], "total_results": 10}
{"repo": "LocAgent", "query": "search for constants", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.510800838470459, "line": 33, "text": "def handle_edge_cases(code):\n    # hard-coded edge cases\n    code = code.replace('\\ufeff', '')\n    code = code.replace('constants.False', '_False')\n    code = code.replace('constants.True', '_True')\n "}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.779942512512207, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7068397998809814, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.6128168106079102, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5676873922348022, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5409942865371704, "line": 542, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n\n    files, _, "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5157586336135864, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.4740337133407593, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n\n_SEARCHENTITY_DESCRIPTION = \"\"\"\nSearches the codebase to retrieve the complete imple"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.3701319694519043, "line": 782, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "repo_index/utils/xml.py", "name": "", "type": "codeblock", "score": 1.3695151805877686, "line": 1, "text": "import re\nfrom typing import List\n\n\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -> List[str]:\n    ext_list = re.findall(f'<{tag}>(.+?)</{tag}>', string, re.DOTALL)\n    if stri"}], "total_results": 10}
{"repo": "LocAgent", "query": "find type annotations", "top_10": [{"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 2.3655145168304443, "line": 137, "text": "class GlobalVariableVisitor(cst.CSTVisitor):\n    METADATA_DEPENDENCIES = (cst.metadata.PositionProvider,)\n\n    def __init__(self):\n        self.global_assigns = []\n\n    def leave_Module(self, original"}, {"file": "repo_index/codeblocks/module.py", "name": "", "type": "codeblock", "score": 1.764121174812317, "line": 50, "text": "class Module(CodeBlock):\n\n    def find_related_span_ids(self, span_id: str) -> Set[str]:\n        related_span_ids = set()\n\n        blocks = self.find_blocks_by_span_id(span_id)\n        for block in bl"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.6632429361343384, "line": 156, "text": "def get_module_name_by_line_num(file_path: str, line_num: int):\n    # TODO: \n    # if the given line isn't in a function of a class and the class is large, \n    # find the nearest two member functions"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.617933750152588, "line": 239, "text": "def parse_node_id(nid: str):\n    nfile = nid.split(':')[0]\n    nname = nid.split(':')[-1]\n    return nfile, nname\n\n\ndef search_entity_in_global_dict(term: str, include_files: Optional[List[str]] = Non"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.598156213760376, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 1.381080150604248, "line": 954, "text": "class CodeBlock(BaseModel):\n\n    def get_all_relationships(\n        self, exclude_types: Optional[List[CodeBlockType]] = None\n    ) -> List[Relationship]:\n        if exclude_types is None:\n           "}, {"file": "repo_index/file_context.py", "name": "", "type": "codeblock", "score": 1.3731529712677002, "line": 293, "text": "class ContextFile(BaseModel):\n\n    def add_line_span(self, start_line: int, end_line: int):\n        module = self.file.module\n\n        logger.info(f'Adding line span {start_line} - {end_line} to {self"}, {"file": "repo_index/file_context.py", "name": "", "type": "codeblock", "score": 1.360536813735962, "line": 273, "text": "class ContextFile(BaseModel):\n\n    def add_span(\n        self,\n        span_id: str,\n        tokens: Optional[int] = None,\n    ):\n        existing_span = next(\n            (span for span in self.spans"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.3359878063201904, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.3347082138061523, "line": 319, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        found_entities_dict = search_entity_in_global_dict(term, include_files)\n        if "}], "total_results": 10}
{"repo": "LocAgent", "query": "locate module exports", "top_10": [{"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 3.8572397232055664, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 3.617173671722412, "line": 36, "text": "class CodeBlockType(Enum):\n    MODULE = (\n        'Module',\n        CodeBlockTypeGroup.STRUCTURE,\n    )  # TODO: Module shouldn't be a STRUCTURE\n    CLASS = ('Class', CodeBlockTypeGroup.STRUCTURE)\n   "}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 3.6131019592285156, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 3.5755655765533447, "line": 298, "text": "def get_edit_entities_from_raw_locs(found_edit_locs, \n                                    searcher: RepoEntitySearcher,\n                                    ranking_method='majority',\n                 "}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 2.688467025756836, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.676823139190674, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.582024097442627, "line": 63, "text": "FAKE_USER_MSG_FOR_LOC = (\n    'Verify if the found locations contain all the necessary information to address the issue, and check for any relevant references in other parts of the codebase that may n"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.256528854370117, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 2.0184996128082275, "line": 137, "text": "def merge_sample_locations(found_files, found_modules, found_entities, ranking_method='majority'):\n\n    def rank_locs(found_locs, ranking_method=\"majority\"):\n        flat_locs = [loc for sublist in fo"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.792087435722351, "line": 96, "text": "def parse_comment_nodes(target_file):\n    comment_nodes = []\n    with open(target_file, 'r') as f:\n        source_code = f.read()\n    # Tokenize the source code to find comments and their locations\n  "}], "total_results": 10}
{"repo": "LocAgent", "query": "search for decorators", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.8440475463867188, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.779942512512207, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7068397998809814, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.6128168106079102, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5676873922348022, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5409942865371704, "line": 542, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n\n    files, _, "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.5157586336135864, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.4740337133407593, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n\n_SEARCHENTITY_DESCRIPTION = \"\"\"\nSearches the codebase to retrieve the complete imple"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.3701319694519043, "line": 782, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "repo_index/utils/xml.py", "name": "", "type": "codeblock", "score": 1.3695151805877686, "line": 1, "text": "import re\nfrom typing import List\n\n\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -> List[str]:\n    ext_list = re.findall(f'<{tag}>(.+?)</{tag}>', string, re.DOTALL)\n    if stri"}], "total_results": 10}
{"repo": "LocAgent", "query": "parse Python AST", "top_10": [{"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 5.600128173828125, "line": 217, "text": "def parse_python_file(file_path, file_content=None):\n    \"\"\"Parse a Python file to extract class and function definitions with their line numbers.\n    :param file_path: Path to the Python file.\n    :r"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 4.109907150268555, "line": 1, "text": "import libcst as cst\nimport libcst.matchers as m\nimport ast\nimport tokenize\nfrom io import StringIO\nimport logging\n# from libcst.display import dump\n\n\ndef parse_class_docstrings(target_file: str) -> l"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.2141523361206055, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.0272274017333984, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 3.0055887699127197, "line": 34, "text": "# class ClassDocstringVisitor(cst.CSTVisitor):\n#     def __init__(self):\n#         self.class_docstrings = []\n\n#     def visit_ClassDef(self, node: cst.ClassDef):\n#         # Extract the docstring if "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.961493730545044, "line": 518, "text": "def analyze_init(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    invocations = []\n    inherita"}, {"file": "repo_index/codeblocks/parser/python.py", "name": "", "type": "codeblock", "score": 2.88499116897583, "line": 1, "text": "import logging\n\nfrom tree_sitter_languages import get_language\n\nfrom repo_index.codeblocks.codeblocks import (\n    CodeBlock,\n    CodeBlockType,\n    ReferenceScope,\n    RelationshipType,\n    Validatio"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.393083095550537, "line": 176, "text": "# Parese the given file, use CodeAnalyzer to extract classes and helper functions from the file\ndef analyze_file(filepath):\n    with open(filepath, 'r') as file:\n        code = file.read()\n        # c"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.1820156574249268, "line": 152, "text": "class CodeAnalyzer(ast.NodeVisitor):\n\n    def _visit_func(self, node):\n        function_name = node.name\n        full_function_name = '.'.join(self.node_name_stack + [function_name])\n        self.node"}, {"file": "repo_index/codeblocks/parser/create.py", "name": "", "type": "codeblock", "score": 2.1393051147460938, "line": 1, "text": "from typing import Optional\n\nfrom repo_index.codeblocks.parser.parser import CodeParser\nfrom repo_index.codeblocks.parser.python import PythonParser\n\n\ndef is_supported(language: str) -> bool:\n    retu"}], "total_results": 10}
{"repo": "LocAgent", "query": "build dependency graph", "top_10": [{"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 4.20932674407959, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.7508745193481445, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.549826145172119, "line": 741, "text": "def main():\n    # Generate Dependency Graph\n    graph = build_graph(args.repo_path, global_import=args.global_import)\n\n    if args.visualize:\n        visualize_graph(graph)\n\n    inherit_list = []\n    "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.4716310501098633, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.159403085708618, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.929741621017456, "line": 283, "text": "# Traverse all the Python files under repo_path, construct dependency graphs \n# with node types: directory, file, class, function\ndef build_graph(repo_path, fuzzy_search=True, global_import=False):\n  "}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.6474199295043945, "line": 175, "text": "class ReferenceScope(str, Enum):\n    EXTERNAL = 'external'\n    DEPENDENCY = 'dependency'  # External dependency\n    FILE = 'file'  # File in repository\n    PROJECT = 'project'\n    CLASS = 'class'\n    "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.47920298576355, "line": 1, "text": "import argparse\nimport ast\nimport os\nimport re\nfrom collections import Counter, defaultdict\nfrom typing import List\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.374251127243042, "line": 71, "text": "_TREE_EXAMPLE = \"\"\"\nExample Usage:\n1. Exploring Outward Dependencies:\n    ```\n    explore_tree_structure(\n        start_entities=['src/module_a.py:ClassA'],\n        direction='downstream',\n        tra"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.2905020713806152, "line": 453, "text": "def get_inner_nodes(query_node, src_node, graph):\n    inner_nodes = []\n    for _, dst_node, attr in graph.edges(src_node, data=True):\n        if attr['type'] == EDGE_TYPE_CONTAINS and dst_node != quer"}], "total_results": 10}
{"repo": "LocAgent", "query": "create BM25 index", "top_10": [{"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 2.6838555335998535, "line": 1, "text": "import os\nimport pickle\nimport Stemmer\nimport fnmatch\nimport mimetypes\nfrom typing import Dict, List, Optional\n\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core import Document"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.5943498611450195, "line": 378, "text": "def search_entity(query_info, include_files: List[str] = None):\n    # ... other code\n    if continue_search:\n        module_nids = []\n\n        # append the file name to keyword?\n        # # if not any"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.4009435176849365, "line": 810, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        #        parent_block_path=current_span.parent_bloc"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.239271879196167, "line": 905, "text": "def _validate_graph_explorer_inputs(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 1,\n        node_type_filter: Optional[List[str]] = None,\n "}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 2.1204257011413574, "line": 1, "text": "import re\nimport time\nfrom collections.abc import Callable, Sequence\nfrom typing import Any, Optional\n\nfrom llama_index.core.bridge.pydantic import Field\nfrom llama_index.core.callbacks import Callbac"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.0865187644958496, "line": 290, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/index/simple_faiss.py", "name": "", "type": "codeblock", "score": 2.0365700721740723, "line": 260, "text": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    @classmethod\n    def from_persist_dir(\n        cls, persist_dir: str, fs: Optional[fsspec.AbstractFileSystem] = None\n    ) -> 'SimpleFaissVe"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.9689218997955322, "line": 782, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.9002989530563354, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.8225780725479126, "line": 123, "text": "def build_module_retriever_from_graph(graph_path: Optional[str] = None,\n                                      entity_searcher: Optional[RepoEntitySearcher] = None,\n                                    "}], "total_results": 10}
{"repo": "LocAgent", "query": "tokenize code blocks", "top_10": [{"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 3.8510653972625732, "line": 469, "text": "class CodeIndex:\n\n    def find_by_name(\n        self,\n        class_names: Optional[List[str]] = None,\n        function_names: Optional[List[str]] = None,\n        file_pattern: Optional[str] = None,\n "}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 3.290142297744751, "line": 42, "text": "class EpicSplitter(NodeParser):\n    language: str = Field(\n        default=\"python\", description=\"Language of the code blocks to parse.\"\n    )\n\n    text_splitter: TextSplitter = Field(\n        descrip"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 3.046023368835449, "line": 184, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 2.9285173416137695, "line": 464, "text": "class EpicSplitter(NodeParser):\n\n    def _contains_block_paths(self, codeblock: CodeBlock, block_paths: list[list[str]]):\n        return [\n            block_path\n            for block_path in block_pa"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.9107720851898193, "line": 430, "text": "class CodeBlock(BaseModel):\n\n    def replace_by_path(self, path: List[str], new_block: 'CodeBlock'):\n        if not path:\n            return\n\n        for i, child in enumerate(self.children):\n        "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.8827931880950928, "line": 834, "text": "class CodeParser:\n\n    def _create_span_id(self, block: CodeBlock, label: Optional[str] = None):\n        if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n            structure_block = block\n      "}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.7910871505737305, "line": 247, "text": "class Parameter(BaseModel):\n    identifier: str = Field(description='The identifier of the parameter.')\n    type: Optional[str] = Field(description='The type of the parameter.')\n\n\nclass SpanType(str, "}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.78690767288208, "line": 810, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        #        parent_block_path=current_span.parent_bloc"}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 2.7519192695617676, "line": 1, "text": "import re\nimport time\nfrom collections.abc import Callable, Sequence\nfrom typing import Any, Optional\n\nfrom llama_index.core.bridge.pydantic import Field\nfrom llama_index.core.callbacks import Callbac"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 2.610448122024536, "line": 307, "text": "class CodeParser:\n\n    def parse_code(\n        self,\n        content_bytes: bytes,\n        node: Node,\n        start_byte: int = 0,\n        level: int = 0,\n        file_path: Optional[str] = None,\n   "}], "total_results": 10}
{"repo": "LocAgent", "query": "extract function signature", "top_10": [{"file": "plugins/location_tools/locationtools.py", "name": "", "type": "codeblock", "score": 3.4234275817871094, "line": 1, "text": "from inspect import signature\n\nfrom plugins.location_tools import repo_ops, retriever\nfrom plugins.location_tools.utils.dependency import import_functions\n\n# import_functions(\n#     module=retriever, "}, {"file": "util/actions/action_parser.py", "name": "", "type": "codeblock", "score": 2.318523406982422, "line": 125, "text": "class CodeActActionParserIPythonRunCell:\n\n    def extract_function(self, code_str):\n        \"\"\"\n        Extracts the function name and arguments from a string like `open_file('app.py')`.\n        \"\"\"\n "}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.2109317779541016, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 2.0564053058624268, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 2.0239505767822266, "line": 1, "text": "import os\nimport json\nimport re\nimport subprocess\nimport tempfile\nimport collections\nimport argparse\nimport logging\nimport logging.handlers\nfrom datetime import datetime\nfrom collections import defaul"}, {"file": "plugins/location_tools/utils/util.py", "name": "", "type": "codeblock", "score": 1.988323450088501, "line": 34, "text": "def get_meta_data(target_id, dataset:str=\"princeton-nlp/SWE-bench_Lite\", split:str = \"test\"):\n    swe_bench_data = load_dataset(dataset, split=split)\n    bench_data = [x for x in swe_bench_data if x[\""}, {"file": "util/actions/action_parser.py", "name": "", "type": "codeblock", "score": 1.925680160522461, "line": 72, "text": "class CodeActActionParserIPythonRunCell:\n    def __init__(self):\n        self.commands = []\n\n    def check_condition(self, action_str: str) -> bool:\n        python_code = re.search(\n            r'<exe"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.8542752265930176, "line": 176, "text": "# Parese the given file, use CodeAnalyzer to extract classes and helper functions from the file\ndef analyze_file(filepath):\n    with open(filepath, 'r') as file:\n        code = file.read()\n        # c"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.778397560119629, "line": 217, "text": "def parse_python_file(file_path, file_content=None):\n    \"\"\"Parse a Python file to extract class and function definitions with their line numbers.\n    :param file_path: Path to the Python file.\n    :r"}, {"file": "util/process_output.py", "name": "", "type": "codeblock", "score": 1.772271752357483, "line": 104, "text": "def extract_python_file_path(line, valid_folders):\n    \"\"\"\n    Extracts the Python file path from a given line of text.\n\n    Parameters:\n    - line (str): A line of text that may contain a Python file"}], "total_results": 10}
{"repo": "LocAgent", "query": "resolve qualified names", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.628230571746826, "line": 176, "text": "# Parese the given file, use CodeAnalyzer to extract classes and helper functions from the file\ndef analyze_file(filepath):\n    with open(filepath, 'r') as file:\n        code = file.read()\n        # c"}, {"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.4471487998962402, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 2.163774013519287, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.9466276168823242, "line": 256, "text": "def resolve_symlink(file_path):\n    \"\"\"\n    Resolve the absolute path of a symbolic link.\n    \n    Args:\n        file_path (str): The symbolic link file path.\n    \n    Returns:\n        str: The absolu"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.415470838546753, "line": 689, "text": "def get_entity_contents(entity_names: List[str]):\n    searcher = get_graph_entity_searcher()\n\n    result = ''\n    for name in entity_names:\n        name = name.strip().strip('.')\n        if not name: "}, {"file": "plugins/location_tools/utils/dependency.py", "name": "", "type": "codeblock", "score": 1.3389697074890137, "line": 1, "text": "from types import ModuleType\n\n\ndef import_functions(\n    module: ModuleType, function_names: list[str], target_globals: dict\n) -> None:\n    for name in function_names:\n        if hasattr(module, name)"}, {"file": "util/benchmark/parse_python_file.py", "name": "", "type": "codeblock", "score": 1.3000297546386719, "line": 217, "text": "def parse_python_file(file_path, file_content=None):\n    \"\"\"Parse a Python file to extract class and function definitions with their line numbers.\n    :param file_path: Path to the Python file.\n    :r"}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.2805986404418945, "line": 69, "text": "# def get_module_from_line_number_with_file_structure(line, file_structure, include_class=False, merge_init=True):\ndef get_module_from_line_number_with_file_structure(line, file_structure, \n          "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 1.2661794424057007, "line": 31, "text": "def add_quotes_to_nodes(G):\n    H = nx.MultiDiGraph()\n\n    # Map old node names to new node names\n    node_mapping = {node: f'\"{node}\"' for node in G.nodes}\n\n    # Add nodes with updated names and cop"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.25332772731781, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n\n_SEARCHENTITY_DESCRIPTION = \"\"\"\nSearches the codebase to retrieve the complete imple"}], "total_results": 10}
{"repo": "LocAgent", "query": "traverse call graph", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 4.600194931030273, "line": 581, "text": "def analyze_invokes(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    # store all the invokes fo"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 4.490260124206543, "line": 716, "text": "def traverse_directory_structure(graph, root='/'):\n    def traverse(node, prefix, is_last):\n        if node == root:\n            print(f\"{node}\")\n            new_prefix = ''\n        else:\n            "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 4.0211286544799805, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.707601308822632, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.386526107788086, "line": 365, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n\n    # check last traversed directory\n    while len(dir_stack) > 0:\n        if not dir_include_stack[-1]:\n            graph.remove_n"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.2989249229431152, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 3.1623239517211914, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.9123940467834473, "line": 283, "text": "# Traverse all the Python files under repo_path, construct dependency graphs \n# with node types: directory, file, class, function\ndef build_graph(repo_path, fuzzy_search=True, global_import=False):\n  "}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.8129472732543945, "line": 198, "text": "class RepoDependencySearcher:\n    \"\"\"Traverse Repository Graph\"\"\"\n\n    def __init__(self, graph):\n        self.G = graph\n        self._etypes_dict = {\n            etype: i for i, etype in enumerate(VA"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.7490038871765137, "line": 518, "text": "def analyze_init(node, code_tree, graph, repo_path):\n    caller_name = node.split(':')[-1].split('.')[-1]\n    file_path = os.path.join(repo_path, node.split(':')[0])\n\n    invocations = []\n    inherita"}], "total_results": 10}
{"repo": "LocAgent", "query": "filter directories", "top_10": [{"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.841273307800293, "line": 44, "text": "_STRUCTURE_EXPLORER_DESCRIPTION = \"\"\"\nUnified repository exploring tool that traverses a pre-built code graph to retrieve dependency structure around specified entities.\nThe search can be controlled t"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.598421335220337, "line": 969, "text": "def explore_tree_structure(\n        start_entities: List[str],\n        direction: str = 'downstream',\n        traversal_depth: int = 2,\n        entity_type_filter: Optional[List[str]] = None,\n        "}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 2.54182767868042, "line": 1, "text": "from litellm import (\n    ChatCompletionToolParam,\n    ChatCompletionToolParamFunctionChunk,\n    ModelResponse,\n)\n\n_STRUCTURE_EXPLORER_DESCRIPTION_simple = \"\"\"\nA unified tool that traverses a pre-buil"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.2353415489196777, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 2.1880807876586914, "line": 559, "text": "class CodeIndex:\n\n    def _vector_search(\n        self,\n        query: str = '',\n        exact_query_match: bool = False,\n        category: str = 'implementation',\n        file_pattern: Optional[str] "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.9783837795257568, "line": 50, "text": "# litellm.set_verbose=True\n# os.environ['LITELLM_LOG'] = 'DEBUG\n\n\ndef filter_dataset(dataset, filter_column: str, used_list: str):\n    file_path = os.path.join(os.path.dirname(os.path.abspath(__file__"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.7819775342941284, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "util/runtime/structure_tools.py", "name": "", "type": "codeblock", "score": 1.7773404121398926, "line": 114, "text": "_STRUCTURE_EXPLORER_PARAMETERS = {\n    'type': 'object',\n    'properties': {\n        'start_entities': {\n            'description': (\n                'List of entities (e.g., class, function, file, or"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 1.6914687156677246, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 1.6111974716186523, "line": 256, "text": "def resolve_symlink(file_path):\n    \"\"\"\n    Resolve the absolute path of a symbolic link.\n    \n    Args:\n        file_path (str): The symbolic link file path.\n    \n    Returns:\n        str: The absolu"}], "total_results": 10}
{"repo": "LocAgent", "query": "serialize graph data", "top_10": [{"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 4.365196704864502, "line": 741, "text": "def main():\n    # Generate Dependency Graph\n    graph = build_graph(args.repo_path, global_import=args.global_import)\n\n    if args.visualize:\n        visualize_graph(graph)\n\n    inherit_list = []\n    "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 3.9013657569885254, "line": 453, "text": "def get_inner_nodes(query_node, src_node, graph):\n    inner_nodes = []\n    for _, dst_node, attr in graph.edges(src_node, data=True):\n        if attr['type'] == EDGE_TYPE_CONTAINS and dst_node != quer"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.9043946266174316, "line": 387, "text": "def build_graph(repo_path, fuzzy_search=True, global_import=False):\n    # ... other code\n    for node, attributes in graph.nodes(data=True):\n        if attributes.get('type') not in [NODE_TYPE_CLASS, "}, {"file": "util/benchmark/parse_patch.py", "name": "", "type": "codeblock", "score": 2.2731425762176514, "line": 95, "text": "def analyze_swe_dataset(dataset, max_edit_file_num=5, ignore_error=True, selected_list=None, output_file=None):\n    file_num_dist = collections.defaultdict(list)\n    repo_dist = collections.defaultdic"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.1727683544158936, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.1046910285949707, "line": 31, "text": "def add_quotes_to_nodes(G):\n    H = nx.MultiDiGraph()\n\n    # Map old node names to new node names\n    node_mapping = {node: f'\"{node}\"' for node in G.nodes}\n\n    # Add nodes with updated names and cop"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.103729009628296, "line": 716, "text": "def traverse_directory_structure(graph, root='/'):\n    def traverse(node, prefix, is_last):\n        if node == root:\n            print(f\"{node}\")\n            new_prefix = ''\n        else:\n            "}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.070451498031616, "line": 283, "text": "# Traverse all the Python files under repo_path, construct dependency graphs \n# with node types: directory, file, class, function\ndef build_graph(repo_path, fuzzy_search=True, global_import=False):\n  "}, {"file": "util/benchmark/setup_repo.py", "name": "", "type": "codeblock", "score": 2.05648136138916, "line": 1, "text": "import os\nfrom typing import Optional\nfrom datasets import load_dataset\nfrom util.benchmark.git_repo_manager import setup_github_repo\nimport argparse\n\n\ndef load_instances(\n    dataset_name: str = \"pri"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.035574197769165, "line": 97, "text": "gt_file = os.environ.get(\"GT_MODULES_FILE\")\ngt_data = load_jsonl(gt_file)\ngt_data_dict = {}\nfor data in gt_data:\n    instance_id = data['instance_id']\n    gt_data_dict[instance_id] = data\n\ndataset_nam"}], "total_results": 10}
{"repo": "LocAgent", "query": "rank search results", "top_10": [{"file": "repo_index/index/types.py", "name": "", "type": "codeblock", "score": 3.999532699584961, "line": 31, "text": "class SearchCodeHit(BaseModel):\n    file_path: str = Field(\n        description='The file path where the relevant code is found.'\n    )\n    spans: List[SpanHit] = Field(\n        default_factory=list,\n"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 3.7949676513671875, "line": 296, "text": "def run_localize(rank, args, bug_queue, log_queue, output_file_lock, traj_file_lock):\n    queue_handler = logging.handlers.QueueHandler(log_queue)\n    logger = logging.getLogger()\n    logger.setLevel("}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.52254056930542, "line": 745, "text": "def bm25_content_retrieve(\n        query_info: QueryInfo,\n        # query: str,\n        include_files: Optional[List[str]] = None,\n        # file_pattern: Optional[str] = None,\n        similarity_top_"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.3791775703430176, "line": 689, "text": "def get_entity_contents(entity_names: List[str]):\n    searcher = get_graph_entity_searcher()\n\n    result = ''\n    for name in entity_names:\n        name = name.strip().strip('.')\n        if not name: "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 3.231722116470337, "line": 181, "text": "class CodeIndex:\n\n    def search(\n        self,\n        query: Optional[str] = None,\n        code_snippet: Optional[str] = None,\n        class_names: Optional[List[str]] = None,\n        function_names"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.229548454284668, "line": 490, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    \"\"\"Searches"}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 3.132678508758545, "line": 542, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n\n    files, _, "}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 3.015547752380371, "line": 622, "text": "class CodeIndex:\n\n    def _vector_search(\n        self,\n        query: str = '',\n        exact_query_match: bool = False,\n        category: str = 'implementation',\n        file_pattern: Optional[str] "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.952587127685547, "line": 618, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    # ... other"}, {"file": "repo_index/index/code_index.py", "name": "", "type": "codeblock", "score": 2.8764212131500244, "line": 516, "text": "class CodeIndex:\n\n    def find_by_name(\n        self,\n        class_names: Optional[List[str]] = None,\n        function_names: Optional[List[str]] = None,\n        file_pattern: Optional[str] = None,\n "}], "total_results": 10}
{"repo": "LocAgent", "query": "format output", "top_10": [{"file": "util/prompts/pipelines/auto_search_prompt.py", "name": "", "type": "codeblock", "score": 2.6501078605651855, "line": 1, "text": "TASK_INSTRUECTION=\"\"\"\nGiven the following GitHub problem description, your objective is to localize the specific files, classes or functions, and lines of code that need modification or contain key in"}, {"file": "repo_index/types.py", "name": "", "type": "codeblock", "score": 2.601074695587158, "line": 65, "text": "class ActionResponse(BaseModel):\n    trigger: Optional[str] = None\n    output: Optional[dict[str, Any]] = None\n    retry_message: Optional[str] = None\n\n    @classmethod\n    def retry(cls, retry_messag"}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 2.523153781890869, "line": 148, "text": "for output in tqdm(output_data):\n    if output['instance_id'] in processed_instance:\n        continue\n\n    gt_entities = []\n    for module in output['file_changes'][0]['changes']['edited_modules']:\n  "}, {"file": "plugins/location_tools/repo_ops/repo_ops.py", "name": "", "type": "codeblock", "score": 2.487959861755371, "line": 597, "text": "def search_code_snippets(\n        search_terms: Optional[List[str]] = None,\n        line_nums: Optional[List] = None,\n        file_path_or_pattern: Optional[str] = \"**/*.py\",\n) -> str:\n    # ... other"}, {"file": "util/runtime/execute_ipython.py", "name": "", "type": "codeblock", "score": 2.338292121887207, "line": 1, "text": "from IPython import get_ipython\nfrom plugins.location_tools.repo_ops.repo_ops import (\n    search_code_snippets,\n    get_entity_contents,\n    explore_graph_structure,\n    explore_tree_structure,\n)\n\nfr"}, {"file": "util/prompts/pipelines/simple_localize_pipeline.py", "name": "", "type": "codeblock", "score": 2.2406392097473145, "line": 1, "text": "SEARCH_LOC_TASK_INSTRUCTION=\"\"\"\n# Task:\nYou will be provided with a GitHub problem description. Your objective is to localize the specific files, classes, functions, or variable declarations that requ"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.8522847890853882, "line": 1, "text": "import argparse\nimport os\nimport json\nimport torch\nfrom datasets import Dataset\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nfrom unsloth.chat_templates import get_c"}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 1.836327314376831, "line": 116, "text": "def commit_changes(repo_dir, commit_message):\n    subprocess.run(\n        ['git', 'commit', '-m', commit_message, '--no-verify'],\n        cwd=repo_dir,\n        check=True,\n        text=True,\n        c"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.7975361347198486, "line": 147, "text": "def auto_search_process(result_queue,\n                        model_name, messages, fake_user_msg,\n                        tools = None,\n                        traj_data=None,\n                       "}, {"file": "util/extract_entity_from_issue.py", "name": "", "type": "codeblock", "score": 1.7668794393539429, "line": 45, "text": "PR_TEMPLATE=\"\"\"\nGiven the following GitHub problem description, classify the problem statement into the following categories: Problem description, error trace, code to reproduce the bug, and additiona"}], "total_results": 10}
{"repo": "LocAgent", "query": "handle import errors", "top_10": [{"file": "repo_index/codeblocks/parser/python.py", "name": "", "type": "codeblock", "score": 2.994135618209839, "line": 1, "text": "import logging\n\nfrom tree_sitter_languages import get_language\n\nfrom repo_index.codeblocks.codeblocks import (\n    CodeBlock,\n    CodeBlockType,\n    ReferenceScope,\n    RelationshipType,\n    Validatio"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.8197178840637207, "line": 211, "text": "def add_imports(root_node, imports, graph, repo_path):\n    for imp in imports:\n        if imp['type'] == 'import':\n            # Handle 'import module' statements\n            module_name = imp['module"}, {"file": "dependency_graph/build_graph.py", "name": "", "type": "codeblock", "score": 2.624624729156494, "line": 51, "text": "def find_imports(filepath, repo_path, tree=None):\n    if tree is None:\n        try:\n            with open(filepath, 'r') as file:\n                tree = ast.parse(file.read(), filename=filepath)\n     "}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.5823416709899902, "line": 1, "text": "import re\nfrom enum import Enum\nfrom typing import List, Optional, Set\n\nfrom pydantic import BaseModel, Field, root_validator, validator\nfrom typing_extensions import deprecated\n\nfrom repo_index.codeb"}, {"file": "util/benchmark/parse_patch.py", "name": "", "type": "codeblock", "score": 2.2991180419921875, "line": 1, "text": "import os\nimport re\nimport collections\nfrom tqdm import tqdm\nimport unidiff\nfrom unidiff.errors import UnidiffParseError\nimport json\nfrom collections import defaultdict\n\n\ndef get_oracle_filenames(patc"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.233839988708496, "line": 36, "text": "class CodeBlockType(Enum):\n    MODULE = (\n        'Module',\n        CodeBlockTypeGroup.STRUCTURE,\n    )  # TODO: Module shouldn't be a STRUCTURE\n    CLASS = ('Class', CodeBlockTypeGroup.STRUCTURE)\n   "}, {"file": "dependency_graph/batch_build_graph.py", "name": "", "type": "codeblock", "score": 2.21822452545166, "line": 1, "text": "import argparse\nimport json\nimport os\nimport pickle\nimport time\nfrom pathlib import Path\nimport subprocess\nimport torch.multiprocessing as mp\nimport os.path as osp\nfrom datasets import load_dataset\nfr"}, {"file": "repo_index/repository.py", "name": "", "type": "codeblock", "score": 2.2027034759521484, "line": 1, "text": "import difflib\nimport glob\nimport logging\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nfrom pydantic import BaseModel\n\nfrom repo_index.codeblocks import get_parser_by_path\n"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 2.121570587158203, "line": 79, "text": "class CodeBlockType(Enum):\n\n    @classmethod\n    def from_string(cls, tag: str) -> Optional['CodeBlockType']:\n        if not tag.startswith('definition'):\n            return None\n\n        tag_to_block"}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 2.010058879852295, "line": 39, "text": "# def preprocess_statement(statement):\n#     if not statement or not isinstance(statement, str):\n#         return \"\"\n#     max_length = 2000\n#     if len(statement) > max_length:\n#         return stat"}], "total_results": 10}
{"repo": "LocAgent", "query": "configure logger", "top_10": [{"file": "sft_train.py", "name": "", "type": "codeblock", "score": 2.450404167175293, "line": 1, "text": "import argparse\nimport os\nimport json\nimport torch\nfrom datasets import Dataset\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nfrom unsloth.chat_templates import get_c"}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 1.8448179960250854, "line": 1, "text": "import os\nimport openai\nimport litellm\nimport pandas as pd\nimport time\nimport logging\nfrom util.utils import load_jsonl\nimport json\nimport argparse\nfrom datasets import load_dataset\n\n\n# Configure logg"}, {"file": "sft_train.py", "name": "", "type": "codeblock", "score": 1.620788335800171, "line": 50, "text": "def main():\n    args = parse_args()\n    os.makedirs(os.path.join(args.output_dir, args.exp_name), exist_ok=True)\n    # save args to json\n    with open(os.path.join(args.output_dir, args.exp_name, \"arg"}, {"file": "repo_index/codeblocks/parser/parser.py", "name": "", "type": "codeblock", "score": 1.5793204307556152, "line": 703, "text": "class CodeParser:\n\n    def _create_new_span(\n        self, current_span: Optional[BlockSpan], block: CodeBlock\n    ) -> Optional[BlockSpan]:\n        # Set documentation phase on comments in the start "}, {"file": "util/benchmark/gen_oracle_locations.py", "name": "", "type": "codeblock", "score": 1.5345226526260376, "line": 405, "text": "def run_extract_locations_from_patch(rank, \n                                  queue, log_queue, output_file_lock,\n                                  repo_playground, output_file, max_edit_file_num\n    "}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.450584888458252, "line": 296, "text": "def run_localize(rank, args, bug_queue, log_queue, output_file_lock, traj_file_lock):\n    queue_handler = logging.handlers.QueueHandler(log_queue)\n    logger = logging.getLogger()\n    logger.setLevel("}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 1.374387502670288, "line": 26, "text": "def maybe_clone(repo_url, repo_dir):\n    if not os.path.exists(f'{repo_dir}/.git'):\n        logger.info(f\"Cloning repo '{repo_url}'\")\n        # Clone the repo if the directory doesn't exist\n        re"}, {"file": "util/benchmark/git_repo_manager.py", "name": "", "type": "codeblock", "score": 1.374387502670288, "line": 25, "text": "def maybe_clone(repo_url, repo_dir):\n    if not os.path.exists(f\"{repo_dir}/.git\"):\n        logger.info(f\"Cloning repo '{repo_url}'\")\n        # Clone the repo if the directory doesn't exist\n        re"}, {"file": "util/benchmark/git_repo_manager.py", "name": "", "type": "codeblock", "score": 1.3242045640945435, "line": 1, "text": "import logging\nimport os\nimport subprocess\nlogger = logging.getLogger(__name__)\n\ndef get_repo_dir_name(repo: str):\n    return repo.replace(\"/\", \"_\")\n\n\ndef setup_github_repo(repo: str, base_commit: str"}, {"file": "repo_index/index/epic_split.py", "name": "", "type": "codeblock", "score": 1.2868709564208984, "line": 137, "text": "class EpicSplitter(NodeParser):\n\n    def _parse_nodes(\n        self,\n        nodes: Sequence[BaseNode],\n        show_progress: bool = False,\n        **kwargs: Any,\n    ) -> list[BaseNode]:\n        nod"}], "total_results": 10}
{"repo": "LocAgent", "query": "run integration tests", "top_10": [{"file": "util/actions/action.py", "name": "", "type": "codeblock", "score": 2.2009024620056152, "line": 1, "text": "from dataclasses import dataclass\nfrom pydantic import BaseModel, Field\n\nclass ActionTypeSchema(BaseModel):\n\n    MESSAGE: str = Field(default='message')\n    \"\"\"Represents a message.\n    \"\"\"\n\n    RUN_I"}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 2.1500134468078613, "line": 44, "text": "def pull_latest(repo_dir):\n    subprocess.run(\n        ['git', 'pull'],\n        cwd=repo_dir,\n        check=True,\n        text=True,\n        capture_output=True,\n    )\n\n\ndef clean_and_reset_state(repo"}, {"file": "util/benchmark/git_repo_manager.py", "name": "", "type": "codeblock", "score": 2.1462974548339844, "line": 43, "text": "def pull_latest(repo_dir):\n    subprocess.run(\n        [\"git\", \"pull\"],\n        cwd=repo_dir,\n        check=True,\n        text=True,\n        capture_output=True,\n    )\n\n\ndef clean_and_reset_state(repo"}, {"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.13834285736084, "line": 1, "text": "import re\nfrom collections import defaultdict\nfrom typing import Optional, List\n\nimport networkx as nx\n\nfrom dependency_graph.build_graph import (\n    VALID_EDGE_TYPES, VALID_NODE_TYPES, \n    NODE_TYP"}, {"file": "util/benchmark/git_repo_manager.py", "name": "", "type": "codeblock", "score": 2.117124557495117, "line": 115, "text": "def commit_changes(repo_dir, commit_message):\n    subprocess.run(\n        [\"git\", \"commit\", \"-m\", commit_message, \"--no-verify\"],\n        cwd=repo_dir,\n        check=True,\n        text=True,\n        c"}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 2.10355281829834, "line": 116, "text": "def commit_changes(repo_dir, commit_message):\n    subprocess.run(\n        ['git', 'commit', '-m', commit_message, '--no-verify'],\n        cwd=repo_dir,\n        check=True,\n        text=True,\n        c"}, {"file": "repo_index/utils/repo.py", "name": "", "type": "codeblock", "score": 2.0486443042755127, "line": 85, "text": "def create_and_checkout_branch(repo_dir, branch_name):\n    try:\n        branches = subprocess.run(\n            ['git', 'branch'],\n            cwd=repo_dir,\n            check=True,\n            text=Tru"}, {"file": "util/benchmark/git_repo_manager.py", "name": "", "type": "codeblock", "score": 2.0486443042755127, "line": 84, "text": "def create_and_checkout_branch(repo_dir, branch_name):\n    try:\n        branches = subprocess.run(\n            [\"git\", \"branch\"],\n            cwd=repo_dir,\n            check=True,\n            text=Tru"}, {"file": "plugins/requirement.py", "name": "", "type": "codeblock", "score": 2.0352132320404053, "line": 1, "text": "from abc import abstractmethod\nfrom dataclasses import dataclass\n\n# from openhands.events.action import Action\n# from openhands.events.observation import Observation\n\n\n# class Plugin:\n#     \"\"\"Base cl"}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 1.9049838781356812, "line": 35, "text": "def build_code_retriever_from_repo(repo_path,\n                                   similarity_top_k=10,\n                                   min_chunk_size=100,\n                                   chunk_si"}], "total_results": 10}
{"repo": "LocAgent", "query": "measure performance", "top_10": [{"file": "dependency_graph/traverse_graph.py", "name": "", "type": "codeblock", "score": 2.1772210597991943, "line": 242, "text": "def traverse_graph_structure(G, roots, direction='downstream', hops=2,\n                             node_type_filter: Optional[List[str]] = None,\n                             edge_type_filter: Optiona"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 2.173978328704834, "line": 67, "text": "SearchRepoTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='search_code_snippets',\n        description=_SEARCHREPO_DESCRIPTION,\n    "}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 1.7579652070999146, "line": 68, "text": "def classify_with_retry(problem_statement, model, retries=3, delay=1):\n    for attempt in range(retries):\n        try:\n            category = classify_problem_statement(problem_statement, model=model)"}, {"file": "util/runtime/content_tools.py", "name": "", "type": "codeblock", "score": 1.7434173822402954, "line": 50, "text": "_SEARCHREPO_DESCRIPTION = \"\"\"Searches the codebase to retrieve relevant code snippets based on given queries(terms or line numbers).\n** Note:\n- Either `search_terms` or `line_nums` must be provided to"}, {"file": "util/prompts/general_prompt.py", "name": "", "type": "codeblock", "score": 1.6609487533569336, "line": 1, "text": "PR_TEMPLATE = \"\"\"\n--- BEGIN PROBLEM STATEMENT ---\nTitle: {title}\n\n{description}\n--- END PROBLEM STATEMENT ---\n\n\"\"\"\n\n\nSYSTEM_PROMPT=\"\"\"You're an experienced software tester and static analysis expert. "}, {"file": "util/classify_issue.py", "name": "", "type": "codeblock", "score": 1.574080228805542, "line": 1, "text": "import os\nimport openai\nimport litellm\nimport pandas as pd\nimport time\nimport logging\nfrom util.utils import load_jsonl\nimport json\nimport argparse\nfrom datasets import load_dataset\n\n\n# Configure logg"}, {"file": "auto_search_main.py", "name": "", "type": "codeblock", "score": 1.3518694639205933, "line": 609, "text": "def main():\n    # ... other code\n    parser.add_argument(\"--simple_desc\", action=\"store_true\", \n                        help=\"Use simplified function descriptions due to certain LLM limitations. Set t"}, {"file": "util/runtime/fn_call_converter.py", "name": "", "type": "codeblock", "score": 0.537660539150238, "line": 50, "text": "IN_CONTEXT_LEARNING_EXAMPLE_PREFIX = \"\"\"\nHere's a running example of how to perform a task with the provided tools.\n\n--------------------- START OF EXAMPLE ---------------------\n\nUSER: Create a list o"}, {"file": "repo_index/codeblocks/codeblocks.py", "name": "", "type": "codeblock", "score": 0.0, "line": 153, "text": "@deprecated('Use BlockSpans to define code block visibility instead')\nclass PathTree(BaseModel):\n\n    def add_to_tree(self, path: Optional[list[str]] = None):\n        if path is None:\n            retu"}, {"file": "plugins/location_tools/retriever/bm25_retriever.py", "name": "", "type": "codeblock", "score": 0.0, "line": 72, "text": "def build_code_retriever_from_repo(repo_path,\n                                   similarity_top_k=10,\n                                   min_chunk_size=100,\n                                   chunk_si"}], "total_results": 10}
