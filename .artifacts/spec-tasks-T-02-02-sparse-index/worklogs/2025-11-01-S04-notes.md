# Development Notes - 2025-11-01 Session 04

**Task**: T-02-02-sparse-index
**Session**: 04 (Phase 2: Custom Tokenizer - Planning & Prep)
**Date**: 2025-11-01

---

## Technical Notes

### Session 04 Planning Checklist

Planning Tasks:

- [x] Review metadata acceptance matrix for remaining criteria
- [x] Extract tokenizer requirements from LocAgent + PRD-02/06
- [x] Document Tantivy/BM25 schema + index storage expectations
- [x] Outline parity validation strategy (overlap@10 ≥90%)
- [x] Update TODO roster for Session 04 implementation threads

Open Risks to Monitor:

- Stop-word export automation pending; fixture updates remain manual.
- BM25 persistence & rebuild strategy (index dir layout, concurrency) not finalized.
- Highlight/snippet design for BM25 search results still open; needs parity validation.

---

## Architecture Decisions

1. **Tokenizer Parity Pipeline** — Implement tokenizer.rs mirroring LocAgent (normalize → identifier split → stop-word filter → Porter stem) with fixture-driven stop words to guarantee identical token streams; expose both standalone API and Tantivy analyzer component.
2. **Tantivy Analyzer Strategy** — Build a custom analyzer in Phase 3 that reuses the tokenizer pipeline to avoid divergence from LocAgent; configure BM25 index under `TANTIVY_DATA_DIR` with k1=1.5/b=0.75 defaults.
3. **Parity Harness Approach** — Reuse LocAgent 50-query JSONL for overlap@10; build Rust parity loader utilities (`tests/support/parity_loader.rs`) to compare hierarchical search outputs during Phase 5 validation.
4. **Offset Preservation** — Maintain byte offsets through normalization so Tantivy tokens can drive future highlighting while still stemming for scoring; register analyzer under stable name `cds_code`.

---

## Implementation Details

### Phase 2: Custom Tokenizer

**Requirements from LocAgent**:

- BM25 stage consumes tokens produced by `EpicSplitter` + `Stemmer.Stemmer("english")`; we must mirror the normalization steps.
- Identifier splitting: `fooBarBaz` → `foo`, `bar`, `baz`; `parse_ast_node` → `parse`, `ast`, `node`; preserve digits.
- Normalize by lowercasing, ASCII-folding, and stripping punctuation except `_`/`-` before splitting.
- Stop-word filtering must reuse LocAgent list (to be exported into fixture for parity).
- Apply English stemming (Porter/Hunter) to match the `Stemmer` output.

**Parity Strategy**:

- Build `tokenizer.rs` pipeline: normalize → identifier split → punctuation removal → stop-word filter → stemmer.
- Provide golden reference outputs sourced from LocAgent to lock behavior (compare via integration tests).
- Use `rust-stemmers` crate (Porter) and load stop-word list at runtime for configurability.

### Tantivy Analyzer Integration

- Added `TokenizedToken` struct capturing text + byte offsets to feed Tantivy token stream.
- Implemented `TantivyCodeTokenizer` (`Tokenizer` adapter) and `CodeTokenStream` to bridge into Tantivy.
- Exposed `AnalyzerConfig`, `register_code_analyzer`, and `CODE_ANALYZER_NAME` for schema wiring in Phase 3.
- Tests now cover offset preservation, analyzer parity, and fixture stop-word flow.

### Phase 3 Preview: BM25 Index Scaffold

- Implemented `Bm25Index`, `Bm25Document`, `SearchResult`, and `AnalyzerConfig` to manage Tantivy-backed sparse index.
- Added create/open helpers with analyzer registration and bulk ingestion via `replace_documents`.
- Search pipeline uses `QueryParser` (tokenized with CDS analyzer), optional `NodeKind` filtering, and matched-term detection (query ∩ doc tokens).
- Stored content with `IndexRecordOption::WithFreqsAndPositions` to unlock future snippet/highlight generation.
- Unit tests validate indexing/search and entity-type filters.

### Phase 3 Planning: Persistence & Benchmarks

- Aligning on directory layout (`indices/bm25/`, `meta.json`) and rebuild workflow following PRD FR-GS-1.
- Documented configuration requirements (`BM25_INDEX_DIR`, analyzer registration) and lifecycle operations (create, open, clear, refresh).
- Drafted benchmarking checklist covering dataset selection, query corpus, latency/throughput targets, and reporting cadence.
- Action items captured for Phase 3 kickoff:
  - [ ] Implement `bm25::Builder` with create/open/clear API and config wiring.
  - [ ] Add CLI rebuild command + progress logging for BM25 index lifecycle.
  - [ ] Extend `benches/search_bench.rs` with BM25 scenario and machine-readable output.
  - [ ] Prototype snippet/highlighting extraction leveraging stored term positions.

---

## Testing Strategy

- Unit tests cover normalization, camel/snake splits, stop-word pruning, and digit handling.
- Integration tests validate fixture stop-word loading, analyzer parity via `TokenizerManager`, offset invariants, and BM25 search behaviour.
- Upcoming work: add property tests comparing Rust tokenizer output against LocAgent golden fixtures plus BM25 parity harness on golden queries.

---

## Performance Notes

### Current Baselines (from Session 03)

| Operation | Median | Target | Status |
|-----------|--------|--------|--------|
| Exact match | 68.42 ns | <10ms | ✅ |
| Prefix match | 699.40 ns | <10ms | ✅ |
| Index build (1,024) | 2.287 ms | <5s | ✅ |

### Phase 2 Performance Targets

[To be defined for tokenizer operations]

---

## Code Review Notes

[To be documented as code is written]

---

## Debugging Notes

[To be documented as issues arise]

---

## TODO / Follow-up

### Immediate (Phase 2 - Tokenizer)

- [x] Extract LocAgent stop-word list → `tests/fixtures/parity/tokenizer/stop_words.txt`
- [x] Create `tests/support/parity_loader.rs` helper module
- [x] Implement tokenizer.rs with camel/snake splitting + stemming
- [x] Integrate tokenizer into Tantivy analyzer pipeline
- [x] Golden tokenizer fixtures for validation

### Near-term (Phase 3 - BM25)

- [ ] Define `TANTIVY_DATA_DIR` env var + config
- [ ] Integrate Tantivy with custom analyzer (lowercase → identifier split → ASCII fold → Porter stem)
- [ ] Create `BM25Backend` trait for pluggability
- [ ] Wire hierarchical search (upper → lower tier) with configurable fallback threshold
- [ ] Implement BM25 persistence/rebuild workflow and CLI hooks (per Thread 07 plan)
- [ ] Author benchmarking harness (dataset selection, query set, latency reporting)

### Future (Phase 5 - Parity)

- [ ] Replace synthetic benchmark data with parity fixtures
- [ ] Measure overlap@10 against LocAgent baselines (50-query JSONL)
- [ ] Tune BM25 parameters (k1, b) if needed

---

## References

- **PRD**: spacs/prd/0.1.0-MVP-PRDs-v0/02-cds-index-service.md (Section 3.2: Index Architecture)
- **PRD**: spacs/prd/0.1.0-MVP-PRDs-v0/06-rust-refactoring-plan.md (Tokenizer parity)
- **Issue**: spacs/issues/04-0.1.0-mvp/02-index-core/02-sparse-index.md
- **Task**: spacs/tasks/0.1.0-mvp/02-index-core/T-02-02-sparse-index.md
- **LocAgent Reference**: tmp/LocAgent/repo_index/ (tokenizer implementation)
- **Parity baseline**: tests/fixtures/parity/golden_outputs/ (T-06-01 deliverable)

---

## Session Statistics

- **Session Duration**: ~2.9h (Threads 01-06)
- **Productivity**: High (planning, fixtures, analyzer integration, BM25 scaffold completed)
- **Blockers**: Stop-word export script + BM25 persistence/benchmarks pending
- **Code Quality**: Tokenizer/analyzer/BM25 paths covered by unit + integration tests
- **Technical Debt**: Automate stop-word sync; finalize BM25 storage + highlighting strategy

---

**Last Updated**: 2025-11-01 12:05 UTC (Threads 01-06 complete)
**Next Session**: Phase 3 BM25 backend build-out & benchmark wiring
